{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4b9feeda",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"LightGBM and CatBoost\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "    toc-depth: 4\n",
    "    jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde96228",
   "metadata": {},
   "source": [
    "Gradient boosting is one of the most powerful techniques for **structured/tabular data**, often serving as the **go-to choice for tabular data tasks in machine learning competitions**.\n",
    "\n",
    "In the previous chapter, we explored **XGBoost** in detail—covering its **optimization objective**, **regularization techniques**, **split finding algorithms**, and its role as a cornerstone in modern **tabular modeling**.\n",
    "\n",
    "While **XGBoost** is highly effective, other libraries have introduced innovations to address challenges like scalability and categorical feature handling. In this chapter, we focus on two **advanced gradient boosting libraries** and their **key innovations**:\n",
    "\n",
    "- **LightGBM**: Developed by Microsoft, **LightGBM** is optimized for **speed and scalability**. It introduces **Gradient-based One-Side Sampling (GOSS)**, which prioritizes instances with larger gradients for faster training, and **Exclusive Feature Bundling (EFB)**, which reduces memory usage by grouping mutually exclusive features. **LightGBM** also supports **categorical features** efficiently, making it ideal for **large datasets and high-dimensional features**.\n",
    "\n",
    "- **CatBoost**: Created by Yandex, **CatBoost** excels in its **optimized support for categorical features** through advanced target-based encoding. It uses **ordered boosting** to prevent prediction shift and reduce overfitting, often performing well with **minimal tuning** on datasets rich in **categorical variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a15a5d",
   "metadata": {},
   "source": [
    "## What They Share with XGBoost\n",
    "\n",
    "While **LightGBM** and **CatBoost** introduce unique innovations, they build on the same foundational principles as **XGBoost**:\n",
    "\n",
    "- They use a **similar objective function structure** (loss plus regularization) to balance model fit and complexity.\n",
    "- They apply a **second-order Taylor approximation** for efficient optimization of the loss function.\n",
    "- They support **histogram-based split-finding algorithms** to speed up training, with **LightGBM** particularly optimized for this approach.\n",
    "- They support **parallel tree building**, significantly accelerating training compared to traditional gradient boosting.\n",
    "- They provide **native support for categorical encoding**, reducing the need for preprocessing (e.g., one-hot encoding), with **XGBoost** introducing this feature starting in version 1.5.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eba32f",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "\n",
    "### What is LightGBM?\n",
    "\n",
    "**LightGBM** (Light Gradient Boosting Machine) is a high-performance gradient boosting framework developed by Microsoft in 2017. Designed for **speed and scalability**, it is typically faster than **XGBoost** due to its optimized algorithms, with accuracy that is generally comparable but may require tuning. LightGBM excels in:\n",
    "\n",
    "- **Handling large-scale datasets** with many rows and features\n",
    "- **Achieving high speed and memory efficiency** through innovations like **Gradient-based One-Side Sampling (GOSS)**, **Exclusive Feature Bundling (EFB)**, and **histogram-based splitting**\n",
    "\n",
    "Like **XGBoost** and **CatBoost**, it supports **native categorical encoding** and **parallel tree building**, enhancing its efficiency for tabular data tasks. See the [LightGBM paper](https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf) for details on its algorithmic innovations and performance benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cab06e",
   "metadata": {},
   "source": [
    "###  What Makes LightGBM Lighting Fast?\n",
    "\n",
    "LightGBM often outperforms XGBoost in **training speed** and **memory efficiency**, thanks to several key innovations:\n",
    "\n",
    "\n",
    "####  Leaf-Wise Tree Growth\n",
    "\n",
    "- LightGBM splits the **leaf with the largest potential loss reduction**, unlike XGBoost’s **level-wise** approach.\n",
    "- This leads to **lower loss per tree**, making learning more efficient — though it may **overfit** without proper regularization.\n",
    "- Main controls:\n",
    "  - `num_leaves`: primary control for tree complexity\n",
    "  - `max_depth`: optional constraint to prevent overfitting\n",
    "\n",
    "\n",
    "####  GOSS (Gradient-based One-Side Sampling)\n",
    "\n",
    "- GOSS improves speed by:\n",
    "  - **Retaining all instances with large gradients** (i.e., high error)\n",
    "  - **Randomly sampling those with small gradients**\n",
    "- This reduces the dataset size while maintaining accurate split decisions.\n",
    "\n",
    "In gradient boosting, the tree is fit to the **negative gradient** of the loss:\n",
    "\n",
    "$$\n",
    "r_m = -\\left[ \\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)} \\right]_{f = f_{m-1}}\n",
    "$$\n",
    "\n",
    "Observations with larger gradients have more influence on reducing the loss — GOSS prioritizes those. This approach reduces the number of data points processed per iteration, speeding up training while preserving important information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f02e40",
   "metadata": {},
   "source": [
    "#### Exclusive Feature Bundling (EFB)\n",
    "\n",
    "- **EFB** reduces memory usage and accelerates training by bundling **mutually exclusive** features (i.e., features that rarely have non-zero values simultaneously) in **high-dimensional sparse feature spaces**.\n",
    "- This is particularly effective for datasets with **many categorical variables** or **one-hot encoded features**, avoiding the memory overhead of one-hot encoding and complementing LightGBM’s **native categorical support**.\n",
    "\n",
    "**Example**:  \n",
    "The table below shows two mutually exclusive features, `feature1` and `feature2`, bundled into a single `feature_bundle` by assigning distinct value ranges (e.g., 1–4 for `feature1`, 5–6 for `feature2`):\n",
    "\n",
    "| `feature1` | `feature2` | `feature_bundle` |\n",
    "|------------|------------|------------------|\n",
    "| 0          | 2          | 6                |\n",
    "| 0          | 1          | 5                |\n",
    "| 0          | 2          | 6                |\n",
    "| 1          | 0          | 1                |\n",
    "| 2          | 0          | 2                |\n",
    "| 3          | 0          | 3                |\n",
    "| 4          | 0          | 4                |\n",
    "\n",
    "- **Hyperparameter for EFB**:\n",
    "  - `enable_bundle`: Enabled by default to activate automatic bundling.\n",
    "  - `max_conflict_rate`: Controls the maximum conflict rate for bundling (default: 0.0, no conflicts allowed); adjust (e.g., 0.1) to allow minor overlaps.\n",
    "\n",
    "This approach reduces the number of features processed per iteration, speeding up training while preserving important information.\n",
    "\n",
    "Combined with **GOSS**, **EFB** makes **LightGBM** especially well-suited for **large-scale, sparse, tabular datasets**, offering **speed and scalability** while maintaining comparable accuracy with proper tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774de8f",
   "metadata": {},
   "source": [
    "### Using LightGBM\n",
    "\n",
    "\n",
    "Although **LightGBM is not part of Scikit-learn**, it provides a **Scikit-learn-compatible API** through the `lightgbm.sklearn` module. This allows you to use LightGBM models seamlessly with Scikit-learn tools such as `Pipeline`, `GridSearchCV`, and `cross_val_score`.\n",
    "\n",
    "The main classes are:\n",
    "\n",
    "- [`LGBMRegressor`](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html): for regression tasks  \n",
    "- [`LGBMClassifier`](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html): for classification tasks\n",
    "\n",
    "To install the package:\n",
    "\n",
    "\n",
    "``` python\n",
    "pip install lightgbm\n",
    "```\n",
    "> **Note:** LightGBM is a separate library, not part of Scikit-learn, but it provides a **Scikit-learn-compatible API** via `LGBMClassifier` and `LGBMRegressor`.  \n",
    "> This makes it easy to integrate LightGBM models into Scikit-learn workflows such as `Pipeline`, `GridSearchCV`, and `cross_val_score`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09726b8b",
   "metadata": {},
   "source": [
    "#### Core LightGBM Hyperparameters\n",
    "\n",
    "**Core Tree Structure**:\n",
    "\n",
    "- `num_leaves`: Maximum number of leaves (terminal nodes) per tree.\n",
    "- `min_data_in_leaf`: Minimum number of data points required in a leaf.\n",
    "- `max_depth`: Maximum depth of a tree (used to control overfitting).\n",
    "\n",
    "\n",
    "**Learning Control and Regularization**:\n",
    "\n",
    "- `learning_rate (η)`: Shrinks the contribution of each tree.\n",
    "- `n_estimators`: Number of boosting rounds.\n",
    "- `lambda_l1` / `lambda_l2`: L1 and L2 regularization on leaf weights.\n",
    "- `min_gain_to_split`: Minimum loss reduction required to make a further split (structure regularization).\n",
    "\n",
    "\n",
    "\n",
    "**Data Handling**:\n",
    "\n",
    "- `feature_fraction`: Fraction of features randomly sampled for each tree (a.k.a. `colsample_bytree` in XGBoost).\n",
    "- `bagging_fraction`: Fraction of data randomly sampled for each iteration.\n",
    "- `bagging_freq`: Frequency (in iterations) to perform bagging.\n",
    "- `categorical_feature`: Specifies which features are categorical (enables native handling).\n",
    "\n",
    "\n",
    "**Speed vs. Accuracy Trade-offs**:\n",
    "\n",
    "- `max_bin`: Number of bins used to bucket continuous features.\n",
    "- `data_sample_strategy` : `bagging` or `goss`\n",
    "- `top_rate` *(`goss` only)*: Fraction of instances with the largest gradients to keep.\n",
    "- `other_rate` *(`goss` only)*: Fraction of small-gradient instances to randomly sample.\n",
    "-`enable_bundle`: set this to true to spped up the training for sparse datasets\n",
    "\n",
    "\n",
    "**Optimization Control**:\n",
    "\n",
    "- `boosting`: Type of boosting algorithm (`gbdt`, `dart`, `rf`, etc.).\n",
    "- `early_stopping_rounds`: Stops training if the validation score doesn’t improve over a set number of rounds.\n",
    "\n",
    "\n",
    "**Imbalanced Data**\n",
    "\n",
    "- `scale_pos_weight`: Manually sets the weight for the positive class in binary classification.\n",
    "- `is_unbalance`: Automatically adjusts class weights based on the training data distribution.\n",
    "\n",
    "> ⚠️ These two options are **mutually exclusive** — use **only one**. If both are set, `scale_pos_weight` takes priority.\n",
    "\n",
    "For full details and advanced options, see the [LightGBM Parameters Guide](https://lightgbm.readthedocs.io/en/latest/Parameters.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f819f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram, plot_convergence\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c74843",
   "metadata": {},
   "source": [
    "We'll continue to use the same datasets that we have been using throughout the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9036ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vw</td>\n",
       "      <td>Beetle</td>\n",
       "      <td>2014</td>\n",
       "      <td>Manual</td>\n",
       "      <td>55457</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>30</td>\n",
       "      <td>65.3266</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vauxhall</td>\n",
       "      <td>GTC</td>\n",
       "      <td>2017</td>\n",
       "      <td>Manual</td>\n",
       "      <td>15630</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>47.2049</td>\n",
       "      <td>1.4</td>\n",
       "      <td>10998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>merc</td>\n",
       "      <td>G Class</td>\n",
       "      <td>2012</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>43000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>570</td>\n",
       "      <td>25.1172</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audi</td>\n",
       "      <td>RS5</td>\n",
       "      <td>2019</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>10</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>30.5593</td>\n",
       "      <td>2.9</td>\n",
       "      <td>51990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>merc</td>\n",
       "      <td>X-CLASS</td>\n",
       "      <td>2018</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>14000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>240</td>\n",
       "      <td>35.7168</td>\n",
       "      <td>2.3</td>\n",
       "      <td>28990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      brand     model  year transmission  mileage fuelType  tax      mpg  \\\n",
       "0        vw    Beetle  2014       Manual    55457   Diesel   30  65.3266   \n",
       "1  vauxhall       GTC  2017       Manual    15630   Petrol  145  47.2049   \n",
       "2      merc   G Class  2012    Automatic    43000   Diesel  570  25.1172   \n",
       "3      audi       RS5  2019    Automatic       10   Petrol  145  30.5593   \n",
       "4      merc   X-CLASS  2018    Automatic    14000   Diesel  240  35.7168   \n",
       "\n",
       "   engineSize  price  \n",
       "0         1.6   7490  \n",
       "1         1.4  10998  \n",
       "2         3.0  44990  \n",
       "3         2.9  51990  \n",
       "4         2.3  28990  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "car = pd.read_csv('Datasets/car.csv')\n",
    "car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6b5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car.drop(columns=['price'])\n",
    "y = car['price']\n",
    "\n",
    "# extract the categorical columns and put them in a list\n",
    "categorical_feature = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# extract the numerical columns and put them in a list\n",
    "numerical_feature = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# convert the categorical columns to category type\n",
    "for col in categorical_feature:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c772c1",
   "metadata": {},
   "source": [
    "####  Building a Baseline Model Using LightGBM’s Native Categorical Feature Support\n",
    "\n",
    "LightGBM provides **built-in support for handling categorical features**, eliminating the need for manual encoding (like one-hot or ordinal encoding). By directly passing categorical column names or indices to the model, LightGBM can internally apply efficient encoding and optimized split finding for categorical variables.\n",
    "\n",
    "In this section, we'll use this native capability to **quickly build a baseline model**, taking advantage of LightGBM’s efficiency with structured data that includes categorical columns.\n",
    "\n",
    "This baseline model serves as a **starting point** for comparison against more advanced tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38736472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Baseline LightGBM Model =====\n",
      "Test RMSE: 3680.8999\n",
      "Test R²: 0.9538\n",
      "CPU times: total: 875 ms\n",
      "Wall time: 82.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ===== 1. Baseline Model =====\n",
    "print(\"\\n===== Baseline LightGBM Model =====\")\n",
    "# Initialize the LightGBM regressor\n",
    "model = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "# Train the model with categorical features specified\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    categorical_feature=categorical_feature\n",
    ")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output results\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c4a044",
   "metadata": {},
   "source": [
    "####  Enabling GOSS and EFB in LightGBM\n",
    "\n",
    "##### GOSS is **not enabled by default**. \n",
    "The default boosting type is `gbdt` (traditional Gradient Boosting Decision Tree), which uses all data instances for each iteration without sampling based on gradients.\n",
    "\n",
    "To use GOSS, you must explicitly set the `boosting_type` parameter to `goss` in the model configuration. When you do this, LightGBM uses GOSS with default values for its specific hyperparameters:\n",
    "\n",
    "* `top_rate`: 0.2 (keeps 20% of instances with large gradients)\n",
    "* `other_rate`: 0.1 (randomly samples 10% of instances with small gradients)\n",
    "  \n",
    "\n",
    "##### EFB is **enabled by default**\n",
    "\n",
    "```python\n",
    "enable_bundle = True\n",
    "```\n",
    "\n",
    "This optimization reduces dimensionality by bundling mutually exclusive sparse features, such as those resulting from one-hot encoding.\n",
    "\n",
    "⚠️ Note: In our car dataset, the data size is small and there are only a few categorical features, so these optimizations may not have a noticeable impact.\n",
    "However, for large-scale datasets with many categorical features, enabling GOSS and EFB is highly recommended to improve training efficiency and reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1677750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== LightGBM with GOSS Sampling =====\n",
      "Test RMSE (GOSS): 3510.7726\n",
      "Test R² (GOSS): 0.9580\n",
      "CPU times: total: 766 ms\n",
      "Wall time: 79.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ===== 2. LightGBM with GOSS Sampling =====\n",
    "print(\"\\n===== LightGBM with GOSS Sampling =====\")\n",
    "\n",
    "# Initialize the LightGBM regressor with GOSS\n",
    "model_goss = lgb.LGBMRegressor(\n",
    "    boosting_type='goss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model with categorical features specified\n",
    "model_goss.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    categorical_feature=categorical_feature\n",
    ")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_goss = model_goss.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rmse_goss = root_mean_squared_error(y_test, y_pred_goss)\n",
    "r2_goss = r2_score(y_test, y_pred_goss)\n",
    "\n",
    "# Output results\n",
    "print(f\"Test RMSE (GOSS): {rmse_goss:.4f}\")\n",
    "print(f\"Test R² (GOSS): {r2_goss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f91c63",
   "metadata": {},
   "source": [
    "####  Tuning `top_rate` and `other_rate` in GOSS\n",
    "\n",
    "Even with this small dataset, we observed a **shorter execution time** and a **slight improvement in performance** using GOSS. \n",
    "\n",
    "The default settings are reasonable for many datasets. To leverage **GOSS** more effectively, optimize performance by tuning **top_rate** (e.g., 0.1, 0.2, 0.3, 0.4) and **other_rate** (e.g., 0.05, 0.1, 0.15, 0.2) using cross-validation, especially for large or noisy datasets.\n",
    "\n",
    "> ⚠️ **Note:** When using `boosting_type='goss'`, LightGBM requires that  \n",
    "> **`top_rate + other_rate ≤ 1.0`**  \n",
    "> This constraint ensures that the combined sample used for training does not exceed the size of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09e449da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  OrderedDict({'other_rate': 0.33986603248215197, 'top_rate': 0.31901459322046166})\n",
      "Test RMSE (GOSS with tuning): 3458.7664\n",
      "Test R² (GOSS with tuning): 0.9592\n"
     ]
    }
   ],
   "source": [
    "# tuning the top_rate and other_rate parameters\n",
    "# Initialize the LightGBM regressor with GOSS\n",
    "model_goss_tune = lgb.LGBMRegressor(\n",
    "    boosting_type='goss',\n",
    "    random_state=42\n",
    ")\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'top_rate': Real(0.1, 0.6, prior='uniform'),\n",
    "    'other_rate': Real(0.1, 0.4, prior='uniform'),\n",
    "}\n",
    "# Initialize the BayesSearchCV object\n",
    "opt = BayesSearchCV(\n",
    "    model_goss_tune,\n",
    "    param_grid,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "# Fit the model\n",
    "opt.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    categorical_feature=categorical_feature\n",
    ")\n",
    "# the best parameters\n",
    "print(\"Best parameters found: \", opt.best_params_)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_opt = opt.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rmse_opt = root_mean_squared_error(y_test, y_pred_opt)\n",
    "r2_opt = r2_score(y_test, y_pred_opt)\n",
    "# Output results\n",
    "print(f\"Test RMSE (GOSS with tuning): {rmse_opt:.4f}\")\n",
    "print(f\"Test R² (GOSS with tuning): {r2_opt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537963ac",
   "metadata": {},
   "source": [
    "#### Optimizing LightGBM with `BayesSearchCV`\n",
    "\n",
    "`BayesSearchCV` from `scikit-optimize` provides an efficient way to tune hyperparameters. Here's how to set this up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35e60b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: OrderedDict({'learning_rate': 0.31777940485083805, 'max_depth': 5, 'min_data_in_leaf': 47, 'n_estimators': 369, 'num_leaves': 20, 'other_rate': 0.4, 'top_rate': 0.6})\n",
      "Best Score: -3361.8218393725633\n",
      "RMSE (Bayesian Optimized): 3071.418344800289\n",
      "R2 Score (Bayesian Optimized): 0.9678447743461689\n",
      "CPU times: total: 49.4 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ===== 2. Hyperparameter Tuning with Bayesian Optimization =====\n",
    "# Define the parameter space for Bayesian optimization\n",
    "param_space = {\n",
    "    'num_leaves': Integer(20, 100),\n",
    "    'max_depth': Integer(5, 50),\n",
    "    'min_data_in_leaf': Integer(1, 100),\n",
    "    'learning_rate': Real(0.01, 0.5, prior='uniform'),\n",
    "    'n_estimators': Integer(50, 500),\n",
    "    'top_rate': Real(0.1, 0.6, prior='uniform'),\n",
    "    'other_rate': Real(0.1, 0.4, prior='uniform'),\n",
    "}\n",
    "# Create the Bayesian search object\n",
    "bayes_search = BayesSearchCV(\n",
    "    # using verbose=-1 to suppress warnings\n",
    "    # using n_jobs=-1 to use all available cores\n",
    "    # using random_state=42 for reproducibility\n",
    "    estimator=lgb.LGBMRegressor( categorical_feature=categorical_feature, random_state=42, boosting_type='goss', verbose=-1),\n",
    "    # Define the parameter space for Bayesian optimization\n",
    "    search_spaces=param_space,\n",
    "    n_iter=50,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "# Fit the Bayesian search object to the training data\n",
    "bayes_search.fit(X_train, y_train)\n",
    "# Get the best parameters and score\n",
    "best_params = bayes_search.best_params_\n",
    "best_score = bayes_search.best_score_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score}\")\n",
    "# Get the best model\n",
    "best_model = bayes_search.best_estimator_\n",
    "# Make predictions on the test set\n",
    "y_pred_bayes = best_model.predict(X_test)\n",
    "# Calculate RMSE and R2 score for the best model\n",
    "rmse_bayes = root_mean_squared_error(y_test, y_pred_bayes)\n",
    "r2_bayes = r2_score(y_test, y_pred_bayes)\n",
    "print(f\"RMSE (Bayesian Optimized): {rmse_bayes}\")\n",
    "print(f\"R2 Score (Bayesian Optimized): {r2_bayes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1830fb",
   "metadata": {},
   "source": [
    "**LightGBM** achieved performance comparable to **XGBoost**. By leveraging **GOSS** (Gradient-based One-Side Sampling) for gradient sampling and **EFB** (Exclusive Feature Bundling) for feature reduction, it improved training speed slightly on large, sparse datasets. These optimizations, along with **native categorical feature support**, can also help reduce cross-validation tuning time by simplifying the feature space and accelerating learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b16144",
   "metadata": {},
   "source": [
    "##  CatBoost\n",
    "\n",
    "### What is CatBoost?\n",
    "\n",
    "**CatBoost** (short for *Categorical Boosting*) is a high-performance gradient boosting framework developed by **Yandex**. While several modern boosting frameworks support native categorical features, CatBoost uses **optimized encoding strategies**—such as **ordered target statistics**—that often lead to better performance with less risk of overfitting on **categorical-heavy** data.\n",
    "\n",
    "In addition to its categorical handling, CatBoost includes features like **ordered boosting** and strong **regularization**, which help reduce overfitting. It typically requires **less hyperparameter tuning** than XGBoost or LightGBM, making it more **user-friendly**, especially on datasets with many categorical variables.\n",
    "\n",
    "\n",
    "### What Makes CatBoost Unique?\n",
    "\n",
    "CatBoost introduces several **key innovations** that set it apart from other gradient boosting frameworks:\n",
    "\n",
    "\n",
    "\n",
    "####  Symmetric (Oblivious) Trees\n",
    "\n",
    "CatBoost builds **symmetric (oblivious) decision trees**, where the same feature and split threshold are used at each level of the tree across all nodes. This structure results in:\n",
    "\n",
    "- **Robust to noise**\n",
    "- **Improved regularization**\n",
    "- **Faster inference times**\n",
    "\n",
    "\n",
    "\n",
    "####  Advanced Categorical Feature Handling\n",
    "\n",
    "CatBoost can **natively process categorical features** using an approach based on **ordered target statistics**, which:\n",
    "\n",
    "- Avoids target leakage during training\n",
    "- Typically outperforms traditional encodings like one-hot or label encoding\n",
    "\n",
    "\n",
    "####  Ordered Boosting (vs. Standard Boosting)\n",
    "\n",
    "Traditional gradient boosting algorithms often suffer from **prediction shift**, a form of overfitting that occurs when the model uses the same data to compute residuals and to fit new trees.\n",
    "\n",
    "CatBoost addresses this with **ordered boosting**, a permutation-driven strategy that builds each tree on one subset of data and computes residuals on another (unseen) subset.\n",
    "\n",
    "Recall that gradient boosting fits trees on the gradient of the loss function:\n",
    "\n",
    "$$\n",
    "r_m = -\\left[ \\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)} \\right]_{f = f_{m-1}}\n",
    "$$\n",
    "\n",
    "In classic boosting, this gradient is calculated using the same training observations that were used to fit the model, which leads to target leakage.\n",
    "\n",
    "In contrast, CatBoost:\n",
    "\n",
    "- Shuffles the data at each iteration\n",
    "- Computes residuals for an observation **only from prior observations** in the permutation\n",
    "- Ensures that **each gradient estimate is based on unseen data**\n",
    "\n",
    "This significantly improves the model’s **generalizability** and reduces overfitting, especially on **small or noisy datasets**.\n",
    "\n",
    "\n",
    "#### Handling of Text and Embedding Features\n",
    "\n",
    "CatBoost can process text features directly by converting them into numerical representations (e.g., using bag-of-words or embeddings) within the model, reducing the need for external preprocessing.\n",
    "It also supports integration with pre-trained embeddings, which is useful for natural language processing (NLP) tasks.\n",
    "\n",
    "Together, these innovations make CatBoost a strong candidate for modeling **high-dimensional, categorical, and imbalanced tabular data**, even with minimal feature engineering or hyperparameter tuning.\n",
    "\n",
    "#### Ease of Use and Defaults\n",
    "\n",
    "CatBoost’s default hyperparameters are well-tuned for a wide range of problems, reducing the need for extensive tuning. For example, its learning rate, depth, and regularization parameters often yield strong performance out of the box. In the paper, the authors also showed that CatBoost outperforms XGBoost and LightGBM without tuning, i.e., with default hyperparameter settings.\n",
    "\n",
    "Read the [CatBoost paper](https://proceedings.neurips.cc/paper_files/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf) for more details.\n",
    "\n",
    "Here is a good [blog](https://neptune.ai/blog/when-to-choose-catboost-over-xgboost-or-lightgbm) listing the key features of CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3a95a",
   "metadata": {},
   "source": [
    "###  Using CatBoost\n",
    "\n",
    "CatBoost provides a **scikit-learn-compatible API** through `CatBoostClassifier` and `CatBoostRegressor`, which makes it easy to integrate into pipelines and use with tools like `GridSearchCV`, `cross_val_score`, and `train_test_split`.\n",
    "\n",
    "###  Installation\n",
    "\n",
    "To install CatBoost, run:\n",
    "\n",
    "``` python\n",
    "pip install catboost\n",
    "```\n",
    "> 💡 GPU users: CatBoost automatically detects and uses GPU if available. You can explicitly enable it with `task_type='GPU'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c009a2",
   "metadata": {},
   "source": [
    "### CatBoost for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d987907",
   "metadata": {},
   "source": [
    "Let us check the performance of `CatBoostRegressor()` without tuning, i.e., with default hyperparameter settings on our car dataset\n",
    "\n",
    "The parameter `cat_features` will be used to specify the indices of the categorical predictors for target encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf0a6c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (CatBoost): 3307.2604\n",
      "Test R² (CatBoost): 0.9627\n"
     ]
    }
   ],
   "source": [
    "# build a catboostregressor model\n",
    "from catboost import CatBoostRegressor\n",
    "# Initialize the CatBoost regressor\n",
    "model_cat = CatBoostRegressor(\n",
    "    cat_features=categorical_feature,\n",
    "    random_seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_cat.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "y_pred_cat = model_cat.predict(X_test)\n",
    "# Calculate evaluation metrics\n",
    "rmse_cat = root_mean_squared_error(y_test, y_pred_cat)\n",
    "r2_cat = r2_score(y_test, y_pred_cat)\n",
    "# Output results\n",
    "print(f\"Test RMSE (CatBoost): {rmse_cat:.4f}\")\n",
    "print(f\"Test R² (CatBoost): {r2_cat:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895c618",
   "metadata": {},
   "source": [
    "Even with default hyperparameter settings, CatBoost has outperformed both XGBoost and LightGBM in terms of test RMSE and R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06740ea",
   "metadata": {},
   "source": [
    "### Tuning `CatBoostRegressor`\n",
    "\n",
    "You can tune the hyperparameters of `CatBoostRegressor` using **Optuna** or other tuning strategies, just as you would for `XGBoost` or `LightGBM`. However, CatBoost has a **distinct set of hyperparameters**, reflecting its unique design choices.\n",
    "\n",
    "\n",
    "#### ❌ Hyperparameters **not used** in CatBoost:\n",
    "\n",
    "- `reg_alpha`: CatBoost does **not** support L1 regularization on leaf weights; it uses only **L2 regularization** (`l2_leaf_reg`).\n",
    "- `colsample_bytree`: CatBoost **does not** use this parameter; it uses `rsm` and handles feature selection differently.\n",
    "\n",
    "These parameters are common in XGBoost and LightGBM but are **not part of CatBoost's configuration**.\n",
    "\n",
    "\n",
    "\n",
    "#### ✅ Unique Hyperparameters in CatBoost\n",
    "\n",
    "CatBoost introduces several hyperparameters related to **categorical feature handling** and **ordered boosting**:\n",
    "\n",
    "- `one_hot_max_size`: Threshold for switching between **one-hot encoding** and **target encoding** for categorical features.\n",
    "\n",
    "- `boosting_type='Ordered'`: Ordered boosting is **enabled by default** in CatBoost to reduce overfitting and prevent prediction shift.\n",
    "\n",
    "- `bootstrap_type='Bayesian'`: Default bootstrap method. Works well with ordered boosting.\n",
    "\n",
    "- `bagging_temperature`: Works with `bootstrap_type='Bayesian'`.  \n",
    "  Controls how sharply bootstrap weights are distributed:\n",
    "  - **Low values** (e.g., `0`): more uniform sampling (close to deterministic).\n",
    "  - **High values** (e.g., `1`, `5`, `10`): more aggressive sampling—some rows are weighted more heavily.\n",
    "\n",
    "- `random_strength`: Adds randomness to the **split selection score**, especially useful for regularizing categorical splits.\n",
    "\n",
    "- `rsm`: Random selection rate for column sampling.\n",
    "\n",
    "These CatBoost-specific hyperparameters are important when fine-tuning with Cross-Validation, particularly for datasets with many **categorical features** or at risk of **overfitting**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6403528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 06:53:24,620] A new study created in memory with name: no-name-2b89c789-86c1-45aa-9511-7e7990a5767a\n",
      "[I 2025-05-16 06:53:36,438] Trial 0 finished with value: -2885.7311361568736 and parameters: {'learning_rate': 0.12726746487613003, 'depth': 10, 'l2_leaf_reg': 0.00172009052841597, 'min_data_in_leaf': 13, 'bagging_temperature': 0.21730485409197553, 'random_strength': 0.0002251704542179119}. Best is trial 0 with value: -2885.7311361568736.\n",
      "[I 2025-05-16 06:54:07,518] Trial 1 finished with value: -2620.171198484414 and parameters: {'learning_rate': 0.05369228812155998, 'depth': 7, 'l2_leaf_reg': 2.5645654686725287e-07, 'min_data_in_leaf': 28, 'bagging_temperature': 0.03449070019194467, 'random_strength': 2.200162833623553}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:55:01,902] Trial 2 finished with value: -2696.8294539080816 and parameters: {'learning_rate': 0.02548811714993481, 'depth': 8, 'l2_leaf_reg': 0.0023811609906064252, 'min_data_in_leaf': 13, 'bagging_temperature': 0.9288401488970826, 'random_strength': 1.082500115732704}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:55:22,721] Trial 3 finished with value: -2724.528794214105 and parameters: {'learning_rate': 0.06451150035785631, 'depth': 9, 'l2_leaf_reg': 4.5131464056397556e-08, 'min_data_in_leaf': 30, 'bagging_temperature': 0.5960655866129079, 'random_strength': 9.28215317432208e-07}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:55:36,587] Trial 4 finished with value: -2878.820243617394 and parameters: {'learning_rate': 0.11527331094852836, 'depth': 4, 'l2_leaf_reg': 0.4475951626701213, 'min_data_in_leaf': 20, 'bagging_temperature': 0.7324000256379442, 'random_strength': 0.4338664457953787}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:55:49,775] Trial 5 finished with value: -2668.619984949151 and parameters: {'learning_rate': 0.1855528089325658, 'depth': 6, 'l2_leaf_reg': 1.8378952869939127e-05, 'min_data_in_leaf': 24, 'bagging_temperature': 0.5768414336451607, 'random_strength': 0.010522014874970544}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:55:57,119] Trial 6 finished with value: -2912.272947098299 and parameters: {'learning_rate': 0.2451855882147167, 'depth': 10, 'l2_leaf_reg': 1.7673885188960817e-06, 'min_data_in_leaf': 10, 'bagging_temperature': 0.4334470051053827, 'random_strength': 0.11406026772554442}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:56:13,622] Trial 7 finished with value: -2695.2648598625924 and parameters: {'learning_rate': 0.09755102190100745, 'depth': 10, 'l2_leaf_reg': 9.566125114415794e-08, 'min_data_in_leaf': 19, 'bagging_temperature': 0.9211592949414568, 'random_strength': 2.436347090461743e-08}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:56:26,903] Trial 8 finished with value: -2753.084945654914 and parameters: {'learning_rate': 0.18843128663283498, 'depth': 5, 'l2_leaf_reg': 5.835652831494221e-06, 'min_data_in_leaf': 6, 'bagging_temperature': 0.7987698449327993, 'random_strength': 0.06362728767715319}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:56:34,769] Trial 9 finished with value: -2921.4504143784643 and parameters: {'learning_rate': 0.22960449698497942, 'depth': 10, 'l2_leaf_reg': 1.1782309803914464e-08, 'min_data_in_leaf': 22, 'bagging_temperature': 0.7169193876429558, 'random_strength': 0.023405106337219345}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:56:45,103] Trial 10 finished with value: -2797.656433395867 and parameters: {'learning_rate': 0.29638954558703867, 'depth': 7, 'l2_leaf_reg': 7.121156648133439, 'min_data_in_leaf': 1, 'bagging_temperature': 0.028555585214749657, 'random_strength': 0.00013397670124843048}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:57:00,983] Trial 11 finished with value: -2987.804912052353 and parameters: {'learning_rate': 0.17465375823124038, 'depth': 6, 'l2_leaf_reg': 3.169840926062148e-05, 'min_data_in_leaf': 29, 'bagging_temperature': 0.40829527505593155, 'random_strength': 7.361593602808678}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:58:30,211] Trial 12 finished with value: -2656.269812196844 and parameters: {'learning_rate': 0.017073325011989847, 'depth': 7, 'l2_leaf_reg': 0.00018641156280634486, 'min_data_in_leaf': 25, 'bagging_temperature': 0.2504148253088835, 'random_strength': 0.0036050209677933906}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:59:27,791] Trial 13 finished with value: -2744.3027101379294 and parameters: {'learning_rate': 0.01817177055582332, 'depth': 7, 'l2_leaf_reg': 0.03706735720453296, 'min_data_in_leaf': 25, 'bagging_temperature': 0.002547331855073512, 'random_strength': 2.0356833250740667e-05}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 06:59:53,265] Trial 14 finished with value: -2697.6837955182573 and parameters: {'learning_rate': 0.06236194061749396, 'depth': 8, 'l2_leaf_reg': 5.295910383215519e-07, 'min_data_in_leaf': 27, 'bagging_temperature': 0.20340714193628523, 'random_strength': 0.0018522086502427496}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 07:00:21,452] Trial 15 finished with value: -2766.897166940931 and parameters: {'learning_rate': 0.061014851192040906, 'depth': 6, 'l2_leaf_reg': 0.00013014280192782276, 'min_data_in_leaf': 17, 'bagging_temperature': 0.21609021631792624, 'random_strength': 9.66330609620808}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 07:01:00,089] Trial 16 finished with value: -2731.9161533728666 and parameters: {'learning_rate': 0.027412623287634285, 'depth': 8, 'l2_leaf_reg': 0.0010697541231850665, 'min_data_in_leaf': 26, 'bagging_temperature': 0.1205465052440132, 'random_strength': 9.050362919853505e-06}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 07:01:13,872] Trial 17 finished with value: -2950.387762628911 and parameters: {'learning_rate': 0.06559997537771182, 'depth': 5, 'l2_leaf_reg': 0.03303703827909148, 'min_data_in_leaf': 22, 'bagging_temperature': 0.33823889215394143, 'random_strength': 0.004091235937143242}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 07:01:24,805] Trial 18 finished with value: -2799.2851339120025 and parameters: {'learning_rate': 0.08913764405155444, 'depth': 7, 'l2_leaf_reg': 4.0696494316792653e-07, 'min_data_in_leaf': 30, 'bagging_temperature': 0.3238078952128749, 'random_strength': 0.0012282635994702415}. Best is trial 1 with value: -2620.171198484414.\n",
      "[I 2025-05-16 07:01:36,339] Trial 19 finished with value: -2772.5541221320145 and parameters: {'learning_rate': 0.14059069364937926, 'depth': 9, 'l2_leaf_reg': 9.039692246883738e-05, 'min_data_in_leaf': 23, 'bagging_temperature': 0.07579428007376465, 'random_strength': 0.5896255350389338}. Best is trial 1 with value: -2620.171198484414.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import create_study\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# create a validation set for early stopping\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "#convert to Catboost pool\n",
    "train_pool = Pool(X_train, y_train, cat_features=categorical_feature)\n",
    "valid_pool = Pool(X_valid, y_valid, cat_features=categorical_feature)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 30),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),\n",
    "\n",
    "        # Fixed parameters\n",
    "        'iterations': 3000,  # Set to a high number, early stopping will determine the actual number\n",
    "        'verbose': False,\n",
    "        'random_seed': 42\n",
    "    }\n",
    "    \n",
    "    # Create and train the model with early stopping\n",
    "    model = CatBoostRegressor(**params)\n",
    "    \n",
    "    # Use early stopping to prevent overfitting\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=valid_pool,\n",
    "        early_stopping_rounds=20,  # Stop if no improvement for 50 rounds\n",
    "        verbose=False,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_pred = model.predict(valid_pool)\n",
    "    val_rmse = root_mean_squared_error(y_valid, y_pred)\n",
    "    \n",
    "    # Return negative RMSE (for maximization)\n",
    "    return -val_rmse\n",
    "\n",
    "# Create and run the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e347a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.05369228812155998, 'depth': 7, 'l2_leaf_reg': 2.5645654686725287e-07, 'min_data_in_leaf': 28, 'bagging_temperature': 0.03449070019194467, 'random_strength': 2.200162833623553}\n",
      "Best trial: FrozenTrial(number=1, state=1, values=[-2620.171198484414], datetime_start=datetime.datetime(2025, 5, 16, 6, 53, 36, 439603), datetime_complete=datetime.datetime(2025, 5, 16, 6, 54, 7, 518257), params={'learning_rate': 0.05369228812155998, 'depth': 7, 'l2_leaf_reg': 2.5645654686725287e-07, 'min_data_in_leaf': 28, 'bagging_temperature': 0.03449070019194467, 'random_strength': 2.200162833623553}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'depth': IntDistribution(high=10, log=False, low=4, step=1), 'l2_leaf_reg': FloatDistribution(high=10.0, log=True, low=1e-08, step=None), 'min_data_in_leaf': IntDistribution(high=30, log=False, low=1, step=1), 'bagging_temperature': FloatDistribution(high=1.0, log=False, low=0.0, step=None), 'random_strength': FloatDistribution(high=10.0, log=True, low=1e-08, step=None)}, trial_id=1, value=None)\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters and train final model with early stopping\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Get the best trial\n",
    "best_trial = study.best_trial\n",
    "print(\"Best trial:\", best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700beb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of trees used: 1021\n",
      "Test RMSE: 3147.8477\n",
      "Test R²: 0.9662\n"
     ]
    }
   ],
   "source": [
    "# Use column indices instead of names\n",
    "cat_feature_indices = [X_train.columns.get_loc(col) for col in categorical_feature]\n",
    "\n",
    "# Add iterations parameter back for final model\n",
    "best_params['iterations'] = 3000  # High number, early stopping will be used\n",
    "\n",
    "# create a train+validation set for final model\n",
    "train_val_pool = Pool(\n",
    "    np.vstack((X_train, X_valid)),\n",
    "    np.concatenate((y_train, y_valid)),\n",
    "    cat_features=cat_feature_indices\n",
    ")\n",
    "\n",
    "# Create a test pool\n",
    "test_pool = Pool(X_test, y_test, cat_features=categorical_feature)\n",
    "\n",
    "# Train final model on combined train+validation data\n",
    "final_model = CatBoostRegressor(**best_params)\n",
    "final_model.fit(\n",
    "    train_val_pool,\n",
    "    eval_set=test_pool,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Get actual number of trees used after early stopping\n",
    "actual_iterations = final_model.tree_count_\n",
    "print(f\"Actual number of trees used: {actual_iterations}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "test_rmse = root_mean_squared_error(y_test, y_pred_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Test R²: {test_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c35df952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          -2885.7311361568736,
          -2620.171198484414,
          -2696.8294539080816,
          -2724.528794214105,
          -2878.820243617394,
          -2668.619984949151,
          -2912.272947098299,
          -2695.2648598625924,
          -2753.084945654914,
          -2921.4504143784643,
          -2797.656433395867,
          -2987.804912052353,
          -2656.269812196844,
          -2744.3027101379294,
          -2697.6837955182573,
          -2766.897166940931,
          -2731.9161533728666,
          -2950.387762628911,
          -2799.2851339120025,
          -2772.5541221320145
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          -2885.7311361568736,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414,
          -2620.171198484414
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "l2_leaf_reg (FloatDistribution): 0.012425799583815931<extra></extra>",
          "random_strength (FloatDistribution): 0.0731150244069925<extra></extra>",
          "depth (IntDistribution): 0.09900368078284365<extra></extra>",
          "min_data_in_leaf (IntDistribution): 0.16536625562969337<extra></extra>",
          "bagging_temperature (FloatDistribution): 0.1923784406056739<extra></extra>",
          "learning_rate (FloatDistribution): 0.45771079899098055<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "0.01",
          "0.07",
          "0.10",
          "0.17",
          "0.19",
          "0.46"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.012425799583815931,
          0.0731150244069925,
          0.09900368078284365,
          0.16536625562969337,
          0.1923784406056739,
          0.45771079899098055
         ],
         "y": [
          "l2_leaf_reg",
          "random_strength",
          "depth",
          "min_data_in_leaf",
          "bagging_temperature",
          "learning_rate"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = optuna.visualization.plot_optimization_history(study)\n",
    "fig1.show()\n",
    "    \n",
    "fig2 = optuna.visualization.plot_param_importances(study)\n",
    "fig2.show()\n",
    "    \n",
    "# Plot feature importance from the final model\n",
    "# Get feature importance values\n",
    "feature_importance = final_model.get_feature_importance()\n",
    "\n",
    "# Get sorted indices\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 7))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx])\n",
    "\n",
    "# Use feature names if X is a DataFrame\n",
    "feature_names = X.columns if hasattr(X, 'columns') else np.array(range(X.shape[1]))\n",
    "plt.yticks(range(len(sorted_idx)), feature_names[sorted_idx])\n",
    "\n",
    "plt.title('CatBoost Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77739800",
   "metadata": {},
   "source": [
    "Check the [documentation](https://catboost.ai/en/docs/references/training-parameters/common) for hyperparameter tuning.\n",
    "\n",
    "With proper hyperparameter tuning, CatBoost can achieve better performance than its default settings. However, even without tuning, CatBoost’s default configuration often outperforms the default settings of XGBoost and LightGBM, particularly on datasets with categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff1eeb",
   "metadata": {},
   "source": [
    "###  When to Use **CatBoost** Over **XGBoost**\n",
    "\n",
    "- When your dataset is \"categorical-heavy**\n",
    "- **CatBoost** tends to perform well **out of the box** with minimal hyperparameter tuning, making it more user-friendly for quick experimentation or deployment  \n",
    "- CatBoost’s **GPU implementation** is optimized for handling categorical data efficiently, and can **outperform XGBoost** on datasets dominated by categorical variables  \n",
    "  > While both libraries support GPU acceleration, CatBoost's architecture is particularly well-suited for categorical-heavy tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39185a87",
   "metadata": {},
   "source": [
    "##  Handling Imbalanced Classification: XGBoost vs. LightGBM vs. CatBoost\n",
    "\n",
    "Imbalanced classification occurs when one class significantly outnumbers the other (e.g., fraud detection, disease diagnosis). Each boosting library offers tools to address this issue:\n",
    "\n",
    "\n",
    "**XGBoost**:\n",
    "\n",
    "- **Parameter**: `scale_pos_weight`\n",
    "  - Formula:  \n",
    "    $$\n",
    "    \\texttt{scale\\_pos\\_weight} = \\frac{\\text{Number of negative samples}}{\\text{Number of positive samples}}\n",
    "    $$\n",
    "  - Increases the gradient of the positive class during training.\n",
    "- **Additional Strategies**:\n",
    "  - Use custom `eval_metric` (e.g., `\"auc\"`, `\"aucpr\"`, or `\"logloss\"`)\n",
    "  - Apply early stopping on validation AUC\n",
    "\n",
    "\n",
    "\n",
    "**LightGBM**:\n",
    "\n",
    "- **Parameter**: `scale_pos_weight` (same as in XGBoost)\n",
    "- **Alternative**: `is_unbalance = TRUE`\n",
    "  - Automatically adjusts class weights based on distribution\n",
    "- **Other Tips**:\n",
    "  - Use `metric = \"auc\"` or `\"binary_logloss\"` for better guidance during training\n",
    "  - Resampling techniques also compatible\n",
    "\n",
    "\n",
    "\n",
    "**CatBoost**:\n",
    "\n",
    "- **Parameter**: `class_weights`\n",
    "  - Accepts a numeric vector (e.g., `class_weights = c(1, 5)` for [negative, positive])\n",
    "  - Directly modifies the loss function to emphasize minority class\n",
    "- **Advantages**:\n",
    "  - More flexible than `scale_pos_weight`\n",
    "  - Works well with default settings\n",
    "- **Other Tips**:\n",
    "  - Use `loss_function = \"Logloss\"` and `eval_metric = \"AUC\"` for binary classification\n",
    "\n",
    "\n",
    "\n",
    "Below is the summary table:\n",
    "\n",
    "| Library   | Imbalance Handling Parameter          | Default Support        | Recommended Metric         |\n",
    "|-----------|----------------------------------------|-------------------------|-----------------------------|\n",
    "| XGBoost   | `scale_pos_weight`                    | No                      | `auc`, `aucpr`              |\n",
    "| LightGBM  | `scale_pos_weight`, `is_unbalance`    | Yes (with flag)         | `auc`, `binary_logloss`     |\n",
    "| CatBoost  | `class_weights`                       | Yes                     | `Logloss`, `AUC`            |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bedc733",
   "metadata": {},
   "source": [
    "##  Summary: XGBoost vs. LightGBM vs. CatBoost\n",
    "\n",
    "Gradient boosting is a powerful ensemble technique, and XGBoost, LightGBM, and CatBoost are three of its most widely used implementations. Each has unique strengths and is well-suited to different use cases.\n",
    "\n",
    "**XGBoost**: \n",
    "\n",
    "- **Strengths**: Robust, well-documented, strong performance on structured/tabular data  \n",
    "- **Split Finding**: Level-wise tree growth  \n",
    "- **Regularization**: Explicit L1 and L2 regularization  \n",
    "- **Flexibility**: Highly customizable with many hyperparameters  \n",
    "- **Best for**: General-purpose tabular data, especially when you have time to tune parameters\n",
    "\n",
    "**LightGBM**: \n",
    "\n",
    "- **Strengths**: Fast training, low memory usage, excellent scalability  \n",
    "- **Split Finding**: Leaf-wise tree growth with depth control  \n",
    "- **Binning**: Uses histogram-based algorithm with `max_bin` to speed up training  \n",
    "- **Best for**: Large-scale datasets, high-dimensional features, and when training speed matters\n",
    "\n",
    "**CatBoost**:\n",
    "\n",
    "- **Strengths**: Handles categorical features natively, works well with minimal tuning  \n",
    "- **Boosting Innovation**: Uses *ordered boosting* to prevent prediction shift  \n",
    "- **Categorical Encoding**: Uses target-based encoding internally  \n",
    "- **Best for**: Datasets with many categorical variables or limited time for tuning\n",
    "\n",
    "\n",
    "\n",
    "**Final Thoughts**\n",
    "\n",
    "All three libraries are powerful and battle-tested. Here's a rough guideline:\n",
    "\n",
    "- **Use XGBoost** if you want control, flexibility, and a well-documented standard\n",
    "- **Use LightGBM** when training speed and large data scalability are your top priorities\n",
    "- **Use CatBoost** when working with many categorical features or seeking strong baseline results with minimal tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd7460",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [LightGBM Paper (Original NIPS 2017)](https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf)\n",
    "* [LightGBM Official Website](https://lightgbm.readthedocs.io/)\n",
    "* [CatBoost Paper (arXiv)](https://arxiv.org/abs/1810.11363)\n",
    "* [CatBoost Official Website](https://catboost.ai/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
