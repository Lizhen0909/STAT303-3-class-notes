<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Science III with python (Class notes) - 13&nbsp; LightGBM and CatBoost</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Lec10_Ensemble.html" rel="next">
<link href="./Lec9_XGBoost.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Lec3_RegressionTrees.html">Tree based models</a></li><li class="breadcrumb-item"><a href="./Lec11_More boosting models.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">LightGBM and CatBoost</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./NU_Stat_logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science III with python (Class notes)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Sklearn; Bias &amp; Variance; KNN</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./L1_Scikit-learn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to scikit-learn</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Bias_variance_code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias-variance tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./KNN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">KNN</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Hyperparameter tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Hyperparameter tuning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Tree based models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec3_RegressionTrees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regression trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec4_ClassificationTree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Classification trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec4_Bagging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bagging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Bagging (OOB vs K-fold cross-validation).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Bagging (addendum)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec6_RandomForest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Random Forest</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec7_AdaBoost.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Adaptive Boosting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec8_Gradient_Boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Gradient Boosting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec9_XGBoost.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">XGBoost</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec11_More boosting models.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">LightGBM and CatBoost</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec10_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Ensemble modeling</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Assignments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Assignment 1</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment 2 questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Assignment 2 (Section 21)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment 3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Assignment 3 (Sections 21 &amp; 22)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./HomeworkAssignment4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Assignment 4</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Stratified splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Stratified splitting (classification problem)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Parallel_processing_Bonus_Questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Parallel processing bonus Q</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Miscellaneous questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Miscellaneous questions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Datasets, assignment and project files</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#lightgbm" id="toc-lightgbm" class="nav-link active" data-scroll-target="#lightgbm"><span class="header-section-number">13.1</span> LightGBM</a>
  <ul>
  <li><a href="#lightgbm-for-regression" id="toc-lightgbm-for-regression" class="nav-link" data-scroll-target="#lightgbm-for-regression"><span class="header-section-number">13.1.1</span> LightGBM for regression</a></li>
  <li><a href="#lightgbm-vs-xgboost" id="toc-lightgbm-vs-xgboost" class="nav-link" data-scroll-target="#lightgbm-vs-xgboost"><span class="header-section-number">13.1.2</span> LightGBM vs XGBoost</a></li>
  </ul></li>
  <li><a href="#catboost" id="toc-catboost" class="nav-link" data-scroll-target="#catboost"><span class="header-section-number">13.2</span> CatBoost</a>
  <ul>
  <li><a href="#catboost-for-regression" id="toc-catboost-for-regression" class="nav-link" data-scroll-target="#catboost-for-regression"><span class="header-section-number">13.2.1</span> CatBoost for regression</a></li>
  <li><a href="#catboost-vs-xgboost" id="toc-catboost-vs-xgboost" class="nav-link" data-scroll-target="#catboost-vs-xgboost"><span class="header-section-number">13.2.2</span> CatBoost vs XGBoost</a></li>
  <li><a href="#tuning-catboostregressor" id="toc-tuning-catboostregressor" class="nav-link" data-scroll-target="#tuning-catboostregressor"><span class="header-section-number">13.2.3</span> Tuning <code>CatBoostRegressor</code></a></li>
  <li><a href="#tuning-tips" id="toc-tuning-tips" class="nav-link" data-scroll-target="#tuning-tips"><span class="header-section-number">13.2.4</span> Tuning Tips</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Lec3_RegressionTrees.html">Tree based models</a></li><li class="breadcrumb-item"><a href="./Lec11_More boosting models.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">LightGBM and CatBoost</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">LightGBM and CatBoost</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="f819f995" class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score,train_test_split, KFold, cross_val_predict</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve, accuracy_score, <span class="op">\</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>recall_score, precision_score, confusion_matrix</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor,DecisionTreeClassifier</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV, ParameterGrid, StratifiedKFold, RandomizedSearchCV</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier, GradientBoostingRegressor,GradientBoostingClassifier, BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression,LogisticRegression, LassoCV, RidgeCV, ElasticNetCV</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools <span class="im">as</span> it</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time <span class="im">as</span> time</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lightgbm <span class="im">import</span> LGBMRegressor</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> catboost <span class="im">import</span> CatBoostRegressor</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt <span class="im">import</span> BayesSearchCV</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt.space <span class="im">import</span> Real, Categorical, Integer</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt.plots <span class="im">import</span> plot_objective, plot_histogram, plot_convergence</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython <span class="im">import</span> display</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll continue to use the same datasets that we have been using throughout the course.</p>
<div id="a9036ef3" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Using the same datasets as used for linear regression in STAT303-2, </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#so that we can compare the non-linear models with linear regression</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>trainf <span class="op">=</span> pd.read_csv(<span class="st">'./Datasets/Car_features_train.csv'</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>trainp <span class="op">=</span> pd.read_csv(<span class="st">'./Datasets/Car_prices_train.csv'</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>testf <span class="op">=</span> pd.read_csv(<span class="st">'./Datasets/Car_features_test.csv'</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>testp <span class="op">=</span> pd.read_csv(<span class="st">'./Datasets/Car_prices_test.csv'</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.merge(trainf,trainp)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.merge(testf,testp)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>train.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">carID</th>
<th data-quarto-table-cell-role="th">brand</th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">transmission</th>
<th data-quarto-table-cell-role="th">mileage</th>
<th data-quarto-table-cell-role="th">fuelType</th>
<th data-quarto-table-cell-role="th">tax</th>
<th data-quarto-table-cell-role="th">mpg</th>
<th data-quarto-table-cell-role="th">engineSize</th>
<th data-quarto-table-cell-role="th">price</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>18473</td>
<td>bmw</td>
<td>6 Series</td>
<td>2020</td>
<td>Semi-Auto</td>
<td>11</td>
<td>Diesel</td>
<td>145</td>
<td>53.3282</td>
<td>3.0</td>
<td>37980</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>15064</td>
<td>bmw</td>
<td>6 Series</td>
<td>2019</td>
<td>Semi-Auto</td>
<td>10813</td>
<td>Diesel</td>
<td>145</td>
<td>53.0430</td>
<td>3.0</td>
<td>33980</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>18268</td>
<td>bmw</td>
<td>6 Series</td>
<td>2020</td>
<td>Semi-Auto</td>
<td>6</td>
<td>Diesel</td>
<td>145</td>
<td>53.4379</td>
<td>3.0</td>
<td>36850</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>18480</td>
<td>bmw</td>
<td>6 Series</td>
<td>2017</td>
<td>Semi-Auto</td>
<td>18895</td>
<td>Diesel</td>
<td>145</td>
<td>51.5140</td>
<td>3.0</td>
<td>25998</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>18492</td>
<td>bmw</td>
<td>6 Series</td>
<td>2015</td>
<td>Automatic</td>
<td>62953</td>
<td>Diesel</td>
<td>160</td>
<td>51.4903</td>
<td>3.0</td>
<td>18990</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="db6b5f99" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> train[[<span class="st">'mileage'</span>,<span class="st">'mpg'</span>,<span class="st">'year'</span>,<span class="st">'engineSize'</span>]]</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>Xtest <span class="op">=</span> test[[<span class="st">'mileage'</span>,<span class="st">'mpg'</span>,<span class="st">'year'</span>,<span class="st">'engineSize'</span>]]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> train[<span class="st">'price'</span>]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>ytest <span class="op">=</span> test[<span class="st">'price'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="lightgbm" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="lightgbm"><span class="header-section-number">13.1</span> LightGBM</h2>
<p>LightGBM is a gradient boosting decision tree algorithm developed by Microsoft in 2017. LightGBM outperforms XGBoost in terms of compuational speed, and provides comparable accuracy in general. The following two key features in LightGBM that make it faster than XGBoost:</p>
<p><strong>1. Gradient-based One-Side Sampling</strong> (GOSS): Recall, in gradient boosting, we fit trees on the gradient of the loss function <em>(refer the gradient boosting algorithm in section 10.10.2 of the book, <a href="https://hastie.su.domains/ElemStatLearn/">Elements of Statistical Learning</a>):</em></p>
<p><span class="math display">\[r_m = -\bigg[ \frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}  \bigg]_{f = f_{m-1}}. \]</span></p>
<p>Observations that correspond to relatively larger gradients contribute more to minimizing the loss function as compared to observations with smaller gradients. The algorithm down-samples the observations with small gradients, while selecting all the observations with large gradients. As observations with large gradients contribute the most to the reduction in loss function when considering a split, the accuracy of loss reduction estimate is maintained even with a reduced sample size. This leads to similar performance in terms of prediction accuracy while reducing computation speed due to reduction in sample size to fit trees.</p>
<p><strong>2. Exclusive feature bundling</strong> (EFB): This is useful when there are a lot of predictors, but the predictor space is sparse, i.e., most of the values are zero for several predictors, and the predictors rarely take non-zero values simultaneously. This can typically happen in case of a lot of dummy variables in the data. In such a case, the predictors are bundled to create a single predictor.</p>
<p>In the example below you can see that feature1 and feature2 are mutually exclusive. In order to achieve non overlapping buckets we add bundle size of feature1 to feature2. This makes sure that non zero data points of bundled features (feature1 and feature2) reside in different buckets. In feature_bundle buckets 1 to 4 contains non zero instances of feature1 and buckets 5,6 contain non zero instances of feature2 <em>(<a href="https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e">Reference</a>)</em>.</p>
<table class="table">
<thead>
<tr class="header">
<th>feature1</th>
<th>feature2</th>
<th>feature_bundle</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>2</td>
<td>6</td>
</tr>
<tr class="even">
<td>0</td>
<td>1</td>
<td>5</td>
</tr>
<tr class="odd">
<td>0</td>
<td>2</td>
<td>6</td>
</tr>
<tr class="even">
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0</td>
<td>2</td>
</tr>
<tr class="even">
<td>3</td>
<td>0</td>
<td>3</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0</td>
<td>4</td>
</tr>
</tbody>
</table>
<p>Read the <a href="https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf">LightGBM paper</a> for more details.</p>
<section id="lightgbm-for-regression" class="level3" data-number="13.1.1">
<h3 data-number="13.1.1" class="anchored" data-anchor-id="lightgbm-for-regression"><span class="header-section-number">13.1.1</span> LightGBM for regression</h3>
<p>Let us tune a lightGBM model for regression for our problem of predicting car price. We’ll use the function <a href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html"><code>LGBMRegressor</code></a>. For classification problems, <a href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html"><code>LGBMClassifier</code></a> can be used. Note that we are using the GOSS algorithm to downsample observations with smaller gradients.</p>
<div id="4787ccf3" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#K-fold cross validation to find optimal parameters for LightGBM regressor</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'num_leaves'</span>: [<span class="dv">20</span>, <span class="dv">31</span>, <span class="dv">40</span>],</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>              <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>],</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>               <span class="st">'reg_lambda'</span>:[<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>                <span class="st">'n_estimators'</span>:[<span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>],</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>                <span class="st">'reg_alpha'</span>: [<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">'subsample'</span>: [<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>],</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">'colsample_bytree'</span>: [<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>]}</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>,shuffle<span class="op">=</span><span class="va">True</span>,random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>optimal_params <span class="op">=</span> RandomizedSearchCV(estimator<span class="op">=</span>LGBMRegressor(boosting_type <span class="op">=</span> <span class="st">'goss'</span>),                                                       </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>                             param_distributions <span class="op">=</span> param_grid, n_iter <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>                             verbose <span class="op">=</span> <span class="dv">1</span>, scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>,</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>                             n_jobs<span class="op">=-</span><span class="dv">1</span>,random_state<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>                             cv <span class="op">=</span> cv)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>optimal_params.fit(X,y)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal parameter values ="</span>, optimal_params.best_params_)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal cross validation RMSE = "</span>,optimal_params.best_score_)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Time taken = "</span>, <span class="bu">round</span>((time.time()<span class="op">-</span>start_time)<span class="op">/</span><span class="dv">60</span>), <span class="st">" minutes"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 200 candidates, totalling 1000 fits
Optimal parameter values = {'subsample': 1.0, 'reg_lambda': 10, 'reg_alpha': 0, 'num_leaves': 20, 'n_estimators': 1000, 'learning_rate': 0.1, 'colsample_bytree': 1.0}
Optimal cross validation R-squared =  -5670.309021679375
Time taken =  1  minutes</code></pre>
</div>
</div>
<div id="fabd5eec" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#RMSE based on the optimal parameter values of a LighGBM Regressor model</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>np.sqrt(mean_squared_error(optimal_params.best_estimator_.predict(Xtest),ytest))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>5614.374498193448</code></pre>
</div>
</div>
<p>Note that downsampling of small-gradient observations leads to faster execution time, but potentially by compromising some accuracy. We can expect to improve the accuracy by increasing the <code>top_rate</code> or the <code>other_rate</code> hyperparameters, but at an increased computational cost. In the cross-validation below, we have increased the <code>top_rate</code> to 0.5 from the default value of 0.2.</p>
<div id="35f60979" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#K-fold cross validation to find optimal parameters for LightGBM regressor</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'num_leaves'</span>: [<span class="dv">20</span>, <span class="dv">31</span>, <span class="dv">40</span>],</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>              <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>],</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>               <span class="st">'reg_lambda'</span>:[<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                <span class="st">'n_estimators'</span>:[<span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>],</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                <span class="st">'reg_alpha'</span>: [<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">'subsample'</span>: [<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>],</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">'colsample_bytree'</span>: [<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>]}</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>,shuffle<span class="op">=</span><span class="va">True</span>,random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>optimal_params <span class="op">=</span> RandomizedSearchCV(estimator<span class="op">=</span>LGBMRegressor(boosting_type <span class="op">=</span> <span class="st">'goss'</span>, top_rate <span class="op">=</span> <span class="fl">0.5</span>),                                                       </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>                             param_distributions <span class="op">=</span> param_grid, n_iter <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>                             verbose <span class="op">=</span> <span class="dv">1</span>, scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>,</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>                             n_jobs<span class="op">=-</span><span class="dv">1</span>,random_state<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>                             cv <span class="op">=</span> cv)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>optimal_params.fit(X,y)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal parameter values ="</span>, optimal_params.best_params_)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal cross validation RMSE = "</span>,optimal_params.best_score_)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Time taken = "</span>, <span class="bu">round</span>((time.time()<span class="op">-</span>start_time)<span class="op">/</span><span class="dv">60</span>), <span class="st">" minutes"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 200 candidates, totalling 1000 fits
Optimal parameter values = {'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha': 100, 'num_leaves': 31, 'n_estimators': 500, 'learning_rate': 0.05, 'colsample_bytree': 1.0}
Optimal cross validation R-squared =  -5436.062435616846
Time taken =  1  minutes</code></pre>
</div>
</div>
<div id="b8f16539" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#RMSE based on the optimal parameter values of a LighGBM Regressor model</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>np.sqrt(mean_squared_error(optimal_params.best_estimator_.predict(Xtest),ytest))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>5355.964600884197</code></pre>
</div>
</div>
<p>Note that the cross-validated RMSE has reduced. However, this is at an increased computational expense. In the simulations below, we compare the time taken to train models with increasing values of the <code>top_rate</code> hyperparameter.</p>
<div id="556a7536" class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>time_list <span class="op">=</span> []</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LGBMRegressor(boosting_type <span class="op">=</span> <span class="st">'goss'</span>, top_rate <span class="op">=</span> <span class="fl">0.2</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>).fit(X, y)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    time_list.append(time.time()<span class="op">-</span>start_time)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="7ac6d4d5" class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>time_list2 <span class="op">=</span> []</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LGBMRegressor(boosting_type <span class="op">=</span> <span class="st">'goss'</span>, top_rate <span class="op">=</span> <span class="fl">0.5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>).fit(X, y)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    time_list2.append(time.time()<span class="op">-</span>start_time)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="e1e67d22" class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>time_list3 <span class="op">=</span> []</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LGBMRegressor(boosting_type <span class="op">=</span> <span class="st">'goss'</span>, top_rate <span class="op">=</span> <span class="fl">0.8</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>).fit(X, y)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    time_list3.append(time.time()<span class="op">-</span>start_time)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="4f5bd8ba" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.boxplot([time_list, time_list2, time_list3])<span class="op">;</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels([<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>])<span class="op">;</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Time'</span>)<span class="op">;</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'top_rate'</span>)<span class="op">;</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation <span class="op">=</span> <span class="dv">45</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lec11_More boosting models_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="lightgbm-vs-xgboost" class="level3" data-number="13.1.2">
<h3 data-number="13.1.2" class="anchored" data-anchor-id="lightgbm-vs-xgboost"><span class="header-section-number">13.1.2</span> LightGBM vs XGBoost</h3>
<p>LightGBM model took 2 minutes for a random search with 1000 fits as compared to 7 minutes for an XGBoost model with 1000 fits on the same data (as shown below). In terms of prediction accuracy, we observe that the accuracy of LightGBM on test <em>(unseen)</em> data is comparable to that of XGBoost.</p>
<div id="336194fc" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">#K-fold cross validation to find optimal parameters for XGBoost</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'max_depth'</span>: [<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">8</span>],</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>              <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>],</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>               <span class="st">'reg_lambda'</span>:[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">10</span>],</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>                <span class="st">'n_estimators'</span>:[<span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>],</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>                <span class="st">'gamma'</span>: [<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">'subsample'</span>: [<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>],</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">'colsample_bytree'</span>: [<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>]}</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>,shuffle<span class="op">=</span><span class="va">True</span>,random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>optimal_params <span class="op">=</span> RandomizedSearchCV(estimator<span class="op">=</span>xgb.XGBRegressor(),                                                       </span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>                             param_distributions <span class="op">=</span> param_grid, n_iter <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>                             verbose <span class="op">=</span> <span class="dv">1</span>, scoring <span class="op">=</span> <span class="st">'neg_root_mean_squared_error'</span>,</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>                             n_jobs<span class="op">=-</span><span class="dv">1</span>,random_state <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>                             cv <span class="op">=</span> cv)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>optimal_params.fit(X,y)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal parameter values ="</span>, optimal_params.best_params_)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal cross validation R-squared = "</span>,optimal_params.best_score_)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Time taken = "</span>, <span class="bu">round</span>((time.time()<span class="op">-</span>start_time)<span class="op">/</span><span class="dv">60</span>), <span class="st">" minutes"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 200 candidates, totalling 1000 fits
Optimal parameter values = {'subsample': 0.75, 'reg_lambda': 1, 'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.01, 'gamma': 100, 'colsample_bytree': 1.0}
Optimal cross validation R-squared =  -5178.8689594137295
Time taken =  7  minutes</code></pre>
</div>
</div>
<div id="7ebe7659" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">#RMSE based on the optimal parameter values</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>np.sqrt(mean_squared_error(optimal_params.best_estimator_.predict(Xtest),ytest))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>5420.661056398766</code></pre>
</div>
</div>
</section>
</section>
<section id="catboost" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="catboost"><span class="header-section-number">13.2</span> CatBoost</h2>
<p>CatBoost is a gradient boosting algorithm developed by Yandex <em>(Russian Google)</em> in 2017. Like LightGBM, CatBoost is also faster than XGBoost in training. However, unlike LightGBM, the authors have claimed that it outperforms both LightGBM and XGBoost in terms of prediction accuracy as well.</p>
<p>The key feature of CatBoost that address the issue with the gradient boosting procedure is the idea of ordered boosting. Classic boosting algorithms are prone to overfitting on small/noisy datasets due to a problem known as prediction shift. Recall, in gradient boosting, we fit trees on the gradient of the loss function <em>(refer the gradient boosting algorithm in section 10.10.2 of the book, <a href="https://hastie.su.domains/ElemStatLearn/">Elements of Statistical Learning</a>):</em></p>
<p><span class="math display">\[r_m = -\bigg[ \frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}  \bigg]_{f = f_{m-1}}. \]</span></p>
<p>When calculating the gradient estimate of an observation, these algorithms use the same observations that the model was built with, thus having no chances of experiencing unseen data. CatBoost, on the other hand, uses the concept of ordered boosting, a permutation-driven approach to train model on a subset of data while calculating residuals on another subset, thus preventing “target leakage” and overfitting. The residuals of an observation are computed based on a model developed on the previous observations, where the observations are randomly shuffled at each iteration, i.e., for each tree.</p>
<p>Thus, the gradient of the loss function is based on test <em>(unseen)</em> data, instead of the data on which the model has been trained, which improves the generalizability of the model, and avoids overfitting on train data.</p>
<p>The authors have also shown that CatBoost performs better than XGBoost and LightGBM without tuning, i.e., with default hyperparameter settings.</p>
<p>Read the <a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf">CatBoost paper</a> for more details.</p>
<p>Here is a good <a href="https://neptune.ai/blog/when-to-choose-catboost-over-xgboost-or-lightgbm">blog</a> listing the key features of CatBoost.</p>
<section id="catboost-for-regression" class="level3" data-number="13.2.1">
<h3 data-number="13.2.1" class="anchored" data-anchor-id="catboost-for-regression"><span class="header-section-number">13.2.1</span> CatBoost for regression</h3>
<p>We’ll use the function <a href="https://catboost.ai/en/docs/concepts/python-reference_catboostregressor">CatBoostRegressor</a> for regression. For classification problems <a href="https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier">CatBoostClassifier</a> can be used.</p>
<p>Let us check the performance of <code>CatBoostRegressor()</code> without tuning, i.e., with default hyperparameter settings.</p>
<div id="17cf8748" class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>model_cat <span class="op">=</span> CatBoostRegressor(verbose<span class="op">=</span><span class="dv">0</span>).fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b545b6b9" class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>,shuffle<span class="op">=</span><span class="va">True</span>,random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>np.mean(<span class="op">-</span>cross_val_score(CatBoostRegressor(verbose<span class="op">=</span><span class="dv">0</span>), X, y, cv <span class="op">=</span> cv, n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>, </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>                scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="103">
<pre><code>5035.972129299527</code></pre>
</div>
</div>
<div id="ce4b9894" class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>np.sqrt(mean_squared_error(model_cat.predict(Xtest),ytest))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>5288.82153844634</code></pre>
</div>
</div>
<p>Even with default hyperparameter settings, CatBoost has outperformed both XGBoost and LightGBM in terms of cross-validated RMSE, and RMSE on test data for our example of predicting car prices.</p>
</section>
<section id="catboost-vs-xgboost" class="level3" data-number="13.2.2">
<h3 data-number="13.2.2" class="anchored" data-anchor-id="catboost-vs-xgboost"><span class="header-section-number">13.2.2</span> CatBoost vs XGBoost</h3>
<p>Let us see the performance of XGBoost with default hyperparameter settings.</p>
<div id="a4cfa0f1" class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>model_xgb <span class="op">=</span> xgb.XGBRFRegressor().fit(X, y)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>np.mean(<span class="op">-</span>cross_val_score(xgb.XGBRFRegressor(), X, y, cv <span class="op">=</span> cv, n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>, </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>                scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="106">
<pre><code>6273.043859096154</code></pre>
</div>
</div>
<div id="6fe05d8f" class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>np.sqrt(mean_squared_error(model_xgb.predict(Xtest),ytest))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="107">
<pre><code>6821.745153860935</code></pre>
</div>
</div>
<p>XGBoost performance deteriorates showing that hyperparameter tuning is more important in XGBoost.</p>
<p>Let us see the performance of LightGBM with default hyperparameter settings.</p>
<div id="9031b444" class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>model_lgbm <span class="op">=</span> LGBMRegressor().fit(X, y)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>np.mean(<span class="op">-</span>cross_val_score(LGBMRegressor(), X, y, cv <span class="op">=</span> cv, n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>, </span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>                scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="112">
<pre><code>5562.149251902867</code></pre>
</div>
</div>
<div id="799f05e1" class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>np.sqrt(mean_squared_error(model_lgbm.predict(Xtest),ytest))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<pre><code>5494.0777923513515</code></pre>
</div>
</div>
<p>LightGBM’s default hyperparameter settings also seem to be more robust as compared to those of XGBoost.</p>
</section>
<section id="tuning-catboostregressor" class="level3" data-number="13.2.3">
<h3 data-number="13.2.3" class="anchored" data-anchor-id="tuning-catboostregressor"><span class="header-section-number">13.2.3</span> Tuning <code>CatBoostRegressor</code></h3>
<p>The CatBoost hyperparameters can be tuned just like the XGBoost hyperparameters. However, there is some difference in the hyperparameters of both the packages. For example, <code>reg_alpha</code> <em>(the L1 penalization on weights of leaves)</em> and <code>colsample_bytree</code> <em>(subsample ratio of columns when constructing each tree)</em> hyperparameters are not there in CatBoost.</p>
<div id="a6403528" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co">#K-fold cross validation to find optimal parameters for CatBoost regressor</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'max_depth'</span>: [<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">8</span>, <span class="dv">10</span>],</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>              <span class="st">'num_leaves'</span>: [<span class="dv">20</span>, <span class="dv">31</span>, <span class="dv">40</span>, <span class="dv">60</span>],</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>              <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>],</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>               <span class="st">'reg_lambda'</span>:[<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>                <span class="st">'n_estimators'</span>:[<span class="dv">500</span>, <span class="dv">1000</span>, <span class="dv">1500</span>],</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">'subsample'</span>: [<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>],</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>             <span class="st">'colsample_bylevel'</span>: [<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>]}</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>,shuffle<span class="op">=</span><span class="va">True</span>,random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>optimal_params <span class="op">=</span> RandomizedSearchCV(estimator<span class="op">=</span>CatBoostRegressor(random_state<span class="op">=</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>                            grow_policy<span class="op">=</span><span class="st">'Lossguide'</span>),                                                       </span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>                             param_distributions <span class="op">=</span> param_grid, n_iter <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>                             verbose <span class="op">=</span> <span class="dv">1</span>,random_state <span class="op">=</span> <span class="dv">1</span>, scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>,</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>                             n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>                             cv <span class="op">=</span> cv)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>optimal_params.fit(X,y)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal parameter values ="</span>, optimal_params.best_params_)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal cross validation RMSE = "</span>,optimal_params.best_score_)</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Time taken = "</span>, <span class="bu">round</span>((time.time()<span class="op">-</span>start_time)<span class="op">/</span><span class="dv">60</span>), <span class="st">" minutes"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 200 candidates, totalling 1000 fits
Optimal parameter values = {'subsample': 0.5, 'reg_lambda': 0, 'num_leaves': 40, 'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bylevel': 0.75}
Optimal cross validation RMSE =  -4993.129407810791
Time taken =  23  minutes</code></pre>
</div>
</div>
<div id="daa32e2f" class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">#RMSE based on the optimal parameter values</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>np.sqrt(mean_squared_error(optimal_params.best_estimator_.predict(Xtest),ytest))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="122">
<pre><code>5249.434282204398</code></pre>
</div>
</div>
<p>It takes 2 minutes to tune CatBoost, which is higher than LightGBM and lesser than XGBoost. CatBoost falls in between LightGBM and XGBoost in terms of speed. However, it is likely to be more accurate than XGBoost and LighGBM, and likely to require lesser tuning as compared to XGBoost.</p>
<div id="4c36db2a" class="cell" data-execution_count="126">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CatBoostRegressor(grow_policy<span class="op">=</span><span class="st">'Lossguide'</span>) </span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> {<span class="st">'num_leaves'</span>: Integer(<span class="dv">4</span>, <span class="dv">64</span>),</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>              <span class="st">'learning_rate'</span>: Real(<span class="fl">0.0001</span>, <span class="fl">1.0</span>),</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>               <span class="st">'reg_lambda'</span>:Real(<span class="dv">0</span>, <span class="fl">1e4</span>),</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>                <span class="st">'n_estimators'</span>:Integer(<span class="dv">2</span>, <span class="dv">2000</span>),</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>                <span class="st">'subsample'</span>: Real(<span class="fl">0.1</span>,<span class="fl">1.0</span>),</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">'colsample_bylevel'</span>: Real(<span class="fl">0.1</span>, <span class="fl">1.0</span>)}</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>kfold <span class="op">=</span> KFold(n_splits <span class="op">=</span> <span class="dv">5</span>, shuffle <span class="op">=</span> <span class="va">True</span>, random_state <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>gcv <span class="op">=</span> BayesSearchCV(model, search_spaces <span class="op">=</span> grid, cv <span class="op">=</span> kfold, n_iter <span class="op">=</span> <span class="dv">200</span>, random_state <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>                         scoring <span class="op">=</span> <span class="st">'neg_root_mean_squared_error'</span>, n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>paras <span class="op">=</span> <span class="bu">list</span>(gcv.search_spaces.keys())</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>paras.sort()</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> monitor(optim_result):</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    cv_values <span class="op">=</span> pd.Series(optim_result[<span class="st">'func_vals'</span>]).cummin()</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>    display.clear_output(wait <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>    min_ind <span class="op">=</span> pd.Series(optim_result[<span class="st">'func_vals'</span>]).argmin()</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(paras, <span class="st">"="</span>, optim_result[<span class="st">'x_iters'</span>][min_ind], pd.Series(optim_result[<span class="st">'func_vals'</span>]).<span class="bu">min</span>())</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>    sns.lineplot(cv_values)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>gcv.fit(X, y, callback <span class="op">=</span> monitor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['colsample_bylevel', 'learning_rate', 'n_estimators', 'num_leaves', 'reg_lambda', 'subsample'] = [0.3745508446405472, 0.1000958551500621, 2000, 11, 0.0, 0.3877212027881348] 5132.537839676808
0:  learn: 15586.6547227    total: 7.88ms   remaining: 15.8s
1:  learn: 14594.4802869    total: 16.4ms   remaining: 16.4s
2:  learn: 14594.4802869    total: 17.2ms   remaining: 11.5s
3:  learn: 13743.4503923    total: 20.1ms   remaining: 10s
4:  learn: 13266.2414822    total: 24.9ms   remaining: 9.94s
5:  learn: 12498.3369959    total: 28.1ms   remaining: 9.33s
6:  learn: 12129.2561319    total: 30.3ms   remaining: 8.63s
7:  learn: 11505.6411010    total: 32.3ms   remaining: 8.03s
8:  learn: 11505.6411010    total: 32.7ms   remaining: 7.23s
9:  learn: 11021.2139091    total: 34.6ms   remaining: 6.89s
10: learn: 10442.9678139    total: 37ms remaining: 6.69s
11: learn: 9947.6741148 total: 39.3ms   remaining: 6.51s
12: learn: 9619.4595819 total: 41ms remaining: 6.27s
13: learn: 9259.8855899 total: 42.9ms   remaining: 6.08s
14: learn: 9259.8855899 total: 43.4ms   remaining: 5.74s
15: learn: 8939.7710703 total: 45.3ms   remaining: 5.62s
16: learn: 8711.0852634 total: 47.3ms   remaining: 5.52s
17: learn: 8604.6071027 total: 49.1ms   remaining: 5.41s
18: learn: 8438.7728051 total: 50.8ms   remaining: 5.3s
19: learn: 8274.7829809 total: 53.2ms   remaining: 5.26s
20: learn: 8042.3020027 total: 55.9ms   remaining: 5.27s
21: learn: 7876.9560283 total: 57.5ms   remaining: 5.17s
22: learn: 7710.6772232 total: 59.5ms   remaining: 5.12s
23: learn: 7571.7455782 total: 61.1ms   remaining: 5.03s
24: learn: 7440.8874033 total: 63ms remaining: 4.98s
25: learn: 7316.5070355 total: 65ms remaining: 4.93s
26: learn: 7190.4998886 total: 66.8ms   remaining: 4.88s
27: learn: 7126.4859430 total: 68.2ms   remaining: 4.8s
28: learn: 7126.4859430 total: 68.6ms   remaining: 4.66s
29: learn: 7016.0377180 total: 70.1ms   remaining: 4.6s
30: learn: 7000.1845553 total: 70.7ms   remaining: 4.49s
31: learn: 6884.2153374 total: 72.3ms   remaining: 4.45s
32: learn: 6884.2153374 total: 72.7ms   remaining: 4.33s
33: learn: 6859.6936709 total: 74.3ms   remaining: 4.29s
34: learn: 6859.6936709 total: 74.7ms   remaining: 4.19s
35: learn: 6784.1411674 total: 76.4ms   remaining: 4.17s
36: learn: 6784.1411674 total: 76.9ms   remaining: 4.08s
37: learn: 6759.2775251 total: 77.8ms   remaining: 4.01s
38: learn: 6699.5901664 total: 79.7ms   remaining: 4.01s
39: learn: 6618.8189493 total: 81.6ms   remaining: 4s
40: learn: 6588.5585061 total: 83.2ms   remaining: 3.97s
41: learn: 6576.3802378 total: 84.1ms   remaining: 3.92s
42: learn: 6576.3802378 total: 84.5ms   remaining: 3.85s
43: learn: 6576.3802378 total: 84.9ms   remaining: 3.77s
44: learn: 6576.3802378 total: 85.3ms   remaining: 3.71s
45: learn: 6554.9758286 total: 86.5ms   remaining: 3.67s
46: learn: 6525.5802913 total: 88.1ms   remaining: 3.66s
47: learn: 6466.1035176 total: 89.1ms   remaining: 3.62s
48: learn: 6436.3855462 total: 90.1ms   remaining: 3.59s
49: learn: 6425.6798093 total: 91.3ms   remaining: 3.56s
50: learn: 6415.6723682 total: 92.3ms   remaining: 3.53s
51: learn: 6370.9376356 total: 95ms remaining: 3.56s
52: learn: 6362.2269483 total: 96.1ms   remaining: 3.53s
53: learn: 6270.8381417 total: 97.5ms   remaining: 3.51s
54: learn: 6224.2584318 total: 98.8ms   remaining: 3.49s
55: learn: 6196.9126269 total: 100ms    remaining: 3.48s
56: learn: 6159.9795842 total: 102ms    remaining: 3.48s
57: learn: 6095.2640049 total: 104ms    remaining: 3.48s
58: learn: 6068.5568780 total: 105ms    remaining: 3.47s
59: learn: 6045.8539265 total: 107ms    remaining: 3.45s
60: learn: 6014.2089991 total: 108ms    remaining: 3.44s
61: learn: 6014.2089991 total: 109ms    remaining: 3.4s
62: learn: 5991.4276619 total: 110ms    remaining: 3.4s
63: learn: 5960.8755319 total: 112ms    remaining: 3.4s
64: learn: 5939.4519328 total: 114ms    remaining: 3.39s
65: learn: 5937.5977651 total: 114ms    remaining: 3.35s
66: learn: 5914.5991789 total: 116ms    remaining: 3.34s
67: learn: 5893.7012597 total: 117ms    remaining: 3.34s
68: learn: 5881.6048683 total: 119ms    remaining: 3.33s
69: learn: 5857.2384791 total: 121ms    remaining: 3.33s
70: learn: 5856.3744823 total: 121ms    remaining: 3.3s
71: learn: 5844.6720134 total: 123ms    remaining: 3.29s
72: learn: 5808.4057279 total: 125ms    remaining: 3.29s
73: learn: 5796.1301234 total: 126ms    remaining: 3.29s
74: learn: 5774.0161859 total: 128ms    remaining: 3.29s
75: learn: 5771.0218306 total: 129ms    remaining: 3.27s
76: learn: 5771.0218306 total: 129ms    remaining: 3.23s
77: learn: 5754.9516948 total: 131ms    remaining: 3.23s
78: learn: 5753.1841839 total: 132ms    remaining: 3.22s
79: learn: 5750.6624545 total: 134ms    remaining: 3.21s
80: learn: 5730.0398718 total: 136ms    remaining: 3.21s
81: learn: 5730.0398718 total: 136ms    remaining: 3.18s
82: learn: 5724.0710370 total: 138ms    remaining: 3.18s
83: learn: 5709.8421847 total: 139ms    remaining: 3.18s
84: learn: 5695.5072261 total: 141ms    remaining: 3.18s
85: learn: 5681.9956673 total: 143ms    remaining: 3.18s
86: learn: 5660.6016053 total: 145ms    remaining: 3.18s
87: learn: 5643.4061588 total: 147ms    remaining: 3.18s
88: learn: 5635.8928486 total: 148ms    remaining: 3.18s
89: learn: 5614.4729570 total: 149ms    remaining: 3.17s
90: learn: 5607.0906414 total: 151ms    remaining: 3.17s
91: learn: 5606.5748917 total: 151ms    remaining: 3.14s
92: learn: 5593.2044205 total: 153ms    remaining: 3.14s
93: learn: 5581.7260489 total: 154ms    remaining: 3.13s
94: learn: 5568.1299183 total: 156ms    remaining: 3.12s
95: learn: 5568.1299183 total: 156ms    remaining: 3.1s
96: learn: 5568.1299183 total: 157ms    remaining: 3.07s
97: learn: 5547.7453457 total: 158ms    remaining: 3.07s
98: learn: 5536.8538716 total: 160ms    remaining: 3.07s
99: learn: 5533.3512293 total: 162ms    remaining: 3.07s
100:    learn: 5531.6988001 total: 163ms    remaining: 3.06s
101:    learn: 5521.6827472 total: 164ms    remaining: 3.06s
102:    learn: 5512.1275625 total: 166ms    remaining: 3.05s
103:    learn: 5501.2710735 total: 167ms    remaining: 3.04s
104:    learn: 5483.1332945 total: 169ms    remaining: 3.04s
105:    learn: 5468.6932573 total: 170ms    remaining: 3.04s
106:    learn: 5468.6932573 total: 171ms    remaining: 3.02s
107:    learn: 5466.3196454 total: 172ms    remaining: 3.01s
108:    learn: 5466.3196454 total: 173ms    remaining: 2.99s
109:    learn: 5450.8555079 total: 174ms    remaining: 2.99s
110:    learn: 5450.5222911 total: 175ms    remaining: 2.98s
111:    learn: 5444.9363205 total: 176ms    remaining: 2.98s
112:    learn: 5434.7455852 total: 178ms    remaining: 2.98s
113:    learn: 5434.7455852 total: 179ms    remaining: 2.96s
114:    learn: 5433.5957428 total: 180ms    remaining: 2.94s
115:    learn: 5415.6597932 total: 181ms    remaining: 2.94s
116:    learn: 5415.6597932 total: 181ms    remaining: 2.92s
117:    learn: 5401.1008140 total: 183ms    remaining: 2.92s
118:    learn: 5391.8658503 total: 185ms    remaining: 2.92s
119:    learn: 5380.7927393 total: 186ms    remaining: 2.92s
120:    learn: 5365.7813769 total: 188ms    remaining: 2.92s
121:    learn: 5365.7813769 total: 188ms    remaining: 2.9s
122:    learn: 5354.1319730 total: 191ms    remaining: 2.91s
123:    learn: 5354.1319730 total: 191ms    remaining: 2.89s
124:    learn: 5342.7838789 total: 193ms    remaining: 2.89s
125:    learn: 5342.7838789 total: 193ms    remaining: 2.87s
126:    learn: 5327.8897475 total: 195ms    remaining: 2.88s
127:    learn: 5310.2941871 total: 197ms    remaining: 2.88s
128:    learn: 5306.9281433 total: 198ms    remaining: 2.87s
129:    learn: 5294.2149974 total: 200ms    remaining: 2.87s
130:    learn: 5291.2189448 total: 202ms    remaining: 2.88s
131:    learn: 5285.4079447 total: 203ms    remaining: 2.87s
132:    learn: 5276.3888293 total: 205ms    remaining: 2.88s
133:    learn: 5253.7966160 total: 206ms    remaining: 2.88s
134:    learn: 5242.4363346 total: 208ms    remaining: 2.87s
135:    learn: 5234.7617159 total: 210ms    remaining: 2.87s
136:    learn: 5230.7299511 total: 211ms    remaining: 2.87s
137:    learn: 5228.9494984 total: 212ms    remaining: 2.86s
138:    learn: 5220.7658686 total: 213ms    remaining: 2.86s
139:    learn: 5220.7658686 total: 214ms    remaining: 2.84s
140:    learn: 5220.3928102 total: 214ms    remaining: 2.83s
141:    learn: 5216.5111017 total: 216ms    remaining: 2.82s
142:    learn: 5213.4217372 total: 217ms    remaining: 2.82s
143:    learn: 5211.7652831 total: 218ms    remaining: 2.81s
144:    learn: 5193.0346592 total: 220ms    remaining: 2.81s
145:    learn: 5185.9448931 total: 221ms    remaining: 2.81s
146:    learn: 5182.0516815 total: 223ms    remaining: 2.81s
147:    learn: 5174.6829049 total: 225ms    remaining: 2.81s
148:    learn: 5174.6829049 total: 225ms    remaining: 2.79s
149:    learn: 5166.2911738 total: 226ms    remaining: 2.79s
150:    learn: 5159.8205215 total: 229ms    remaining: 2.8s
151:    learn: 5156.3185114 total: 230ms    remaining: 2.8s
152:    learn: 5156.3185114 total: 231ms    remaining: 2.78s
153:    learn: 5147.4051798 total: 232ms    remaining: 2.79s
154:    learn: 5147.4051798 total: 233ms    remaining: 2.77s
155:    learn: 5147.2407560 total: 234ms    remaining: 2.76s
156:    learn: 5146.4759564 total: 235ms    remaining: 2.75s
157:    learn: 5137.3716292 total: 236ms    remaining: 2.75s
158:    learn: 5121.4193275 total: 238ms    remaining: 2.75s
159:    learn: 5115.5018273 total: 239ms    remaining: 2.75s
160:    learn: 5115.5018273 total: 240ms    remaining: 2.74s
161:    learn: 5110.2699403 total: 242ms    remaining: 2.74s
162:    learn: 5109.9847477 total: 242ms    remaining: 2.73s
163:    learn: 5101.1792661 total: 244ms    remaining: 2.73s
164:    learn: 5094.6570018 total: 246ms    remaining: 2.73s
165:    learn: 5087.8982851 total: 247ms    remaining: 2.73s
166:    learn: 5075.5065415 total: 249ms    remaining: 2.73s
167:    learn: 5073.0923568 total: 250ms    remaining: 2.73s
168:    learn: 5059.3039228 total: 252ms    remaining: 2.73s
169:    learn: 5052.5169956 total: 254ms    remaining: 2.73s
170:    learn: 5048.6517154 total: 255ms    remaining: 2.73s
171:    learn: 5044.5398469 total: 257ms    remaining: 2.73s
172:    learn: 5042.2657789 total: 258ms    remaining: 2.73s
173:    learn: 5027.5698491 total: 260ms    remaining: 2.73s
174:    learn: 5018.2624339 total: 262ms    remaining: 2.73s
175:    learn: 5015.4207674 total: 263ms    remaining: 2.73s
176:    learn: 5004.4326005 total: 265ms    remaining: 2.73s
177:    learn: 5002.2042902 total: 267ms    remaining: 2.73s
178:    learn: 4991.5613784 total: 268ms    remaining: 2.73s
179:    learn: 4986.5919903 total: 270ms    remaining: 2.73s
180:    learn: 4983.2524252 total: 272ms    remaining: 2.73s
181:    learn: 4983.0495780 total: 273ms    remaining: 2.72s
182:    learn: 4972.3553519 total: 274ms    remaining: 2.72s
183:    learn: 4963.4540764 total: 276ms    remaining: 2.72s
184:    learn: 4959.3484378 total: 277ms    remaining: 2.72s
185:    learn: 4953.8290305 total: 278ms    remaining: 2.71s
186:    learn: 4948.8512443 total: 280ms    remaining: 2.71s
187:    learn: 4942.0173436 total: 282ms    remaining: 2.71s
188:    learn: 4935.2163749 total: 283ms    remaining: 2.71s
189:    learn: 4927.8308601 total: 285ms    remaining: 2.71s
190:    learn: 4922.7874103 total: 286ms    remaining: 2.71s
191:    learn: 4921.8930548 total: 287ms    remaining: 2.71s
192:    learn: 4921.8930548 total: 288ms    remaining: 2.69s
193:    learn: 4916.1740670 total: 289ms    remaining: 2.69s
194:    learn: 4910.6747951 total: 291ms    remaining: 2.69s
195:    learn: 4901.7995007 total: 292ms    remaining: 2.69s
196:    learn: 4901.7821460 total: 293ms    remaining: 2.68s
197:    learn: 4897.4539465 total: 295ms    remaining: 2.68s
198:    learn: 4894.9567494 total: 296ms    remaining: 2.68s
199:    learn: 4891.2982974 total: 298ms    remaining: 2.68s
200:    learn: 4886.1187451 total: 299ms    remaining: 2.67s
201:    learn: 4877.8813207 total: 301ms    remaining: 2.67s
202:    learn: 4875.4244708 total: 302ms    remaining: 2.67s
203:    learn: 4870.3140418 total: 304ms    remaining: 2.67s
204:    learn: 4870.3140418 total: 304ms    remaining: 2.66s
205:    learn: 4856.6381725 total: 306ms    remaining: 2.66s
206:    learn: 4856.6381725 total: 306ms    remaining: 2.65s
207:    learn: 4852.3702566 total: 307ms    remaining: 2.65s
208:    learn: 4851.5158620 total: 309ms    remaining: 2.64s
209:    learn: 4847.0222783 total: 310ms    remaining: 2.64s
210:    learn: 4842.1138566 total: 312ms    remaining: 2.64s
211:    learn: 4838.7635392 total: 313ms    remaining: 2.64s
212:    learn: 4826.0451253 total: 315ms    remaining: 2.64s
213:    learn: 4819.7240280 total: 316ms    remaining: 2.64s
214:    learn: 4811.2169173 total: 318ms    remaining: 2.64s
215:    learn: 4811.2169173 total: 319ms    remaining: 2.63s
216:    learn: 4807.9718531 total: 320ms    remaining: 2.63s
217:    learn: 4806.7792354 total: 322ms    remaining: 2.63s
218:    learn: 4804.2533811 total: 323ms    remaining: 2.63s
219:    learn: 4799.5793423 total: 325ms    remaining: 2.63s
220:    learn: 4792.8584914 total: 326ms    remaining: 2.63s
221:    learn: 4787.4430082 total: 328ms    remaining: 2.63s
222:    learn: 4781.1207856 total: 330ms    remaining: 2.63s
223:    learn: 4773.1142514 total: 331ms    remaining: 2.62s
224:    learn: 4771.3835507 total: 332ms    remaining: 2.62s
225:    learn: 4769.0205967 total: 334ms    remaining: 2.62s
226:    learn: 4769.0205967 total: 334ms    remaining: 2.61s
227:    learn: 4765.8353863 total: 336ms    remaining: 2.61s
228:    learn: 4765.1621035 total: 337ms    remaining: 2.61s
229:    learn: 4761.9525642 total: 339ms    remaining: 2.61s
230:    learn: 4760.0450712 total: 341ms    remaining: 2.61s
231:    learn: 4755.1246652 total: 342ms    remaining: 2.61s
232:    learn: 4753.8217625 total: 343ms    remaining: 2.6s
233:    learn: 4747.5145731 total: 345ms    remaining: 2.6s
234:    learn: 4747.5145731 total: 345ms    remaining: 2.59s
235:    learn: 4744.6301998 total: 347ms    remaining: 2.59s
236:    learn: 4738.8864864 total: 348ms    remaining: 2.59s
237:    learn: 4736.5714509 total: 350ms    remaining: 2.59s
238:    learn: 4735.0890903 total: 352ms    remaining: 2.59s
239:    learn: 4728.3682935 total: 354ms    remaining: 2.59s
240:    learn: 4721.9886699 total: 355ms    remaining: 2.59s
241:    learn: 4717.3702814 total: 357ms    remaining: 2.59s
242:    learn: 4714.6835057 total: 359ms    remaining: 2.59s
243:    learn: 4712.3286406 total: 360ms    remaining: 2.59s
244:    learn: 4710.3755007 total: 362ms    remaining: 2.59s
245:    learn: 4710.3755007 total: 362ms    remaining: 2.58s
246:    learn: 4710.3279402 total: 363ms    remaining: 2.57s
247:    learn: 4708.7320386 total: 364ms    remaining: 2.57s
248:    learn: 4708.5308039 total: 365ms    remaining: 2.57s
249:    learn: 4708.4446512 total: 366ms    remaining: 2.56s
250:    learn: 4704.9778190 total: 368ms    remaining: 2.56s
251:    learn: 4703.1372636 total: 369ms    remaining: 2.56s
252:    learn: 4698.4459674 total: 371ms    remaining: 2.56s
253:    learn: 4698.4309104 total: 371ms    remaining: 2.55s
254:    learn: 4696.1765101 total: 373ms    remaining: 2.55s
255:    learn: 4693.9238815 total: 374ms    remaining: 2.55s
256:    learn: 4689.8119640 total: 377ms    remaining: 2.56s
257:    learn: 4689.8119640 total: 378ms    remaining: 2.55s
258:    learn: 4686.5896296 total: 380ms    remaining: 2.55s
259:    learn: 4680.2191721 total: 382ms    remaining: 2.56s
260:    learn: 4675.0591879 total: 385ms    remaining: 2.56s
261:    learn: 4671.5328062 total: 386ms    remaining: 2.56s
262:    learn: 4669.4746102 total: 388ms    remaining: 2.56s
263:    learn: 4666.6833477 total: 389ms    remaining: 2.56s
264:    learn: 4665.4037114 total: 391ms    remaining: 2.56s
265:    learn: 4663.4051577 total: 392ms    remaining: 2.56s
266:    learn: 4663.3353224 total: 393ms    remaining: 2.55s
267:    learn: 4660.7525508 total: 394ms    remaining: 2.55s
268:    learn: 4657.2685203 total: 396ms    remaining: 2.54s
269:    learn: 4657.2685203 total: 396ms    remaining: 2.54s
270:    learn: 4656.1503206 total: 397ms    remaining: 2.53s
271:    learn: 4652.0533288 total: 399ms    remaining: 2.54s
272:    learn: 4648.9435674 total: 401ms    remaining: 2.54s
273:    learn: 4645.7461085 total: 403ms    remaining: 2.54s
274:    learn: 4642.4289709 total: 404ms    remaining: 2.53s
275:    learn: 4635.8782081 total: 406ms    remaining: 2.53s
276:    learn: 4629.6954381 total: 407ms    remaining: 2.53s
277:    learn: 4627.1516605 total: 409ms    remaining: 2.53s
278:    learn: 4620.0534128 total: 410ms    remaining: 2.53s
279:    learn: 4620.0534128 total: 411ms    remaining: 2.52s
280:    learn: 4617.4583624 total: 412ms    remaining: 2.52s
281:    learn: 4615.3063600 total: 413ms    remaining: 2.52s
282:    learn: 4615.3063600 total: 414ms    remaining: 2.51s
283:    learn: 4615.3063600 total: 414ms    remaining: 2.5s
284:    learn: 4615.2984525 total: 415ms    remaining: 2.5s
285:    learn: 4611.3120573 total: 416ms    remaining: 2.5s
286:    learn: 4602.2423954 total: 418ms    remaining: 2.5s
287:    learn: 4600.2687023 total: 420ms    remaining: 2.5s
288:    learn: 4600.2687023 total: 420ms    remaining: 2.49s
289:    learn: 4596.0500378 total: 422ms    remaining: 2.49s
290:    learn: 4596.0500378 total: 422ms    remaining: 2.48s
291:    learn: 4594.3298144 total: 424ms    remaining: 2.48s
292:    learn: 4594.3298144 total: 424ms    remaining: 2.47s
293:    learn: 4591.3635862 total: 426ms    remaining: 2.47s
294:    learn: 4591.3400551 total: 426ms    remaining: 2.46s
295:    learn: 4591.3400551 total: 427ms    remaining: 2.46s
296:    learn: 4587.7544912 total: 428ms    remaining: 2.46s
297:    learn: 4582.6753402 total: 429ms    remaining: 2.45s
298:    learn: 4581.1496820 total: 431ms    remaining: 2.45s
299:    learn: 4580.8360346 total: 432ms    remaining: 2.45s
300:    learn: 4580.6042904 total: 433ms    remaining: 2.44s
301:    learn: 4577.5019033 total: 435ms    remaining: 2.44s
302:    learn: 4577.5019033 total: 435ms    remaining: 2.44s
303:    learn: 4577.4991453 total: 436ms    remaining: 2.43s
304:    learn: 4574.0774804 total: 438ms    remaining: 2.43s
305:    learn: 4567.1656172 total: 440ms    remaining: 2.44s
306:    learn: 4567.1656172 total: 440ms    remaining: 2.43s
307:    learn: 4567.1656172 total: 441ms    remaining: 2.42s
308:    learn: 4563.1270449 total: 442ms    remaining: 2.42s
309:    learn: 4556.4082285 total: 444ms    remaining: 2.42s
310:    learn: 4549.4002934 total: 446ms    remaining: 2.42s
311:    learn: 4548.6445542 total: 447ms    remaining: 2.42s
312:    learn: 4548.6445542 total: 447ms    remaining: 2.41s
313:    learn: 4548.6445542 total: 448ms    remaining: 2.4s
314:    learn: 4543.7698643 total: 449ms    remaining: 2.4s
315:    learn: 4537.5322728 total: 450ms    remaining: 2.4s
316:    learn: 4537.5322728 total: 451ms    remaining: 2.39s
317:    learn: 4535.8866669 total: 452ms    remaining: 2.39s
318:    learn: 4534.0177274 total: 454ms    remaining: 2.39s
319:    learn: 4534.0177274 total: 454ms    remaining: 2.38s
320:    learn: 4532.6563239 total: 456ms    remaining: 2.38s
321:    learn: 4532.5713131 total: 457ms    remaining: 2.38s
322:    learn: 4530.5122706 total: 458ms    remaining: 2.38s
323:    learn: 4530.0043105 total: 460ms    remaining: 2.38s
324:    learn: 4530.0043105 total: 460ms    remaining: 2.37s
325:    learn: 4521.2667630 total: 462ms    remaining: 2.37s
326:    learn: 4521.2667630 total: 462ms    remaining: 2.37s
327:    learn: 4514.9759966 total: 464ms    remaining: 2.36s
328:    learn: 4514.5353565 total: 465ms    remaining: 2.36s
329:    learn: 4514.5353565 total: 466ms    remaining: 2.35s
330:    learn: 4514.2251824 total: 467ms    remaining: 2.35s
331:    learn: 4513.4657797 total: 468ms    remaining: 2.35s
332:    learn: 4508.6585143 total: 469ms    remaining: 2.35s
333:    learn: 4506.4620472 total: 471ms    remaining: 2.35s
334:    learn: 4505.0540337 total: 472ms    remaining: 2.35s
335:    learn: 4501.2064750 total: 474ms    remaining: 2.35s
336:    learn: 4501.2064750 total: 474ms    remaining: 2.34s
337:    learn: 4496.9533102 total: 476ms    remaining: 2.34s
338:    learn: 4495.3477163 total: 478ms    remaining: 2.34s
339:    learn: 4495.0865050 total: 478ms    remaining: 2.33s
340:    learn: 4495.0865050 total: 479ms    remaining: 2.33s
341:    learn: 4494.8878363 total: 480ms    remaining: 2.33s
342:    learn: 4494.8878363 total: 481ms    remaining: 2.32s
343:    learn: 4493.9972375 total: 482ms    remaining: 2.32s
344:    learn: 4487.6187148 total: 483ms    remaining: 2.32s
345:    learn: 4485.1605053 total: 485ms    remaining: 2.32s
346:    learn: 4483.9053796 total: 486ms    remaining: 2.31s
347:    learn: 4483.9053796 total: 486ms    remaining: 2.31s
348:    learn: 4483.9051133 total: 487ms    remaining: 2.3s
349:    learn: 4483.6219873 total: 489ms    remaining: 2.3s
350:    learn: 4478.6575151 total: 490ms    remaining: 2.3s
351:    learn: 4478.1207406 total: 492ms    remaining: 2.3s
352:    learn: 4472.9000386 total: 493ms    remaining: 2.3s
353:    learn: 4472.8453202 total: 494ms    remaining: 2.3s
354:    learn: 4471.0678218 total: 496ms    remaining: 2.3s
355:    learn: 4468.5441814 total: 497ms    remaining: 2.29s
356:    learn: 4465.5049818 total: 498ms    remaining: 2.29s
357:    learn: 4461.3387165 total: 500ms    remaining: 2.29s
358:    learn: 4459.7424491 total: 501ms    remaining: 2.29s
359:    learn: 4455.5656117 total: 503ms    remaining: 2.29s
360:    learn: 4452.7121694 total: 504ms    remaining: 2.29s
361:    learn: 4447.3890000 total: 506ms    remaining: 2.29s
362:    learn: 4447.0423543 total: 507ms    remaining: 2.29s
363:    learn: 4445.7774126 total: 508ms    remaining: 2.29s
364:    learn: 4445.7774126 total: 509ms    remaining: 2.28s
365:    learn: 4444.5254579 total: 511ms    remaining: 2.28s
366:    learn: 4442.4085722 total: 512ms    remaining: 2.28s
367:    learn: 4441.9445764 total: 513ms    remaining: 2.27s
368:    learn: 4439.0150744 total: 514ms    remaining: 2.27s
369:    learn: 4435.2123964 total: 516ms    remaining: 2.27s
370:    learn: 4433.5067182 total: 517ms    remaining: 2.27s
371:    learn: 4425.5447245 total: 519ms    remaining: 2.27s
372:    learn: 4425.5447245 total: 520ms    remaining: 2.27s
373:    learn: 4423.8261031 total: 521ms    remaining: 2.26s
374:    learn: 4423.3283440 total: 522ms    remaining: 2.26s
375:    learn: 4423.3283440 total: 523ms    remaining: 2.26s
376:    learn: 4420.3203928 total: 524ms    remaining: 2.26s
377:    learn: 4419.5474976 total: 526ms    remaining: 2.25s
378:    learn: 4414.1595475 total: 527ms    remaining: 2.25s
379:    learn: 4412.2039198 total: 529ms    remaining: 2.25s
380:    learn: 4403.8910365 total: 530ms    remaining: 2.25s
381:    learn: 4403.2953039 total: 532ms    remaining: 2.25s
382:    learn: 4399.9196106 total: 533ms    remaining: 2.25s
383:    learn: 4398.9201818 total: 535ms    remaining: 2.25s
384:    learn: 4398.2316231 total: 536ms    remaining: 2.25s
385:    learn: 4398.2316231 total: 536ms    remaining: 2.24s
386:    learn: 4397.1150817 total: 538ms    remaining: 2.24s
387:    learn: 4396.4216007 total: 540ms    remaining: 2.24s
388:    learn: 4391.6969293 total: 541ms    remaining: 2.24s
389:    learn: 4389.9434594 total: 543ms    remaining: 2.24s
390:    learn: 4387.7026310 total: 544ms    remaining: 2.24s
391:    learn: 4385.6624572 total: 546ms    remaining: 2.24s
392:    learn: 4384.3285328 total: 547ms    remaining: 2.24s
393:    learn: 4381.9411758 total: 549ms    remaining: 2.24s
394:    learn: 4377.9349406 total: 550ms    remaining: 2.23s
395:    learn: 4375.2340793 total: 552ms    remaining: 2.23s
396:    learn: 4375.2338690 total: 552ms    remaining: 2.23s
397:    learn: 4374.5378448 total: 553ms    remaining: 2.23s
398:    learn: 4374.5378448 total: 554ms    remaining: 2.22s
399:    learn: 4374.0246587 total: 556ms    remaining: 2.22s
400:    learn: 4373.0983116 total: 557ms    remaining: 2.22s
401:    learn: 4371.7726903 total: 558ms    remaining: 2.22s
402:    learn: 4371.7726903 total: 559ms    remaining: 2.21s
403:    learn: 4367.9188809 total: 561ms    remaining: 2.22s
404:    learn: 4367.3837471 total: 563ms    remaining: 2.22s
405:    learn: 4367.3837471 total: 563ms    remaining: 2.21s
406:    learn: 4366.3383986 total: 565ms    remaining: 2.21s
407:    learn: 4364.9695002 total: 566ms    remaining: 2.21s
408:    learn: 4364.5791148 total: 567ms    remaining: 2.21s
409:    learn: 4364.5791148 total: 567ms    remaining: 2.2s
410:    learn: 4360.6650300 total: 569ms    remaining: 2.2s
411:    learn: 4358.8850197 total: 570ms    remaining: 2.2s
412:    learn: 4358.0952260 total: 572ms    remaining: 2.2s
413:    learn: 4358.0952260 total: 572ms    remaining: 2.19s
414:    learn: 4358.0952260 total: 573ms    remaining: 2.19s
415:    learn: 4353.9406626 total: 574ms    remaining: 2.19s
416:    learn: 4353.9406626 total: 574ms    remaining: 2.18s
417:    learn: 4353.9406626 total: 575ms    remaining: 2.17s
418:    learn: 4350.8582602 total: 576ms    remaining: 2.17s
419:    learn: 4348.7656427 total: 578ms    remaining: 2.17s
420:    learn: 4348.7654323 total: 579ms    remaining: 2.17s
421:    learn: 4347.2057659 total: 580ms    remaining: 2.17s
422:    learn: 4345.8380325 total: 582ms    remaining: 2.17s
423:    learn: 4340.0889391 total: 583ms    remaining: 2.17s
424:    learn: 4337.3466418 total: 585ms    remaining: 2.17s
425:    learn: 4333.1806959 total: 586ms    remaining: 2.16s
426:    learn: 4332.8557929 total: 587ms    remaining: 2.16s
427:    learn: 4332.8557929 total: 588ms    remaining: 2.16s
428:    learn: 4331.0378307 total: 589ms    remaining: 2.16s
429:    learn: 4325.1923800 total: 591ms    remaining: 2.16s
430:    learn: 4319.7524581 total: 592ms    remaining: 2.16s
431:    learn: 4316.9973772 total: 594ms    remaining: 2.16s
432:    learn: 4315.3920928 total: 596ms    remaining: 2.15s
433:    learn: 4313.5095488 total: 597ms    remaining: 2.15s
434:    learn: 4312.0378766 total: 599ms    remaining: 2.15s
435:    learn: 4309.9677471 total: 600ms    remaining: 2.15s
436:    learn: 4307.8543156 total: 602ms    remaining: 2.15s
437:    learn: 4306.3912379 total: 603ms    remaining: 2.15s
438:    learn: 4304.0146016 total: 605ms    remaining: 2.15s
439:    learn: 4304.0146016 total: 605ms    remaining: 2.15s
440:    learn: 4304.0146016 total: 606ms    remaining: 2.14s
441:    learn: 4296.2066898 total: 607ms    remaining: 2.14s
442:    learn: 4296.2066898 total: 608ms    remaining: 2.13s
443:    learn: 4296.2066898 total: 608ms    remaining: 2.13s
444:    learn: 4293.7742302 total: 610ms    remaining: 2.13s
445:    learn: 4290.6682497 total: 611ms    remaining: 2.13s
446:    learn: 4290.6682497 total: 612ms    remaining: 2.13s
447:    learn: 4290.6659104 total: 612ms    remaining: 2.12s
448:    learn: 4290.6659104 total: 613ms    remaining: 2.12s
449:    learn: 4290.6659104 total: 613ms    remaining: 2.11s
450:    learn: 4289.4314861 total: 615ms    remaining: 2.11s
451:    learn: 4287.6019761 total: 616ms    remaining: 2.11s
452:    learn: 4284.1460191 total: 618ms    remaining: 2.11s
453:    learn: 4283.1275688 total: 619ms    remaining: 2.11s
454:    learn: 4283.1275688 total: 620ms    remaining: 2.1s
455:    learn: 4282.2886315 total: 621ms    remaining: 2.1s
456:    learn: 4282.2886315 total: 622ms    remaining: 2.1s
457:    learn: 4281.3414277 total: 623ms    remaining: 2.1s
458:    learn: 4280.9302933 total: 624ms    remaining: 2.1s
459:    learn: 4280.2722045 total: 625ms    remaining: 2.09s
460:    learn: 4278.2675356 total: 627ms    remaining: 2.09s
461:    learn: 4276.8834771 total: 628ms    remaining: 2.09s
462:    learn: 4276.8162392 total: 629ms    remaining: 2.09s
463:    learn: 4271.9664215 total: 631ms    remaining: 2.09s
464:    learn: 4268.1650630 total: 633ms    remaining: 2.09s
465:    learn: 4261.3143626 total: 634ms    remaining: 2.09s
466:    learn: 4261.3143592 total: 635ms    remaining: 2.08s
467:    learn: 4255.8005291 total: 636ms    remaining: 2.08s
468:    learn: 4250.4214698 total: 638ms    remaining: 2.08s
469:    learn: 4248.4840035 total: 640ms    remaining: 2.08s
470:    learn: 4247.4707012 total: 642ms    remaining: 2.08s
471:    learn: 4244.9999349 total: 643ms    remaining: 2.08s
472:    learn: 4244.8961803 total: 644ms    remaining: 2.08s
473:    learn: 4243.5136900 total: 646ms    remaining: 2.08s
474:    learn: 4240.5620812 total: 647ms    remaining: 2.08s
475:    learn: 4237.5068841 total: 649ms    remaining: 2.08s
476:    learn: 4235.7372353 total: 650ms    remaining: 2.08s
477:    learn: 4235.5684329 total: 652ms    remaining: 2.07s
478:    learn: 4235.2638310 total: 653ms    remaining: 2.07s
479:    learn: 4234.8174553 total: 655ms    remaining: 2.07s
480:    learn: 4234.0613475 total: 657ms    remaining: 2.07s
481:    learn: 4234.0612821 total: 657ms    remaining: 2.07s
482:    learn: 4230.8662841 total: 659ms    remaining: 2.07s
483:    learn: 4228.3535703 total: 660ms    remaining: 2.07s
484:    learn: 4227.2170785 total: 662ms    remaining: 2.07s
485:    learn: 4227.2037809 total: 663ms    remaining: 2.07s
486:    learn: 4225.3901041 total: 665ms    remaining: 2.06s
487:    learn: 4224.7331910 total: 667ms    remaining: 2.06s
488:    learn: 4218.3517171 total: 668ms    remaining: 2.06s
489:    learn: 4218.3517171 total: 669ms    remaining: 2.06s
490:    learn: 4217.8187895 total: 670ms    remaining: 2.06s
491:    learn: 4215.5984258 total: 671ms    remaining: 2.06s
492:    learn: 4215.5984258 total: 672ms    remaining: 2.05s
493:    learn: 4213.8364336 total: 674ms    remaining: 2.05s
494:    learn: 4213.8364336 total: 674ms    remaining: 2.05s
495:    learn: 4213.0051294 total: 676ms    remaining: 2.05s
496:    learn: 4212.8201871 total: 677ms    remaining: 2.05s
497:    learn: 4210.8474431 total: 678ms    remaining: 2.04s
498:    learn: 4208.3847884 total: 680ms    remaining: 2.05s
499:    learn: 4207.8647287 total: 682ms    remaining: 2.04s
500:    learn: 4205.4937402 total: 683ms    remaining: 2.04s
501:    learn: 4201.6181630 total: 685ms    remaining: 2.04s
502:    learn: 4199.5545731 total: 686ms    remaining: 2.04s
503:    learn: 4199.5545731 total: 687ms    remaining: 2.04s
504:    learn: 4194.7013059 total: 688ms    remaining: 2.04s
505:    learn: 4194.7012736 total: 689ms    remaining: 2.03s
506:    learn: 4194.2513690 total: 690ms    remaining: 2.03s
507:    learn: 4193.7391858 total: 692ms    remaining: 2.03s
508:    learn: 4192.8297057 total: 694ms    remaining: 2.03s
509:    learn: 4192.3261240 total: 695ms    remaining: 2.03s
510:    learn: 4188.6361916 total: 696ms    remaining: 2.03s
511:    learn: 4184.1036666 total: 698ms    remaining: 2.03s
512:    learn: 4176.3244783 total: 700ms    remaining: 2.03s
513:    learn: 4176.3244783 total: 700ms    remaining: 2.02s
514:    learn: 4172.9846817 total: 701ms    remaining: 2.02s
515:    learn: 4168.9849081 total: 703ms    remaining: 2.02s
516:    learn: 4167.2190260 total: 704ms    remaining: 2.02s
517:    learn: 4167.2190260 total: 705ms    remaining: 2.02s
518:    learn: 4166.9911886 total: 706ms    remaining: 2.01s
519:    learn: 4162.8150043 total: 707ms    remaining: 2.01s
520:    learn: 4162.4234461 total: 709ms    remaining: 2.01s
521:    learn: 4161.6787564 total: 711ms    remaining: 2.01s
522:    learn: 4161.6787564 total: 711ms    remaining: 2.01s
523:    learn: 4159.0877863 total: 713ms    remaining: 2.01s
524:    learn: 4158.1609903 total: 714ms    remaining: 2.01s
525:    learn: 4154.6942835 total: 716ms    remaining: 2.01s
526:    learn: 4151.0966275 total: 718ms    remaining: 2s
527:    learn: 4149.3851416 total: 719ms    remaining: 2s
528:    learn: 4148.7633600 total: 721ms    remaining: 2s
529:    learn: 4148.2950844 total: 722ms    remaining: 2s
530:    learn: 4147.3736223 total: 724ms    remaining: 2s
531:    learn: 4147.3736223 total: 725ms    remaining: 2s
532:    learn: 4147.3596110 total: 725ms    remaining: 2s
533:    learn: 4145.0761992 total: 727ms    remaining: 2s
534:    learn: 4138.0181778 total: 729ms    remaining: 2s
535:    learn: 4136.2533307 total: 730ms    remaining: 1.99s
536:    learn: 4135.3564180 total: 732ms    remaining: 1.99s
537:    learn: 4135.3564180 total: 733ms    remaining: 1.99s
538:    learn: 4134.6207875 total: 734ms    remaining: 1.99s
539:    learn: 4130.3626163 total: 736ms    remaining: 1.99s
540:    learn: 4127.8526230 total: 738ms    remaining: 1.99s
541:    learn: 4127.8526230 total: 738ms    remaining: 1.99s
542:    learn: 4126.9499016 total: 740ms    remaining: 1.99s
543:    learn: 4124.4222877 total: 742ms    remaining: 1.99s
544:    learn: 4124.4093974 total: 744ms    remaining: 1.99s
545:    learn: 4120.4906474 total: 745ms    remaining: 1.98s
546:    learn: 4120.1085313 total: 747ms    remaining: 1.98s
547:    learn: 4118.5497982 total: 748ms    remaining: 1.98s
548:    learn: 4118.5497982 total: 749ms    remaining: 1.98s
549:    learn: 4116.7736360 total: 750ms    remaining: 1.98s
550:    learn: 4114.8590115 total: 752ms    remaining: 1.98s
551:    learn: 4113.8718524 total: 754ms    remaining: 1.98s
552:    learn: 4113.6509912 total: 755ms    remaining: 1.97s
553:    learn: 4112.7943829 total: 756ms    remaining: 1.97s
554:    learn: 4112.7943829 total: 757ms    remaining: 1.97s
555:    learn: 4111.8971678 total: 758ms    remaining: 1.97s
556:    learn: 4108.7174163 total: 760ms    remaining: 1.97s
557:    learn: 4108.0979840 total: 762ms    remaining: 1.97s
558:    learn: 4107.4667399 total: 763ms    remaining: 1.97s
559:    learn: 4107.0891159 total: 765ms    remaining: 1.97s
560:    learn: 4106.3886713 total: 767ms    remaining: 1.97s
561:    learn: 4106.3851242 total: 768ms    remaining: 1.96s
562:    learn: 4106.3797848 total: 768ms    remaining: 1.96s
563:    learn: 4106.3797848 total: 769ms    remaining: 1.96s
564:    learn: 4106.3797848 total: 769ms    remaining: 1.95s
565:    learn: 4106.3797848 total: 770ms    remaining: 1.95s
566:    learn: 4104.3466739 total: 772ms    remaining: 1.95s
567:    learn: 4102.6349434 total: 773ms    remaining: 1.95s
568:    learn: 4093.9566800 total: 775ms    remaining: 1.95s
569:    learn: 4089.1688460 total: 777ms    remaining: 1.95s
570:    learn: 4088.2412857 total: 778ms    remaining: 1.95s
571:    learn: 4088.2412857 total: 779ms    remaining: 1.94s
572:    learn: 4087.4126865 total: 781ms    remaining: 1.94s
573:    learn: 4087.3246347 total: 784ms    remaining: 1.95s
574:    learn: 4079.1728530 total: 786ms    remaining: 1.95s
575:    learn: 4076.9756189 total: 788ms    remaining: 1.95s
576:    learn: 4074.5129417 total: 790ms    remaining: 1.95s
577:    learn: 4073.6434006 total: 792ms    remaining: 1.95s
578:    learn: 4073.6434006 total: 793ms    remaining: 1.95s
579:    learn: 4073.1058334 total: 795ms    remaining: 1.95s
580:    learn: 4070.4631078 total: 797ms    remaining: 1.95s
581:    learn: 4068.7561071 total: 799ms    remaining: 1.95s
582:    learn: 4067.6543142 total: 801ms    remaining: 1.95s
583:    learn: 4064.0010837 total: 802ms    remaining: 1.95s
584:    learn: 4062.6699329 total: 804ms    remaining: 1.95s
585:    learn: 4061.8289513 total: 806ms    remaining: 1.95s
586:    learn: 4058.8888104 total: 808ms    remaining: 1.94s
587:    learn: 4057.5685823 total: 810ms    remaining: 1.94s
588:    learn: 4056.3428995 total: 812ms    remaining: 1.94s
589:    learn: 4051.0984948 total: 814ms    remaining: 1.94s
590:    learn: 4050.7321529 total: 816ms    remaining: 1.94s
591:    learn: 4048.6650531 total: 818ms    remaining: 1.95s
592:    learn: 4047.2165603 total: 820ms    remaining: 1.95s
593:    learn: 4043.7914684 total: 822ms    remaining: 1.94s
594:    learn: 4043.2525797 total: 823ms    remaining: 1.94s
595:    learn: 4043.2525797 total: 824ms    remaining: 1.94s
596:    learn: 4042.6610138 total: 826ms    remaining: 1.94s
597:    learn: 4039.9999717 total: 828ms    remaining: 1.94s
598:    learn: 4034.3252839 total: 830ms    remaining: 1.94s
599:    learn: 4034.3252839 total: 830ms    remaining: 1.94s
600:    learn: 4034.3252839 total: 831ms    remaining: 1.93s
601:    learn: 4034.2830758 total: 832ms    remaining: 1.93s
602:    learn: 4033.9653700 total: 834ms    remaining: 1.93s
603:    learn: 4033.9606019 total: 834ms    remaining: 1.93s
604:    learn: 4028.7695295 total: 836ms    remaining: 1.93s
605:    learn: 4028.4370609 total: 838ms    remaining: 1.93s
606:    learn: 4026.1362055 total: 840ms    remaining: 1.93s
607:    learn: 4025.1194150 total: 842ms    remaining: 1.93s
608:    learn: 4021.1161232 total: 844ms    remaining: 1.93s
609:    learn: 4020.5508077 total: 846ms    remaining: 1.93s
610:    learn: 4020.5508077 total: 846ms    remaining: 1.92s
611:    learn: 4020.3832148 total: 847ms    remaining: 1.92s
612:    learn: 4016.1194956 total: 849ms    remaining: 1.92s
613:    learn: 4013.4009443 total: 851ms    remaining: 1.92s
614:    learn: 4012.3927298 total: 853ms    remaining: 1.92s
615:    learn: 4012.3875832 total: 853ms    remaining: 1.92s
616:    learn: 4012.2092547 total: 855ms    remaining: 1.92s
617:    learn: 4010.9373855 total: 856ms    remaining: 1.91s
618:    learn: 4010.6712533 total: 858ms    remaining: 1.91s
619:    learn: 4007.0184514 total: 859ms    remaining: 1.91s
620:    learn: 4007.0184514 total: 860ms    remaining: 1.91s
621:    learn: 4006.3237895 total: 862ms    remaining: 1.91s
622:    learn: 4004.8793407 total: 864ms    remaining: 1.91s
623:    learn: 4003.9471214 total: 865ms    remaining: 1.91s
624:    learn: 4000.7887982 total: 867ms    remaining: 1.91s
625:    learn: 4000.4795677 total: 868ms    remaining: 1.91s
626:    learn: 4000.3438616 total: 870ms    remaining: 1.9s
627:    learn: 3999.1296902 total: 871ms    remaining: 1.9s
628:    learn: 3998.0867078 total: 873ms    remaining: 1.9s
629:    learn: 3998.0867078 total: 873ms    remaining: 1.9s
630:    learn: 3995.4813310 total: 875ms    remaining: 1.9s
631:    learn: 3995.4813310 total: 876ms    remaining: 1.9s
632:    learn: 3994.7973506 total: 878ms    remaining: 1.9s
633:    learn: 3994.4255478 total: 879ms    remaining: 1.89s
634:    learn: 3993.8426501 total: 881ms    remaining: 1.89s
635:    learn: 3992.4595577 total: 883ms    remaining: 1.89s
636:    learn: 3991.2065592 total: 885ms    remaining: 1.89s
637:    learn: 3990.5372097 total: 887ms    remaining: 1.89s
638:    learn: 3990.5313149 total: 887ms    remaining: 1.89s
639:    learn: 3989.2375720 total: 889ms    remaining: 1.89s
640:    learn: 3987.6399593 total: 891ms    remaining: 1.89s
641:    learn: 3986.0680229 total: 893ms    remaining: 1.89s
642:    learn: 3986.0680229 total: 893ms    remaining: 1.89s
643:    learn: 3985.3611248 total: 895ms    remaining: 1.88s
644:    learn: 3984.9141762 total: 897ms    remaining: 1.88s
645:    learn: 3978.4243745 total: 899ms    remaining: 1.88s
646:    learn: 3978.0748821 total: 900ms    remaining: 1.88s
647:    learn: 3975.0948892 total: 902ms    remaining: 1.88s
648:    learn: 3973.7336182 total: 904ms    remaining: 1.88s
649:    learn: 3973.5694895 total: 906ms    remaining: 1.88s
650:    learn: 3973.5694895 total: 906ms    remaining: 1.88s
651:    learn: 3973.2035512 total: 908ms    remaining: 1.88s
652:    learn: 3971.3748963 total: 910ms    remaining: 1.88s
653:    learn: 3970.8273230 total: 912ms    remaining: 1.88s
654:    learn: 3970.6661701 total: 913ms    remaining: 1.87s
655:    learn: 3970.3188222 total: 915ms    remaining: 1.87s
656:    learn: 3967.7537638 total: 917ms    remaining: 1.87s
657:    learn: 3965.3162844 total: 919ms    remaining: 1.87s
658:    learn: 3963.3457135 total: 922ms    remaining: 1.88s
659:    learn: 3960.6737011 total: 924ms    remaining: 1.88s
660:    learn: 3957.5551840 total: 927ms    remaining: 1.88s
661:    learn: 3954.5284019 total: 928ms    remaining: 1.88s
662:    learn: 3954.2685083 total: 930ms    remaining: 1.88s
663:    learn: 3953.7975769 total: 936ms    remaining: 1.88s
664:    learn: 3952.5579480 total: 939ms    remaining: 1.89s
665:    learn: 3952.5579480 total: 940ms    remaining: 1.88s
666:    learn: 3952.5579480 total: 941ms    remaining: 1.88s
667:    learn: 3952.0530212 total: 943ms    remaining: 1.88s
668:    learn: 3951.0236652 total: 946ms    remaining: 1.88s
669:    learn: 3948.8482121 total: 948ms    remaining: 1.88s
670:    learn: 3948.1039576 total: 950ms    remaining: 1.88s
671:    learn: 3948.1039576 total: 951ms    remaining: 1.88s
672:    learn: 3947.8466720 total: 952ms    remaining: 1.88s
673:    learn: 3944.7760408 total: 954ms    remaining: 1.88s
674:    learn: 3944.3794626 total: 956ms    remaining: 1.88s
675:    learn: 3943.8828460 total: 959ms    remaining: 1.88s
676:    learn: 3939.4803751 total: 962ms    remaining: 1.88s
677:    learn: 3937.0226901 total: 964ms    remaining: 1.88s
678:    learn: 3935.6062093 total: 966ms    remaining: 1.88s
679:    learn: 3931.6908549 total: 968ms    remaining: 1.88s
680:    learn: 3931.6908549 total: 969ms    remaining: 1.88s
681:    learn: 3931.4780236 total: 970ms    remaining: 1.88s
682:    learn: 3931.4780236 total: 971ms    remaining: 1.87s
683:    learn: 3930.1802631 total: 973ms    remaining: 1.87s
684:    learn: 3930.1802631 total: 974ms    remaining: 1.87s
685:    learn: 3930.1802631 total: 974ms    remaining: 1.87s
686:    learn: 3929.9546359 total: 975ms    remaining: 1.86s
687:    learn: 3929.9546359 total: 976ms    remaining: 1.86s
688:    learn: 3929.5200873 total: 978ms    remaining: 1.86s
689:    learn: 3924.1504149 total: 980ms    remaining: 1.86s
690:    learn: 3924.1504149 total: 981ms    remaining: 1.86s
691:    learn: 3924.1504149 total: 981ms    remaining: 1.85s
692:    learn: 3923.3728173 total: 984ms    remaining: 1.86s
693:    learn: 3923.3728173 total: 985ms    remaining: 1.85s
694:    learn: 3921.6096814 total: 987ms    remaining: 1.85s
695:    learn: 3920.3917066 total: 989ms    remaining: 1.85s
696:    learn: 3919.1748239 total: 991ms    remaining: 1.85s
697:    learn: 3918.6781013 total: 993ms    remaining: 1.85s
698:    learn: 3915.5786090 total: 995ms    remaining: 1.85s
699:    learn: 3914.9386661 total: 997ms    remaining: 1.85s
700:    learn: 3914.1044266 total: 999ms    remaining: 1.85s
701:    learn: 3914.1044266 total: 1000ms   remaining: 1.85s
702:    learn: 3911.5461909 total: 1s   remaining: 1.85s
703:    learn: 3909.7858547 total: 1s   remaining: 1.85s
704:    learn: 3908.5848398 total: 1s   remaining: 1.85s
705:    learn: 3908.5846612 total: 1.01s    remaining: 1.84s
706:    learn: 3906.3544545 total: 1.01s    remaining: 1.84s
707:    learn: 3902.5421111 total: 1.01s    remaining: 1.84s
708:    learn: 3900.6794103 total: 1.01s    remaining: 1.84s
709:    learn: 3900.1145635 total: 1.01s    remaining: 1.84s
710:    learn: 3898.7988768 total: 1.02s    remaining: 1.84s
711:    learn: 3897.7890023 total: 1.02s    remaining: 1.84s
712:    learn: 3897.3063669 total: 1.02s    remaining: 1.84s
713:    learn: 3896.0709359 total: 1.02s    remaining: 1.84s
714:    learn: 3893.2716970 total: 1.03s    remaining: 1.84s
715:    learn: 3893.2716970 total: 1.03s    remaining: 1.84s
716:    learn: 3892.7696855 total: 1.03s    remaining: 1.84s
717:    learn: 3891.8609727 total: 1.03s    remaining: 1.84s
718:    learn: 3891.8609727 total: 1.03s    remaining: 1.84s
719:    learn: 3886.5432527 total: 1.03s    remaining: 1.84s
720:    learn: 3885.5890724 total: 1.03s    remaining: 1.84s
721:    learn: 3885.2509517 total: 1.04s    remaining: 1.83s
722:    learn: 3884.8683416 total: 1.04s    remaining: 1.83s
723:    learn: 3883.8658058 total: 1.04s    remaining: 1.83s
724:    learn: 3882.8769674 total: 1.04s    remaining: 1.83s
725:    learn: 3880.1551434 total: 1.04s    remaining: 1.83s
726:    learn: 3878.8486183 total: 1.05s    remaining: 1.83s
727:    learn: 3878.0455602 total: 1.05s    remaining: 1.83s
728:    learn: 3878.0455602 total: 1.05s    remaining: 1.83s
729:    learn: 3875.8100129 total: 1.05s    remaining: 1.83s
730:    learn: 3875.8100129 total: 1.05s    remaining: 1.83s
731:    learn: 3874.7519439 total: 1.05s    remaining: 1.82s
732:    learn: 3873.0181722 total: 1.05s    remaining: 1.82s
733:    learn: 3872.6475110 total: 1.06s    remaining: 1.82s
734:    learn: 3870.6422449 total: 1.06s    remaining: 1.82s
735:    learn: 3869.4474087 total: 1.06s    remaining: 1.82s
736:    learn: 3867.0168014 total: 1.06s    remaining: 1.82s
737:    learn: 3865.3121541 total: 1.06s    remaining: 1.82s
738:    learn: 3864.3253068 total: 1.07s    remaining: 1.82s
739:    learn: 3863.3321651 total: 1.07s    remaining: 1.82s
740:    learn: 3863.0244965 total: 1.07s    remaining: 1.82s
741:    learn: 3861.8958492 total: 1.07s    remaining: 1.82s
742:    learn: 3861.7968837 total: 1.07s    remaining: 1.82s
743:    learn: 3861.7962967 total: 1.07s    remaining: 1.81s
744:    learn: 3860.4491412 total: 1.08s    remaining: 1.81s
745:    learn: 3860.4491412 total: 1.08s    remaining: 1.81s
746:    learn: 3859.3516675 total: 1.08s    remaining: 1.81s
747:    learn: 3858.3562986 total: 1.08s    remaining: 1.81s
748:    learn: 3858.3562986 total: 1.08s    remaining: 1.8s
749:    learn: 3858.3490771 total: 1.08s    remaining: 1.8s
750:    learn: 3858.2502493 total: 1.08s    remaining: 1.8s
751:    learn: 3857.4697682 total: 1.08s    remaining: 1.8s
752:    learn: 3857.4659809 total: 1.08s    remaining: 1.8s
753:    learn: 3856.9435214 total: 1.09s    remaining: 1.8s
754:    learn: 3856.9435214 total: 1.09s    remaining: 1.79s
755:    learn: 3856.2765714 total: 1.09s    remaining: 1.79s
756:    learn: 3855.7600481 total: 1.09s    remaining: 1.79s
757:    learn: 3852.6969291 total: 1.09s    remaining: 1.79s
758:    learn: 3852.6730764 total: 1.09s    remaining: 1.79s
759:    learn: 3852.2047553 total: 1.09s    remaining: 1.79s
760:    learn: 3851.5653409 total: 1.1s remaining: 1.79s
761:    learn: 3851.5508266 total: 1.1s remaining: 1.78s
762:    learn: 3848.7387610 total: 1.1s remaining: 1.78s
763:    learn: 3847.7080161 total: 1.1s remaining: 1.78s
764:    learn: 3847.7080161 total: 1.1s remaining: 1.78s
765:    learn: 3847.6293776 total: 1.1s remaining: 1.78s
766:    learn: 3847.6293776 total: 1.1s remaining: 1.77s
767:    learn: 3847.6289207 total: 1.1s remaining: 1.77s
768:    learn: 3845.8710962 total: 1.11s    remaining: 1.77s
769:    learn: 3845.3032079 total: 1.11s    remaining: 1.77s
770:    learn: 3844.5649758 total: 1.11s    remaining: 1.77s
771:    learn: 3843.7347054 total: 1.11s    remaining: 1.77s
772:    learn: 3841.6978237 total: 1.11s    remaining: 1.77s
773:    learn: 3841.0971126 total: 1.12s    remaining: 1.77s
774:    learn: 3837.4084642 total: 1.12s    remaining: 1.77s
775:    learn: 3837.0934050 total: 1.12s    remaining: 1.76s
776:    learn: 3836.7762376 total: 1.12s    remaining: 1.76s
777:    learn: 3836.2799013 total: 1.12s    remaining: 1.76s
778:    learn: 3834.5565153 total: 1.12s    remaining: 1.76s
779:    learn: 3832.9932344 total: 1.13s    remaining: 1.76s
780:    learn: 3829.3338033 total: 1.13s    remaining: 1.76s
781:    learn: 3828.5601788 total: 1.13s    remaining: 1.76s
782:    learn: 3828.5601788 total: 1.13s    remaining: 1.76s
783:    learn: 3828.5601744 total: 1.13s    remaining: 1.75s
784:    learn: 3827.5366664 total: 1.13s    remaining: 1.75s
785:    learn: 3826.4151057 total: 1.13s    remaining: 1.75s
786:    learn: 3825.7586832 total: 1.14s    remaining: 1.75s
787:    learn: 3825.0938251 total: 1.14s    remaining: 1.75s
788:    learn: 3824.9906903 total: 1.14s    remaining: 1.75s
789:    learn: 3824.5655529 total: 1.14s    remaining: 1.75s
790:    learn: 3822.6288381 total: 1.14s    remaining: 1.75s
791:    learn: 3822.3783984 total: 1.15s    remaining: 1.75s
792:    learn: 3820.2943393 total: 1.15s    remaining: 1.75s
793:    learn: 3820.0646286 total: 1.15s    remaining: 1.74s
794:    learn: 3819.9664245 total: 1.15s    remaining: 1.74s
795:    learn: 3818.9084625 total: 1.15s    remaining: 1.74s
796:    learn: 3818.5750938 total: 1.15s    remaining: 1.74s
797:    learn: 3817.5402599 total: 1.16s    remaining: 1.74s
798:    learn: 3816.2278347 total: 1.16s    remaining: 1.74s
799:    learn: 3812.7380606 total: 1.16s    remaining: 1.74s
800:    learn: 3812.7380606 total: 1.16s    remaining: 1.74s
801:    learn: 3812.7380606 total: 1.16s    remaining: 1.73s
802:    learn: 3811.5718740 total: 1.16s    remaining: 1.73s
803:    learn: 3811.3369065 total: 1.16s    remaining: 1.73s
804:    learn: 3811.1293690 total: 1.16s    remaining: 1.73s
805:    learn: 3811.1183005 total: 1.17s    remaining: 1.73s
806:    learn: 3808.8433205 total: 1.17s    remaining: 1.73s
807:    learn: 3808.6095214 total: 1.17s    remaining: 1.72s
808:    learn: 3807.7139243 total: 1.17s    remaining: 1.72s
809:    learn: 3807.5754253 total: 1.17s    remaining: 1.72s
810:    learn: 3807.4133638 total: 1.17s    remaining: 1.72s
811:    learn: 3805.7109740 total: 1.18s    remaining: 1.72s
812:    learn: 3804.7089862 total: 1.18s    remaining: 1.72s
813:    learn: 3802.8930509 total: 1.18s    remaining: 1.72s
814:    learn: 3802.2797474 total: 1.18s    remaining: 1.72s
815:    learn: 3800.9263311 total: 1.18s    remaining: 1.72s
816:    learn: 3796.9644567 total: 1.19s    remaining: 1.72s
817:    learn: 3796.9644567 total: 1.19s    remaining: 1.71s
818:    learn: 3794.6321824 total: 1.19s    remaining: 1.71s
819:    learn: 3793.7138810 total: 1.19s    remaining: 1.71s
820:    learn: 3793.4292740 total: 1.19s    remaining: 1.71s
821:    learn: 3793.4255576 total: 1.19s    remaining: 1.71s
822:    learn: 3792.1343626 total: 1.19s    remaining: 1.71s
823:    learn: 3790.4684901 total: 1.2s remaining: 1.71s
824:    learn: 3790.0355937 total: 1.2s remaining: 1.71s
825:    learn: 3789.5560775 total: 1.2s remaining: 1.7s
826:    learn: 3787.8915354 total: 1.2s remaining: 1.7s
827:    learn: 3787.5419872 total: 1.2s remaining: 1.7s
828:    learn: 3784.9113968 total: 1.2s remaining: 1.7s
829:    learn: 3784.9113968 total: 1.21s    remaining: 1.7s
830:    learn: 3784.5295880 total: 1.21s    remaining: 1.7s
831:    learn: 3784.5061352 total: 1.21s    remaining: 1.7s
832:    learn: 3783.9559552 total: 1.21s    remaining: 1.7s
833:    learn: 3783.2083733 total: 1.21s    remaining: 1.69s
834:    learn: 3782.5879048 total: 1.21s    remaining: 1.69s
835:    learn: 3778.7531050 total: 1.22s    remaining: 1.69s
836:    learn: 3778.3606445 total: 1.22s    remaining: 1.69s
837:    learn: 3777.5169044 total: 1.22s    remaining: 1.69s
838:    learn: 3776.0781037 total: 1.22s    remaining: 1.69s
839:    learn: 3774.1576914 total: 1.22s    remaining: 1.69s
840:    learn: 3773.0961327 total: 1.23s    remaining: 1.69s
841:    learn: 3769.1849336 total: 1.23s    remaining: 1.69s
842:    learn: 3769.1849336 total: 1.23s    remaining: 1.69s
843:    learn: 3768.5544138 total: 1.23s    remaining: 1.68s
844:    learn: 3767.0540299 total: 1.23s    remaining: 1.68s
845:    learn: 3766.5195021 total: 1.23s    remaining: 1.68s
846:    learn: 3766.5195021 total: 1.23s    remaining: 1.68s
847:    learn: 3766.4835237 total: 1.23s    remaining: 1.68s
848:    learn: 3766.3146637 total: 1.24s    remaining: 1.68s
849:    learn: 3766.3146637 total: 1.24s    remaining: 1.67s
850:    learn: 3760.7193853 total: 1.24s    remaining: 1.67s
851:    learn: 3760.2822988 total: 1.24s    remaining: 1.67s
852:    learn: 3760.2822988 total: 1.24s    remaining: 1.67s
853:    learn: 3760.1005594 total: 1.24s    remaining: 1.67s
854:    learn: 3758.8854406 total: 1.24s    remaining: 1.67s
855:    learn: 3758.2299296 total: 1.25s    remaining: 1.67s
856:    learn: 3755.6860428 total: 1.25s    remaining: 1.66s
857:    learn: 3754.4660145 total: 1.25s    remaining: 1.66s
858:    learn: 3753.1371758 total: 1.25s    remaining: 1.66s
859:    learn: 3752.4535790 total: 1.25s    remaining: 1.66s
860:    learn: 3752.2871783 total: 1.25s    remaining: 1.66s
861:    learn: 3751.5256924 total: 1.26s    remaining: 1.66s
862:    learn: 3751.5209414 total: 1.26s    remaining: 1.66s
863:    learn: 3751.2839240 total: 1.26s    remaining: 1.66s
864:    learn: 3750.8896543 total: 1.26s    remaining: 1.65s
865:    learn: 3748.9138530 total: 1.26s    remaining: 1.65s
866:    learn: 3748.7446691 total: 1.26s    remaining: 1.65s
867:    learn: 3748.2933914 total: 1.27s    remaining: 1.65s
868:    learn: 3747.7771132 total: 1.27s    remaining: 1.65s
869:    learn: 3747.4756519 total: 1.27s    remaining: 1.65s
870:    learn: 3746.8798693 total: 1.27s    remaining: 1.65s
871:    learn: 3746.3395775 total: 1.27s    remaining: 1.65s
872:    learn: 3746.1296952 total: 1.27s    remaining: 1.65s
873:    learn: 3743.5685571 total: 1.28s    remaining: 1.65s
874:    learn: 3741.4152266 total: 1.28s    remaining: 1.64s
875:    learn: 3741.2402215 total: 1.28s    remaining: 1.64s
876:    learn: 3741.0882207 total: 1.28s    remaining: 1.64s
877:    learn: 3740.1415409 total: 1.28s    remaining: 1.64s
878:    learn: 3740.1413814 total: 1.28s    remaining: 1.64s
879:    learn: 3738.9862194 total: 1.29s    remaining: 1.64s
880:    learn: 3737.5337821 total: 1.29s    remaining: 1.64s
881:    learn: 3737.5337821 total: 1.29s    remaining: 1.63s
882:    learn: 3737.1581488 total: 1.29s    remaining: 1.63s
883:    learn: 3736.7844566 total: 1.29s    remaining: 1.63s
884:    learn: 3736.7844566 total: 1.29s    remaining: 1.63s
885:    learn: 3736.7841652 total: 1.29s    remaining: 1.63s
886:    learn: 3736.5406219 total: 1.3s remaining: 1.63s
887:    learn: 3736.1152642 total: 1.3s remaining: 1.63s
888:    learn: 3734.4118333 total: 1.3s remaining: 1.62s
889:    learn: 3733.9724930 total: 1.3s remaining: 1.62s
890:    learn: 3733.8000485 total: 1.3s remaining: 1.62s
891:    learn: 3733.4601714 total: 1.3s remaining: 1.62s
892:    learn: 3733.1641953 total: 1.31s    remaining: 1.62s
893:    learn: 3733.0912557 total: 1.31s    remaining: 1.62s
894:    learn: 3731.9732853 total: 1.31s    remaining: 1.62s
895:    learn: 3731.4078934 total: 1.31s    remaining: 1.62s
896:    learn: 3730.4823594 total: 1.31s    remaining: 1.62s
897:    learn: 3730.4018892 total: 1.32s    remaining: 1.61s
898:    learn: 3729.7012273 total: 1.32s    remaining: 1.61s
899:    learn: 3729.2725886 total: 1.32s    remaining: 1.61s
900:    learn: 3728.4962656 total: 1.32s    remaining: 1.61s
901:    learn: 3728.2322230 total: 1.32s    remaining: 1.61s
902:    learn: 3727.5962340 total: 1.32s    remaining: 1.61s
903:    learn: 3726.0272566 total: 1.33s    remaining: 1.61s
904:    learn: 3725.9333842 total: 1.33s    remaining: 1.61s
905:    learn: 3724.8243608 total: 1.33s    remaining: 1.6s
906:    learn: 3724.2181171 total: 1.33s    remaining: 1.6s
907:    learn: 3724.2181171 total: 1.33s    remaining: 1.6s
908:    learn: 3724.1997717 total: 1.33s    remaining: 1.6s
909:    learn: 3722.5087637 total: 1.33s    remaining: 1.6s
910:    learn: 3722.5087637 total: 1.33s    remaining: 1.6s
911:    learn: 3722.3746981 total: 1.34s    remaining: 1.59s
912:    learn: 3722.0076978 total: 1.34s    remaining: 1.59s
913:    learn: 3721.3351238 total: 1.34s    remaining: 1.59s
914:    learn: 3721.3351238 total: 1.34s    remaining: 1.59s
915:    learn: 3719.7788144 total: 1.34s    remaining: 1.59s
916:    learn: 3718.5757182 total: 1.34s    remaining: 1.59s
917:    learn: 3717.0143275 total: 1.35s    remaining: 1.59s
918:    learn: 3716.7013645 total: 1.35s    remaining: 1.58s
919:    learn: 3716.7013645 total: 1.35s    remaining: 1.58s
920:    learn: 3716.1538803 total: 1.35s    remaining: 1.58s
921:    learn: 3715.6253818 total: 1.35s    remaining: 1.58s
922:    learn: 3715.0529522 total: 1.35s    remaining: 1.58s
923:    learn: 3714.5005523 total: 1.36s    remaining: 1.58s
924:    learn: 3712.1508975 total: 1.36s    remaining: 1.58s
925:    learn: 3711.6039564 total: 1.36s    remaining: 1.58s
926:    learn: 3710.1385822 total: 1.36s    remaining: 1.58s
927:    learn: 3708.9893699 total: 1.36s    remaining: 1.57s
928:    learn: 3708.9768362 total: 1.36s    remaining: 1.57s
929:    learn: 3708.9709846 total: 1.36s    remaining: 1.57s
930:    learn: 3708.4679536 total: 1.37s    remaining: 1.57s
931:    learn: 3707.2311610 total: 1.37s    remaining: 1.57s
932:    learn: 3707.0972053 total: 1.37s    remaining: 1.57s
933:    learn: 3706.8547678 total: 1.37s    remaining: 1.57s
934:    learn: 3704.6011174 total: 1.37s    remaining: 1.56s
935:    learn: 3702.5238173 total: 1.38s    remaining: 1.56s
936:    learn: 3702.4828780 total: 1.38s    remaining: 1.56s
937:    learn: 3702.4828780 total: 1.38s    remaining: 1.56s
938:    learn: 3702.3967813 total: 1.38s    remaining: 1.56s
939:    learn: 3702.0342639 total: 1.38s    remaining: 1.56s
940:    learn: 3701.1780133 total: 1.38s    remaining: 1.55s
941:    learn: 3700.7531695 total: 1.38s    remaining: 1.55s
942:    learn: 3700.4658106 total: 1.39s    remaining: 1.55s
943:    learn: 3699.2095210 total: 1.39s    remaining: 1.55s
944:    learn: 3699.0562756 total: 1.39s    remaining: 1.55s
945:    learn: 3699.0562756 total: 1.39s    remaining: 1.55s
946:    learn: 3698.2595417 total: 1.39s    remaining: 1.55s
947:    learn: 3695.5636725 total: 1.39s    remaining: 1.55s
948:    learn: 3694.5819843 total: 1.4s remaining: 1.55s
949:    learn: 3694.3462767 total: 1.4s remaining: 1.54s
950:    learn: 3693.6615322 total: 1.4s remaining: 1.54s
951:    learn: 3692.5638974 total: 1.4s remaining: 1.54s
952:    learn: 3692.5638974 total: 1.4s remaining: 1.54s
953:    learn: 3685.4910277 total: 1.4s remaining: 1.54s
954:    learn: 3685.2059786 total: 1.4s remaining: 1.54s
955:    learn: 3684.2455121 total: 1.41s    remaining: 1.54s
956:    learn: 3683.7580229 total: 1.41s    remaining: 1.53s
957:    learn: 3681.9457611 total: 1.41s    remaining: 1.53s
958:    learn: 3681.5652050 total: 1.41s    remaining: 1.53s
959:    learn: 3681.5652050 total: 1.41s    remaining: 1.53s
960:    learn: 3680.2135370 total: 1.41s    remaining: 1.53s
961:    learn: 3680.1767027 total: 1.42s    remaining: 1.53s
962:    learn: 3679.8473836 total: 1.42s    remaining: 1.53s
963:    learn: 3677.4207960 total: 1.42s    remaining: 1.52s
964:    learn: 3677.4207960 total: 1.42s    remaining: 1.52s
965:    learn: 3677.4188338 total: 1.42s    remaining: 1.52s
966:    learn: 3677.4188338 total: 1.42s    remaining: 1.52s
967:    learn: 3676.9216619 total: 1.42s    remaining: 1.52s
968:    learn: 3675.3089857 total: 1.42s    remaining: 1.51s
969:    learn: 3675.2688544 total: 1.43s    remaining: 1.51s
970:    learn: 3674.0677886 total: 1.43s    remaining: 1.51s
971:    learn: 3673.5915745 total: 1.43s    remaining: 1.51s
972:    learn: 3673.3693200 total: 1.43s    remaining: 1.51s
973:    learn: 3672.7873480 total: 1.43s    remaining: 1.51s
974:    learn: 3671.8253357 total: 1.43s    remaining: 1.51s
975:    learn: 3668.8709628 total: 1.44s    remaining: 1.51s
976:    learn: 3668.8709628 total: 1.44s    remaining: 1.5s
977:    learn: 3668.7627721 total: 1.44s    remaining: 1.5s
978:    learn: 3667.4786633 total: 1.44s    remaining: 1.5s
979:    learn: 3666.5861168 total: 1.44s    remaining: 1.5s
980:    learn: 3666.3023313 total: 1.44s    remaining: 1.5s
981:    learn: 3666.1529594 total: 1.44s    remaining: 1.5s
982:    learn: 3664.1631253 total: 1.45s    remaining: 1.5s
983:    learn: 3663.8921268 total: 1.45s    remaining: 1.5s
984:    learn: 3663.5891686 total: 1.45s    remaining: 1.49s
985:    learn: 3663.3478513 total: 1.45s    remaining: 1.49s
986:    learn: 3663.3443644 total: 1.45s    remaining: 1.49s
987:    learn: 3662.4739468 total: 1.45s    remaining: 1.49s
988:    learn: 3659.7979207 total: 1.46s    remaining: 1.49s
989:    learn: 3656.7774930 total: 1.46s    remaining: 1.49s
990:    learn: 3655.5815035 total: 1.46s    remaining: 1.49s
991:    learn: 3655.3199530 total: 1.46s    remaining: 1.48s
992:    learn: 3653.0603803 total: 1.46s    remaining: 1.48s
993:    learn: 3653.0603803 total: 1.46s    remaining: 1.48s
994:    learn: 3652.4369568 total: 1.46s    remaining: 1.48s
995:    learn: 3651.9836020 total: 1.47s    remaining: 1.48s
996:    learn: 3649.7055373 total: 1.47s    remaining: 1.48s
997:    learn: 3649.3310304 total: 1.47s    remaining: 1.48s
998:    learn: 3648.6113397 total: 1.47s    remaining: 1.47s
999:    learn: 3648.1952207 total: 1.47s    remaining: 1.47s
1000:   learn: 3647.6434249 total: 1.48s    remaining: 1.47s
1001:   learn: 3647.4992176 total: 1.48s    remaining: 1.47s
1002:   learn: 3647.4992176 total: 1.48s    remaining: 1.47s
1003:   learn: 3645.5814467 total: 1.48s    remaining: 1.47s
1004:   learn: 3645.1610774 total: 1.48s    remaining: 1.47s
1005:   learn: 3645.1130043 total: 1.48s    remaining: 1.47s
1006:   learn: 3643.9491608 total: 1.48s    remaining: 1.46s
1007:   learn: 3641.4554180 total: 1.49s    remaining: 1.46s
1008:   learn: 3640.8504319 total: 1.49s    remaining: 1.46s
1009:   learn: 3640.7715577 total: 1.49s    remaining: 1.46s
1010:   learn: 3640.6094922 total: 1.49s    remaining: 1.46s
1011:   learn: 3638.4023054 total: 1.49s    remaining: 1.46s
1012:   learn: 3636.7756918 total: 1.49s    remaining: 1.46s
1013:   learn: 3635.7462844 total: 1.5s remaining: 1.45s
1014:   learn: 3635.4468132 total: 1.5s remaining: 1.45s
1015:   learn: 3635.3983898 total: 1.5s remaining: 1.45s
1016:   learn: 3635.1676270 total: 1.5s remaining: 1.45s
1017:   learn: 3634.6068208 total: 1.5s remaining: 1.45s
1018:   learn: 3633.7610803 total: 1.5s remaining: 1.45s
1019:   learn: 3632.7942984 total: 1.51s    remaining: 1.45s
1020:   learn: 3630.7096665 total: 1.51s    remaining: 1.45s
1021:   learn: 3629.6153402 total: 1.51s    remaining: 1.45s
1022:   learn: 3629.5740763 total: 1.51s    remaining: 1.44s
1023:   learn: 3629.3666657 total: 1.51s    remaining: 1.44s
1024:   learn: 3628.5367924 total: 1.51s    remaining: 1.44s
1025:   learn: 3627.3209578 total: 1.52s    remaining: 1.44s
1026:   learn: 3627.0698097 total: 1.52s    remaining: 1.44s
1027:   learn: 3624.6297907 total: 1.52s    remaining: 1.44s
1028:   learn: 3624.2137850 total: 1.52s    remaining: 1.44s
1029:   learn: 3623.3317266 total: 1.52s    remaining: 1.43s
1030:   learn: 3623.0141339 total: 1.52s    remaining: 1.43s
1031:   learn: 3622.7357887 total: 1.53s    remaining: 1.43s
1032:   learn: 3622.3153971 total: 1.53s    remaining: 1.43s
1033:   learn: 3621.7364889 total: 1.53s    remaining: 1.43s
1034:   learn: 3621.2690431 total: 1.53s    remaining: 1.43s
1035:   learn: 3619.7498802 total: 1.53s    remaining: 1.43s
1036:   learn: 3617.4767168 total: 1.54s    remaining: 1.43s
1037:   learn: 3617.4767168 total: 1.54s    remaining: 1.42s
1038:   learn: 3616.3999831 total: 1.54s    remaining: 1.42s
1039:   learn: 3616.3999831 total: 1.54s    remaining: 1.42s
1040:   learn: 3616.3999831 total: 1.54s    remaining: 1.42s
1041:   learn: 3615.6974691 total: 1.54s    remaining: 1.42s
1042:   learn: 3613.3498141 total: 1.54s    remaining: 1.42s
1043:   learn: 3613.3498141 total: 1.54s    remaining: 1.41s
1044:   learn: 3612.5324436 total: 1.55s    remaining: 1.41s
1045:   learn: 3611.6863959 total: 1.55s    remaining: 1.41s
1046:   learn: 3611.6110633 total: 1.55s    remaining: 1.41s
1047:   learn: 3611.3409241 total: 1.55s    remaining: 1.41s
1048:   learn: 3609.1333550 total: 1.55s    remaining: 1.41s
1049:   learn: 3607.2325683 total: 1.55s    remaining: 1.41s
1050:   learn: 3606.8956123 total: 1.56s    remaining: 1.41s
1051:   learn: 3606.0445751 total: 1.56s    remaining: 1.4s
1052:   learn: 3604.8280679 total: 1.56s    remaining: 1.4s
1053:   learn: 3603.0442265 total: 1.56s    remaining: 1.4s
1054:   learn: 3603.0414058 total: 1.56s    remaining: 1.4s
1055:   learn: 3602.5215798 total: 1.56s    remaining: 1.4s
1056:   learn: 3601.7869199 total: 1.57s    remaining: 1.4s
1057:   learn: 3601.4903778 total: 1.57s    remaining: 1.4s
1058:   learn: 3601.4903778 total: 1.57s    remaining: 1.39s
1059:   learn: 3600.3736078 total: 1.57s    remaining: 1.39s
1060:   learn: 3599.3800476 total: 1.57s    remaining: 1.39s
1061:   learn: 3599.1596399 total: 1.57s    remaining: 1.39s
1062:   learn: 3598.7990757 total: 1.57s    remaining: 1.39s
1063:   learn: 3597.4087900 total: 1.58s    remaining: 1.39s
1064:   learn: 3597.2450173 total: 1.58s    remaining: 1.39s
1065:   learn: 3596.9727837 total: 1.58s    remaining: 1.39s
1066:   learn: 3596.3506297 total: 1.58s    remaining: 1.38s
1067:   learn: 3595.2715205 total: 1.58s    remaining: 1.38s
1068:   learn: 3593.1006259 total: 1.59s    remaining: 1.38s
1069:   learn: 3592.5959892 total: 1.59s    remaining: 1.38s
1070:   learn: 3592.5883966 total: 1.59s    remaining: 1.38s
1071:   learn: 3592.5343152 total: 1.59s    remaining: 1.38s
1072:   learn: 3592.4848819 total: 1.59s    remaining: 1.38s
1073:   learn: 3592.4848819 total: 1.59s    remaining: 1.38s
1074:   learn: 3591.5370427 total: 1.6s remaining: 1.37s
1075:   learn: 3591.1534654 total: 1.6s remaining: 1.37s
1076:   learn: 3591.0191414 total: 1.6s remaining: 1.37s
1077:   learn: 3590.7011409 total: 1.6s remaining: 1.37s
1078:   learn: 3590.3736424 total: 1.6s remaining: 1.37s
1079:   learn: 3589.1039583 total: 1.61s    remaining: 1.37s
1080:   learn: 3588.7743905 total: 1.61s    remaining: 1.37s
1081:   learn: 3588.5977644 total: 1.61s    remaining: 1.36s
1082:   learn: 3588.2087809 total: 1.61s    remaining: 1.36s
1083:   learn: 3587.7235973 total: 1.61s    remaining: 1.36s
1084:   learn: 3587.3342363 total: 1.62s    remaining: 1.36s
1085:   learn: 3587.2197299 total: 1.62s    remaining: 1.36s
1086:   learn: 3587.2138956 total: 1.62s    remaining: 1.36s
1087:   learn: 3586.5718200 total: 1.62s    remaining: 1.36s
1088:   learn: 3586.3580947 total: 1.62s    remaining: 1.36s
1089:   learn: 3585.3864547 total: 1.62s    remaining: 1.36s
1090:   learn: 3581.8700961 total: 1.63s    remaining: 1.35s
1091:   learn: 3581.4482743 total: 1.63s    remaining: 1.35s
1092:   learn: 3581.4247096 total: 1.63s    remaining: 1.35s
1093:   learn: 3581.0372065 total: 1.63s    remaining: 1.35s
1094:   learn: 3579.1062612 total: 1.63s    remaining: 1.35s
1095:   learn: 3579.1062612 total: 1.63s    remaining: 1.35s
1096:   learn: 3578.4765793 total: 1.64s    remaining: 1.35s
1097:   learn: 3578.2423896 total: 1.64s    remaining: 1.35s
1098:   learn: 3578.1712965 total: 1.64s    remaining: 1.34s
1099:   learn: 3575.3026950 total: 1.64s    remaining: 1.34s
1100:   learn: 3575.1259486 total: 1.64s    remaining: 1.34s
1101:   learn: 3573.3194123 total: 1.65s    remaining: 1.34s
1102:   learn: 3573.3081655 total: 1.65s    remaining: 1.34s
1103:   learn: 3573.2685013 total: 1.65s    remaining: 1.34s
1104:   learn: 3573.2685013 total: 1.65s    remaining: 1.34s
1105:   learn: 3572.4575298 total: 1.65s    remaining: 1.33s
1106:   learn: 3571.8274230 total: 1.65s    remaining: 1.33s
1107:   learn: 3571.6342525 total: 1.66s    remaining: 1.33s
1108:   learn: 3571.0126053 total: 1.66s    remaining: 1.33s
1109:   learn: 3569.9617541 total: 1.66s    remaining: 1.33s
1110:   learn: 3569.7106094 total: 1.66s    remaining: 1.33s
1111:   learn: 3569.5235690 total: 1.66s    remaining: 1.33s
1112:   learn: 3566.0157600 total: 1.66s    remaining: 1.33s
1113:   learn: 3564.8566264 total: 1.67s    remaining: 1.32s
1114:   learn: 3563.8169358 total: 1.67s    remaining: 1.32s
1115:   learn: 3563.1418067 total: 1.67s    remaining: 1.32s
1116:   learn: 3562.7999182 total: 1.67s    remaining: 1.32s
1117:   learn: 3562.6120048 total: 1.67s    remaining: 1.32s
1118:   learn: 3561.7899379 total: 1.68s    remaining: 1.32s
1119:   learn: 3561.5663789 total: 1.68s    remaining: 1.32s
1120:   learn: 3561.5653418 total: 1.68s    remaining: 1.32s
1121:   learn: 3560.3072786 total: 1.68s    remaining: 1.31s
1122:   learn: 3559.8587073 total: 1.68s    remaining: 1.31s
1123:   learn: 3559.8570120 total: 1.68s    remaining: 1.31s
1124:   learn: 3559.6594204 total: 1.69s    remaining: 1.31s
1125:   learn: 3557.8153776 total: 1.69s    remaining: 1.31s
1126:   learn: 3557.6496824 total: 1.69s    remaining: 1.31s
1127:   learn: 3557.6496824 total: 1.69s    remaining: 1.31s
1128:   learn: 3557.6496824 total: 1.69s    remaining: 1.3s
1129:   learn: 3557.2345494 total: 1.69s    remaining: 1.3s
1130:   learn: 3556.5439816 total: 1.7s remaining: 1.3s
1131:   learn: 3555.8897573 total: 1.7s remaining: 1.3s
1132:   learn: 3555.5143977 total: 1.7s remaining: 1.3s
1133:   learn: 3554.2410994 total: 1.7s remaining: 1.3s
1134:   learn: 3554.0107634 total: 1.71s    remaining: 1.3s
1135:   learn: 3553.9615743 total: 1.71s    remaining: 1.3s
1136:   learn: 3551.0941172 total: 1.71s    remaining: 1.3s
1137:   learn: 3550.3466574 total: 1.71s    remaining: 1.3s
1138:   learn: 3550.0225315 total: 1.72s    remaining: 1.3s
1139:   learn: 3550.0225315 total: 1.72s    remaining: 1.29s
1140:   learn: 3548.6873160 total: 1.72s    remaining: 1.29s
1141:   learn: 3547.3571996 total: 1.72s    remaining: 1.29s
1142:   learn: 3546.2323811 total: 1.73s    remaining: 1.29s
1143:   learn: 3545.2744841 total: 1.73s    remaining: 1.29s
1144:   learn: 3545.1597357 total: 1.73s    remaining: 1.29s
1145:   learn: 3545.1597357 total: 1.73s    remaining: 1.29s
1146:   learn: 3544.9196089 total: 1.73s    remaining: 1.29s
1147:   learn: 3542.6693975 total: 1.74s    remaining: 1.29s
1148:   learn: 3542.6693975 total: 1.74s    remaining: 1.29s
1149:   learn: 3542.0170374 total: 1.74s    remaining: 1.29s
1150:   learn: 3541.9987886 total: 1.74s    remaining: 1.29s
1151:   learn: 3541.4564659 total: 1.75s    remaining: 1.29s
1152:   learn: 3537.7902406 total: 1.75s    remaining: 1.29s
1153:   learn: 3535.9440933 total: 1.75s    remaining: 1.29s
1154:   learn: 3535.3618591 total: 1.76s    remaining: 1.29s
1155:   learn: 3534.0038064 total: 1.76s    remaining: 1.29s
1156:   learn: 3528.8624480 total: 1.77s    remaining: 1.29s
1157:   learn: 3528.8624480 total: 1.77s    remaining: 1.28s
1158:   learn: 3528.8624480 total: 1.77s    remaining: 1.28s
1159:   learn: 3528.5705897 total: 1.77s    remaining: 1.28s
1160:   learn: 3527.7039807 total: 1.77s    remaining: 1.28s
1161:   learn: 3526.8718806 total: 1.78s    remaining: 1.28s
1162:   learn: 3525.2002199 total: 1.78s    remaining: 1.28s
1163:   learn: 3524.7384686 total: 1.78s    remaining: 1.28s
1164:   learn: 3521.6204101 total: 1.78s    remaining: 1.28s
1165:   learn: 3521.0234755 total: 1.8s remaining: 1.29s
1166:   learn: 3516.6497800 total: 1.8s remaining: 1.29s
1167:   learn: 3516.0855787 total: 1.81s    remaining: 1.29s
1168:   learn: 3515.7976760 total: 1.81s    remaining: 1.29s
1169:   learn: 3515.5704574 total: 1.81s    remaining: 1.29s
1170:   learn: 3515.1427513 total: 1.82s    remaining: 1.29s
1171:   learn: 3515.0602849 total: 1.82s    remaining: 1.28s
1172:   learn: 3514.7638701 total: 1.82s    remaining: 1.28s
1173:   learn: 3513.5698655 total: 1.82s    remaining: 1.28s
1174:   learn: 3513.0935427 total: 1.82s    remaining: 1.28s
1175:   learn: 3512.7069115 total: 1.83s    remaining: 1.28s
1176:   learn: 3512.2088626 total: 1.83s    remaining: 1.28s
1177:   learn: 3511.8630839 total: 1.83s    remaining: 1.28s
1178:   learn: 3510.1118571 total: 1.83s    remaining: 1.28s
1179:   learn: 3509.9803469 total: 1.84s    remaining: 1.28s
1180:   learn: 3509.6869391 total: 1.84s    remaining: 1.27s
1181:   learn: 3507.4650152 total: 1.84s    remaining: 1.27s
1182:   learn: 3506.7078692 total: 1.84s    remaining: 1.27s
1183:   learn: 3504.7656726 total: 1.85s    remaining: 1.27s
1184:   learn: 3503.8159906 total: 1.85s    remaining: 1.27s
1185:   learn: 3503.8159906 total: 1.85s    remaining: 1.27s
1186:   learn: 3503.6273305 total: 1.85s    remaining: 1.27s
1187:   learn: 3503.6273305 total: 1.85s    remaining: 1.27s
1188:   learn: 3502.9832157 total: 1.85s    remaining: 1.26s
1189:   learn: 3502.7191578 total: 1.86s    remaining: 1.26s
1190:   learn: 3501.7102875 total: 1.86s    remaining: 1.26s
1191:   learn: 3501.6303065 total: 1.86s    remaining: 1.26s
1192:   learn: 3501.6303065 total: 1.86s    remaining: 1.26s
1193:   learn: 3500.2342721 total: 1.86s    remaining: 1.26s
1194:   learn: 3498.5046870 total: 1.87s    remaining: 1.26s
1195:   learn: 3497.4228105 total: 1.87s    remaining: 1.26s
1196:   learn: 3497.4228105 total: 1.87s    remaining: 1.25s
1197:   learn: 3496.7478212 total: 1.87s    remaining: 1.25s
1198:   learn: 3495.8283729 total: 1.88s    remaining: 1.25s
1199:   learn: 3495.8227030 total: 1.88s    remaining: 1.25s
1200:   learn: 3495.8195457 total: 1.88s    remaining: 1.25s
1201:   learn: 3495.8111827 total: 1.88s    remaining: 1.25s
1202:   learn: 3495.3319656 total: 1.88s    remaining: 1.25s
1203:   learn: 3494.7155581 total: 1.88s    remaining: 1.25s
1204:   learn: 3494.7155581 total: 1.88s    remaining: 1.24s
1205:   learn: 3494.4485050 total: 1.89s    remaining: 1.24s
1206:   learn: 3493.8914014 total: 1.89s    remaining: 1.24s
1207:   learn: 3493.4939211 total: 1.89s    remaining: 1.24s
1208:   learn: 3493.3499219 total: 1.89s    remaining: 1.24s
1209:   learn: 3492.0621516 total: 1.89s    remaining: 1.24s
1210:   learn: 3491.9988867 total: 1.9s remaining: 1.24s
1211:   learn: 3491.9983620 total: 1.9s remaining: 1.23s
1212:   learn: 3489.3417180 total: 1.9s remaining: 1.23s
1213:   learn: 3489.1380101 total: 1.9s remaining: 1.23s
1214:   learn: 3489.1380101 total: 1.9s remaining: 1.23s
1215:   learn: 3489.1380101 total: 1.9s remaining: 1.23s
1216:   learn: 3489.1340465 total: 1.91s    remaining: 1.23s
1217:   learn: 3489.1340465 total: 1.91s    remaining: 1.22s
1218:   learn: 3489.1340465 total: 1.91s    remaining: 1.22s
1219:   learn: 3489.0039633 total: 1.91s    remaining: 1.22s
1220:   learn: 3489.0039633 total: 1.91s    remaining: 1.22s
1221:   learn: 3488.9564392 total: 1.91s    remaining: 1.22s
1222:   learn: 3488.9564392 total: 1.92s    remaining: 1.22s
1223:   learn: 3488.9564392 total: 1.92s    remaining: 1.21s
1224:   learn: 3487.9908790 total: 1.92s    remaining: 1.21s
1225:   learn: 3487.7033151 total: 1.92s    remaining: 1.21s
1226:   learn: 3487.4716292 total: 1.92s    remaining: 1.21s
1227:   learn: 3487.4421957 total: 1.93s    remaining: 1.21s
1228:   learn: 3487.4417232 total: 1.93s    remaining: 1.21s
1229:   learn: 3486.1161129 total: 1.93s    remaining: 1.21s
1230:   learn: 3485.3868887 total: 1.93s    remaining: 1.21s
1231:   learn: 3485.0605288 total: 1.94s    remaining: 1.21s
1232:   learn: 3485.0067723 total: 1.94s    remaining: 1.21s
1233:   learn: 3483.1809236 total: 1.94s    remaining: 1.2s
1234:   learn: 3481.3149412 total: 1.94s    remaining: 1.2s
1235:   learn: 3481.1425501 total: 1.95s    remaining: 1.2s
1236:   learn: 3481.1425501 total: 1.95s    remaining: 1.2s
1237:   learn: 3480.8921921 total: 1.95s    remaining: 1.2s
1238:   learn: 3480.3199413 total: 1.95s    remaining: 1.2s
1239:   learn: 3480.3199413 total: 1.96s    remaining: 1.2s
1240:   learn: 3479.3737682 total: 1.96s    remaining: 1.2s
1241:   learn: 3478.0905011 total: 1.96s    remaining: 1.2s
1242:   learn: 3476.7956632 total: 1.96s    remaining: 1.2s
1243:   learn: 3476.3331213 total: 1.97s    remaining: 1.2s
1244:   learn: 3476.0137821 total: 1.97s    remaining: 1.2s
1245:   learn: 3473.3929457 total: 1.97s    remaining: 1.19s
1246:   learn: 3473.3929457 total: 1.97s    remaining: 1.19s
1247:   learn: 3468.8674239 total: 1.98s    remaining: 1.19s
1248:   learn: 3468.5034134 total: 1.98s    remaining: 1.19s
1249:   learn: 3468.5034134 total: 1.98s    remaining: 1.19s
1250:   learn: 3468.3679050 total: 1.98s    remaining: 1.19s
1251:   learn: 3468.3679050 total: 1.98s    remaining: 1.18s
1252:   learn: 3467.6336042 total: 1.98s    remaining: 1.18s
1253:   learn: 3466.0650105 total: 1.99s    remaining: 1.18s
1254:   learn: 3465.5514242 total: 1.99s    remaining: 1.18s
1255:   learn: 3464.7760892 total: 1.99s    remaining: 1.18s
1256:   learn: 3464.7760892 total: 1.99s    remaining: 1.18s
1257:   learn: 3464.7052528 total: 1.99s    remaining: 1.17s
1258:   learn: 3464.2389179 total: 1.99s    remaining: 1.17s
1259:   learn: 3464.2389179 total: 1.99s    remaining: 1.17s
1260:   learn: 3463.7080189 total: 2s   remaining: 1.17s
1261:   learn: 3463.6448661 total: 2s   remaining: 1.17s
1262:   learn: 3463.4723039 total: 2s   remaining: 1.17s
1263:   learn: 3463.4214435 total: 2s   remaining: 1.17s
1264:   learn: 3462.4528015 total: 2.01s    remaining: 1.17s
1265:   learn: 3462.3418798 total: 2.01s    remaining: 1.16s
1266:   learn: 3461.0735834 total: 2.01s    remaining: 1.16s
1267:   learn: 3460.9924441 total: 2.01s    remaining: 1.16s
1268:   learn: 3460.8876125 total: 2.02s    remaining: 1.16s
1269:   learn: 3460.4933662 total: 2.02s    remaining: 1.16s
1270:   learn: 3460.4919842 total: 2.02s    remaining: 1.16s
1271:   learn: 3460.4035048 total: 2.02s    remaining: 1.16s
1272:   learn: 3460.4035048 total: 2.02s    remaining: 1.15s
1273:   learn: 3459.3359575 total: 2.02s    remaining: 1.15s
1274:   learn: 3457.8199183 total: 2.02s    remaining: 1.15s
1275:   learn: 3457.4863670 total: 2.03s    remaining: 1.15s
1276:   learn: 3455.8452690 total: 2.03s    remaining: 1.15s
1277:   learn: 3455.0689443 total: 2.03s    remaining: 1.15s
1278:   learn: 3455.0689443 total: 2.03s    remaining: 1.14s
1279:   learn: 3454.6749412 total: 2.03s    remaining: 1.14s
1280:   learn: 3453.5278084 total: 2.04s    remaining: 1.14s
1281:   learn: 3453.3104756 total: 2.04s    remaining: 1.14s
1282:   learn: 3453.0127466 total: 2.04s    remaining: 1.14s
1283:   learn: 3452.9312517 total: 2.04s    remaining: 1.14s
1284:   learn: 3452.6055727 total: 2.04s    remaining: 1.14s
1285:   learn: 3451.5120403 total: 2.04s    remaining: 1.13s
1286:   learn: 3450.9189052 total: 2.04s    remaining: 1.13s
1287:   learn: 3450.9154103 total: 2.05s    remaining: 1.13s
1288:   learn: 3449.6982402 total: 2.05s    remaining: 1.13s
1289:   learn: 3449.0524982 total: 2.05s    remaining: 1.13s
1290:   learn: 3448.8385412 total: 2.05s    remaining: 1.13s
1291:   learn: 3448.8385412 total: 2.05s    remaining: 1.12s
1292:   learn: 3448.6875173 total: 2.05s    remaining: 1.12s
1293:   learn: 3447.7991746 total: 2.06s    remaining: 1.12s
1294:   learn: 3446.8332555 total: 2.06s    remaining: 1.12s
1295:   learn: 3446.7066740 total: 2.06s    remaining: 1.12s
1296:   learn: 3446.7066740 total: 2.06s    remaining: 1.12s
1297:   learn: 3440.0124138 total: 2.06s    remaining: 1.11s
1298:   learn: 3439.1136582 total: 2.06s    remaining: 1.11s
1299:   learn: 3438.8334759 total: 2.06s    remaining: 1.11s
1300:   learn: 3437.5049112 total: 2.07s    remaining: 1.11s
1301:   learn: 3436.4869249 total: 2.07s    remaining: 1.11s
1302:   learn: 3436.3743441 total: 2.07s    remaining: 1.11s
1303:   learn: 3436.3743441 total: 2.07s    remaining: 1.1s
1304:   learn: 3436.3743441 total: 2.07s    remaining: 1.1s
1305:   learn: 3436.3743441 total: 2.07s    remaining: 1.1s
1306:   learn: 3435.9674258 total: 2.07s    remaining: 1.1s
1307:   learn: 3435.7246142 total: 2.07s    remaining: 1.1s
1308:   learn: 3435.6276167 total: 2.08s    remaining: 1.09s
1309:   learn: 3434.9562900 total: 2.08s    remaining: 1.09s
1310:   learn: 3433.9987724 total: 2.08s    remaining: 1.09s
1311:   learn: 3433.6087305 total: 2.08s    remaining: 1.09s
1312:   learn: 3433.4416265 total: 2.08s    remaining: 1.09s
1313:   learn: 3433.4416265 total: 2.08s    remaining: 1.09s
1314:   learn: 3432.1607968 total: 2.08s    remaining: 1.08s
1315:   learn: 3432.1607968 total: 2.08s    remaining: 1.08s
1316:   learn: 3431.2901737 total: 2.09s    remaining: 1.08s
1317:   learn: 3429.9883872 total: 2.09s    remaining: 1.08s
1318:   learn: 3429.9284206 total: 2.09s    remaining: 1.08s
1319:   learn: 3429.8485066 total: 2.09s    remaining: 1.08s
1320:   learn: 3429.8485066 total: 2.09s    remaining: 1.07s
1321:   learn: 3428.8791224 total: 2.09s    remaining: 1.07s
1322:   learn: 3428.1362123 total: 2.1s remaining: 1.07s
1323:   learn: 3426.5251308 total: 2.1s remaining: 1.07s
1324:   learn: 3426.2746341 total: 2.1s remaining: 1.07s
1325:   learn: 3426.2746341 total: 2.1s remaining: 1.07s
1326:   learn: 3426.2746341 total: 2.1s remaining: 1.06s
1327:   learn: 3425.9170980 total: 2.1s remaining: 1.06s
1328:   learn: 3425.3611482 total: 2.1s remaining: 1.06s
1329:   learn: 3424.4659138 total: 2.1s remaining: 1.06s
1330:   learn: 3423.9350526 total: 2.1s remaining: 1.06s
1331:   learn: 3422.9492344 total: 2.11s    remaining: 1.06s
1332:   learn: 3421.7893589 total: 2.11s    remaining: 1.05s
1333:   learn: 3421.5134698 total: 2.11s    remaining: 1.05s
1334:   learn: 3421.2251437 total: 2.11s    remaining: 1.05s
1335:   learn: 3420.8226376 total: 2.11s    remaining: 1.05s
1336:   learn: 3420.5664151 total: 2.12s    remaining: 1.05s
1337:   learn: 3420.5664151 total: 2.12s    remaining: 1.05s
1338:   learn: 3420.5664151 total: 2.12s    remaining: 1.04s
1339:   learn: 3420.5664151 total: 2.12s    remaining: 1.04s
1340:   learn: 3419.8780256 total: 2.12s    remaining: 1.04s
1341:   learn: 3419.0746453 total: 2.12s    remaining: 1.04s
1342:   learn: 3419.0746453 total: 2.12s    remaining: 1.04s
1343:   learn: 3419.0734552 total: 2.12s    remaining: 1.03s
1344:   learn: 3418.4145722 total: 2.12s    remaining: 1.03s
1345:   learn: 3418.1149355 total: 2.12s    remaining: 1.03s
1346:   learn: 3417.9532152 total: 2.13s    remaining: 1.03s
1347:   learn: 3417.5387633 total: 2.13s    remaining: 1.03s
1348:   learn: 3416.8310578 total: 2.13s    remaining: 1.03s
1349:   learn: 3416.8310578 total: 2.13s    remaining: 1.02s
1350:   learn: 3416.8310578 total: 2.13s    remaining: 1.02s
1351:   learn: 3416.8310578 total: 2.13s    remaining: 1.02s
1352:   learn: 3416.2403108 total: 2.13s    remaining: 1.02s
1353:   learn: 3415.5193738 total: 2.13s    remaining: 1.02s
1354:   learn: 3414.9793795 total: 2.13s    remaining: 1.02s
1355:   learn: 3414.8846548 total: 2.14s    remaining: 1.01s
1356:   learn: 3414.6135055 total: 2.14s    remaining: 1.01s
1357:   learn: 3414.4637963 total: 2.14s    remaining: 1.01s
1358:   learn: 3414.1424451 total: 2.14s    remaining: 1.01s
1359:   learn: 3414.1235906 total: 2.14s    remaining: 1.01s
1360:   learn: 3413.8978249 total: 2.15s    remaining: 1.01s
1361:   learn: 3413.8978249 total: 2.15s    remaining: 1s
1362:   learn: 3413.2717749 total: 2.15s    remaining: 1s
1363:   learn: 3413.1662130 total: 2.15s    remaining: 1s
1364:   learn: 3413.1662130 total: 2.15s    remaining: 1s
1365:   learn: 3412.5539553 total: 2.15s    remaining: 999ms
1366:   learn: 3412.5539553 total: 2.15s    remaining: 997ms
1367:   learn: 3412.2162145 total: 2.15s    remaining: 995ms
1368:   learn: 3411.7199549 total: 2.16s    remaining: 994ms
1369:   learn: 3410.7213858 total: 2.16s    remaining: 992ms
1370:   learn: 3410.7213858 total: 2.16s    remaining: 990ms
1371:   learn: 3410.7130116 total: 2.16s    remaining: 989ms
1372:   learn: 3409.6714120 total: 2.16s    remaining: 987ms
1373:   learn: 3407.0469234 total: 2.16s    remaining: 985ms
1374:   learn: 3406.8334734 total: 2.16s    remaining: 984ms
1375:   learn: 3405.7944436 total: 2.17s    remaining: 982ms
1376:   learn: 3404.3862481 total: 2.17s    remaining: 981ms
1377:   learn: 3404.1123839 total: 2.17s    remaining: 979ms
1378:   learn: 3403.9273859 total: 2.17s    remaining: 978ms
1379:   learn: 3403.8005365 total: 2.17s    remaining: 976ms
1380:   learn: 3403.4403922 total: 2.17s    remaining: 975ms
1381:   learn: 3402.6081195 total: 2.17s    remaining: 973ms
1382:   learn: 3402.1766047 total: 2.18s    remaining: 971ms
1383:   learn: 3402.0382933 total: 2.18s    remaining: 970ms
1384:   learn: 3401.9022868 total: 2.18s    remaining: 968ms
1385:   learn: 3401.9022868 total: 2.18s    remaining: 966ms
1386:   learn: 3401.4068753 total: 2.18s    remaining: 965ms
1387:   learn: 3400.9534708 total: 2.18s    remaining: 963ms
1388:   learn: 3400.0592208 total: 2.19s    remaining: 962ms
1389:   learn: 3399.9068631 total: 2.19s    remaining: 960ms
1390:   learn: 3399.7704808 total: 2.19s    remaining: 959ms
1391:   learn: 3398.3180640 total: 2.19s    remaining: 957ms
1392:   learn: 3398.1779493 total: 2.19s    remaining: 955ms
1393:   learn: 3397.4052751 total: 2.19s    remaining: 954ms
1394:   learn: 3397.3551202 total: 2.19s    remaining: 952ms
1395:   learn: 3397.3551202 total: 2.2s remaining: 950ms
1396:   learn: 3397.3032297 total: 2.2s remaining: 949ms
1397:   learn: 3396.4413072 total: 2.2s remaining: 947ms
1398:   learn: 3396.1246833 total: 2.2s remaining: 946ms
1399:   learn: 3396.1246833 total: 2.2s remaining: 944ms
1400:   learn: 3393.3386727 total: 2.2s remaining: 943ms
1401:   learn: 3393.0818296 total: 2.21s    remaining: 941ms
1402:   learn: 3392.3444709 total: 2.21s    remaining: 940ms
1403:   learn: 3392.3188682 total: 2.21s    remaining: 938ms
1404:   learn: 3392.3180694 total: 2.21s    remaining: 936ms
1405:   learn: 3391.6507938 total: 2.21s    remaining: 934ms
1406:   learn: 3391.3211071 total: 2.21s    remaining: 933ms
1407:   learn: 3391.3199251 total: 2.21s    remaining: 931ms
1408:   learn: 3390.2805332 total: 2.22s    remaining: 930ms
1409:   learn: 3389.8258158 total: 2.22s    remaining: 928ms
1410:   learn: 3388.7130263 total: 2.22s    remaining: 927ms
1411:   learn: 3386.4266049 total: 2.22s    remaining: 925ms
1412:   learn: 3385.1734910 total: 2.22s    remaining: 924ms
1413:   learn: 3381.9668231 total: 2.23s    remaining: 923ms
1414:   learn: 3381.3037243 total: 2.23s    remaining: 921ms
1415:   learn: 3381.2345977 total: 2.23s    remaining: 920ms
1416:   learn: 3380.8300046 total: 2.23s    remaining: 919ms
1417:   learn: 3377.9959849 total: 2.23s    remaining: 917ms
1418:   learn: 3377.2197494 total: 2.24s    remaining: 916ms
1419:   learn: 3377.0327590 total: 2.24s    remaining: 914ms
1420:   learn: 3377.0327590 total: 2.24s    remaining: 912ms
1421:   learn: 3376.5109946 total: 2.24s    remaining: 911ms
1422:   learn: 3376.5038494 total: 2.24s    remaining: 909ms
1423:   learn: 3375.7564955 total: 2.24s    remaining: 908ms
1424:   learn: 3375.6156596 total: 2.25s    remaining: 906ms
1425:   learn: 3375.4890280 total: 2.25s    remaining: 905ms
1426:   learn: 3375.1804910 total: 2.25s    remaining: 904ms
1427:   learn: 3375.1536405 total: 2.25s    remaining: 903ms
1428:   learn: 3375.0401643 total: 2.25s    remaining: 901ms
1429:   learn: 3374.4391521 total: 2.26s    remaining: 899ms
1430:   learn: 3374.1964831 total: 2.26s    remaining: 898ms
1431:   learn: 3374.1497595 total: 2.26s    remaining: 897ms
1432:   learn: 3374.1493869 total: 2.26s    remaining: 895ms
1433:   learn: 3373.8020310 total: 2.26s    remaining: 893ms
1434:   learn: 3373.8020310 total: 2.26s    remaining: 891ms
1435:   learn: 3373.8020310 total: 2.26s    remaining: 889ms
1436:   learn: 3373.8020310 total: 2.26s    remaining: 887ms
1437:   learn: 3373.7951891 total: 2.27s    remaining: 886ms
1438:   learn: 3373.7019291 total: 2.27s    remaining: 884ms
1439:   learn: 3371.3433288 total: 2.27s    remaining: 883ms
1440:   learn: 3371.3234119 total: 2.27s    remaining: 881ms
1441:   learn: 3371.0762139 total: 2.27s    remaining: 880ms
1442:   learn: 3370.8838681 total: 2.28s    remaining: 879ms
1443:   learn: 3370.1963553 total: 2.28s    remaining: 877ms
1444:   learn: 3369.8998741 total: 2.28s    remaining: 876ms
1445:   learn: 3368.6938579 total: 2.28s    remaining: 875ms
1446:   learn: 3368.4789147 total: 2.28s    remaining: 873ms
1447:   learn: 3368.3351815 total: 2.29s    remaining: 871ms
1448:   learn: 3366.8936917 total: 2.29s    remaining: 870ms
1449:   learn: 3366.8388420 total: 2.29s    remaining: 868ms
1450:   learn: 3366.7271114 total: 2.29s    remaining: 867ms
1451:   learn: 3366.7271114 total: 2.29s    remaining: 865ms
1452:   learn: 3366.7271114 total: 2.29s    remaining: 863ms
1453:   learn: 3366.7261233 total: 2.29s    remaining: 861ms
1454:   learn: 3366.5542195 total: 2.29s    remaining: 860ms
1455:   learn: 3366.4240616 total: 2.3s remaining: 858ms
1456:   learn: 3365.8210886 total: 2.3s remaining: 857ms
1457:   learn: 3364.7499193 total: 2.3s remaining: 855ms
1458:   learn: 3364.7499193 total: 2.3s remaining: 853ms
1459:   learn: 3364.4529790 total: 2.3s remaining: 852ms
1460:   learn: 3363.8600341 total: 2.3s remaining: 850ms
1461:   learn: 3363.7260588 total: 2.31s    remaining: 849ms
1462:   learn: 3362.7257758 total: 2.31s    remaining: 847ms
1463:   learn: 3361.8405663 total: 2.31s    remaining: 845ms
1464:   learn: 3361.3130622 total: 2.31s    remaining: 844ms
1465:   learn: 3361.3130622 total: 2.31s    remaining: 842ms
1466:   learn: 3360.9499820 total: 2.31s    remaining: 840ms
1467:   learn: 3358.8757138 total: 2.31s    remaining: 839ms
1468:   learn: 3358.8757138 total: 2.31s    remaining: 837ms
1469:   learn: 3358.4843122 total: 2.32s    remaining: 835ms
1470:   learn: 3358.1180199 total: 2.32s    remaining: 834ms
1471:   learn: 3357.6770658 total: 2.32s    remaining: 832ms
1472:   learn: 3357.5197320 total: 2.32s    remaining: 830ms
1473:   learn: 3357.2766382 total: 2.32s    remaining: 829ms
1474:   learn: 3356.2353078 total: 2.32s    remaining: 827ms
1475:   learn: 3355.3662159 total: 2.33s    remaining: 826ms
1476:   learn: 3355.1446737 total: 2.33s    remaining: 824ms
1477:   learn: 3355.1446737 total: 2.33s    remaining: 822ms
1478:   learn: 3355.1440713 total: 2.33s    remaining: 820ms
1479:   learn: 3355.1400279 total: 2.33s    remaining: 819ms
1480:   learn: 3355.1400279 total: 2.33s    remaining: 817ms
1481:   learn: 3354.4871633 total: 2.33s    remaining: 815ms
1482:   learn: 3354.4270963 total: 2.33s    remaining: 814ms
1483:   learn: 3354.4181495 total: 2.33s    remaining: 812ms
1484:   learn: 3354.1594655 total: 2.34s    remaining: 810ms
1485:   learn: 3353.2292466 total: 2.34s    remaining: 809ms
1486:   learn: 3353.2292466 total: 2.34s    remaining: 807ms
1487:   learn: 3353.1014820 total: 2.34s    remaining: 805ms
1488:   learn: 3353.0987823 total: 2.34s    remaining: 803ms
1489:   learn: 3353.0761911 total: 2.34s    remaining: 801ms
1490:   learn: 3353.0761911 total: 2.34s    remaining: 800ms
1491:   learn: 3352.9010122 total: 2.34s    remaining: 798ms
1492:   learn: 3352.6327161 total: 2.35s    remaining: 796ms
1493:   learn: 3351.5962084 total: 2.35s    remaining: 795ms
1494:   learn: 3351.5962084 total: 2.35s    remaining: 793ms
1495:   learn: 3350.1006470 total: 2.35s    remaining: 791ms
1496:   learn: 3350.1006470 total: 2.35s    remaining: 790ms
1497:   learn: 3350.0253032 total: 2.35s    remaining: 788ms
1498:   learn: 3349.5414000 total: 2.35s    remaining: 787ms
1499:   learn: 3349.4987197 total: 2.35s    remaining: 785ms
1500:   learn: 3349.2979973 total: 2.36s    remaining: 783ms
1501:   learn: 3349.1114527 total: 2.36s    remaining: 782ms
1502:   learn: 3348.9814439 total: 2.36s    remaining: 780ms
1503:   learn: 3348.2336001 total: 2.36s    remaining: 779ms
1504:   learn: 3348.2336001 total: 2.36s    remaining: 777ms
1505:   learn: 3348.2336001 total: 2.36s    remaining: 775ms
1506:   learn: 3347.9761559 total: 2.36s    remaining: 773ms
1507:   learn: 3345.8139572 total: 2.37s    remaining: 772ms
1508:   learn: 3344.4834264 total: 2.37s    remaining: 770ms
1509:   learn: 3344.0163725 total: 2.37s    remaining: 769ms
1510:   learn: 3344.0163725 total: 2.37s    remaining: 767ms
1511:   learn: 3343.9811918 total: 2.37s    remaining: 765ms
1512:   learn: 3343.8073597 total: 2.37s    remaining: 764ms
1513:   learn: 3343.5492516 total: 2.37s    remaining: 762ms
1514:   learn: 3343.5492516 total: 2.37s    remaining: 760ms
1515:   learn: 3343.0367120 total: 2.38s    remaining: 758ms
1516:   learn: 3341.9384454 total: 2.38s    remaining: 757ms
1517:   learn: 3341.2393729 total: 2.38s    remaining: 755ms
1518:   learn: 3340.1546795 total: 2.38s    remaining: 754ms
1519:   learn: 3340.1546795 total: 2.38s    remaining: 752ms
1520:   learn: 3339.2131062 total: 2.38s    remaining: 751ms
1521:   learn: 3338.8641810 total: 2.38s    remaining: 749ms
1522:   learn: 3338.8641810 total: 2.38s    remaining: 747ms
1523:   learn: 3338.8441572 total: 2.39s    remaining: 745ms
1524:   learn: 3338.7404088 total: 2.39s    remaining: 744ms
1525:   learn: 3338.5734868 total: 2.39s    remaining: 742ms
1526:   learn: 3338.1755709 total: 2.39s    remaining: 741ms
1527:   learn: 3338.1263132 total: 2.39s    remaining: 740ms
1528:   learn: 3336.8059586 total: 2.4s remaining: 738ms
1529:   learn: 3336.7759575 total: 2.4s remaining: 737ms
1530:   learn: 3333.9289410 total: 2.4s remaining: 736ms
1531:   learn: 3333.9082217 total: 2.4s remaining: 734ms
1532:   learn: 3333.2865190 total: 2.4s remaining: 732ms
1533:   learn: 3332.0903192 total: 2.41s    remaining: 731ms
1534:   learn: 3332.0516926 total: 2.41s    remaining: 729ms
1535:   learn: 3331.9876738 total: 2.41s    remaining: 728ms
1536:   learn: 3331.9876738 total: 2.41s    remaining: 726ms
1537:   learn: 3331.9876738 total: 2.41s    remaining: 725ms
1538:   learn: 3325.7763364 total: 2.41s    remaining: 723ms
1539:   learn: 3325.5592471 total: 2.42s    remaining: 722ms
1540:   learn: 3324.5254327 total: 2.42s    remaining: 720ms
1541:   learn: 3323.4979834 total: 2.42s    remaining: 719ms
1542:   learn: 3323.4979834 total: 2.42s    remaining: 717ms
1543:   learn: 3323.2673846 total: 2.42s    remaining: 715ms
1544:   learn: 3323.1182052 total: 2.42s    remaining: 714ms
1545:   learn: 3323.0203677 total: 2.43s    remaining: 712ms
1546:   learn: 3323.0203677 total: 2.43s    remaining: 711ms
1547:   learn: 3322.3440984 total: 2.43s    remaining: 709ms
1548:   learn: 3321.0069035 total: 2.43s    remaining: 708ms
1549:   learn: 3320.0109679 total: 2.43s    remaining: 706ms
1550:   learn: 3319.6187768 total: 2.43s    remaining: 705ms
1551:   learn: 3318.7561915 total: 2.44s    remaining: 703ms
1552:   learn: 3317.9903066 total: 2.44s    remaining: 701ms
1553:   learn: 3317.6085681 total: 2.44s    remaining: 700ms
1554:   learn: 3317.3450224 total: 2.44s    remaining: 698ms
1555:   learn: 3316.8069448 total: 2.44s    remaining: 697ms
1556:   learn: 3316.8069448 total: 2.44s    remaining: 695ms
1557:   learn: 3316.7241953 total: 2.44s    remaining: 693ms
1558:   learn: 3316.6687696 total: 2.44s    remaining: 692ms
1559:   learn: 3316.5287101 total: 2.45s    remaining: 690ms
1560:   learn: 3315.8917801 total: 2.45s    remaining: 688ms
1561:   learn: 3312.5867515 total: 2.45s    remaining: 687ms
1562:   learn: 3312.1214123 total: 2.45s    remaining: 685ms
1563:   learn: 3312.1214123 total: 2.45s    remaining: 683ms
1564:   learn: 3312.0073329 total: 2.45s    remaining: 682ms
1565:   learn: 3311.9389137 total: 2.45s    remaining: 680ms
1566:   learn: 3310.6658293 total: 2.46s    remaining: 679ms
1567:   learn: 3309.9400964 total: 2.46s    remaining: 677ms
1568:   learn: 3308.8312949 total: 2.46s    remaining: 675ms
1569:   learn: 3308.7929726 total: 2.46s    remaining: 674ms
1570:   learn: 3308.3089963 total: 2.46s    remaining: 672ms
1571:   learn: 3308.3089963 total: 2.46s    remaining: 670ms
1572:   learn: 3308.1719911 total: 2.46s    remaining: 669ms
1573:   learn: 3308.1719876 total: 2.46s    remaining: 667ms
1574:   learn: 3307.5168749 total: 2.46s    remaining: 665ms
1575:   learn: 3307.2858943 total: 2.47s    remaining: 664ms
1576:   learn: 3307.1156302 total: 2.47s    remaining: 662ms
1577:   learn: 3305.3260678 total: 2.47s    remaining: 661ms
1578:   learn: 3304.6730614 total: 2.47s    remaining: 659ms
1579:   learn: 3304.2796680 total: 2.47s    remaining: 658ms
1580:   learn: 3303.7745689 total: 2.48s    remaining: 656ms
1581:   learn: 3303.6877004 total: 2.48s    remaining: 654ms
1582:   learn: 3302.7013801 total: 2.48s    remaining: 653ms
1583:   learn: 3302.6610349 total: 2.48s    remaining: 651ms
1584:   learn: 3302.4571914 total: 2.48s    remaining: 650ms
1585:   learn: 3302.3956629 total: 2.48s    remaining: 648ms
1586:   learn: 3302.3956629 total: 2.48s    remaining: 646ms
1587:   learn: 3302.3749386 total: 2.48s    remaining: 645ms
1588:   learn: 3302.3163183 total: 2.49s    remaining: 643ms
1589:   learn: 3300.9251761 total: 2.49s    remaining: 642ms
1590:   learn: 3300.7916655 total: 2.49s    remaining: 640ms
1591:   learn: 3300.2545046 total: 2.49s    remaining: 639ms
1592:   learn: 3300.0773203 total: 2.49s    remaining: 637ms
1593:   learn: 3300.0773203 total: 2.49s    remaining: 635ms
1594:   learn: 3299.7183538 total: 2.5s remaining: 634ms
1595:   learn: 3299.5508090 total: 2.5s remaining: 632ms
1596:   learn: 3299.4992761 total: 2.5s remaining: 631ms
1597:   learn: 3299.0124633 total: 2.5s remaining: 629ms
1598:   learn: 3298.1226298 total: 2.5s remaining: 628ms
1599:   learn: 3298.1226298 total: 2.5s remaining: 626ms
1600:   learn: 3298.1226298 total: 2.5s remaining: 624ms
1601:   learn: 3297.9845713 total: 2.51s    remaining: 623ms
1602:   learn: 3297.9165567 total: 2.51s    remaining: 621ms
1603:   learn: 3297.8466098 total: 2.51s    remaining: 620ms
1604:   learn: 3297.8466098 total: 2.51s    remaining: 618ms
1605:   learn: 3297.6440647 total: 2.51s    remaining: 616ms
1606:   learn: 3297.3682602 total: 2.51s    remaining: 615ms
1607:   learn: 3296.5167491 total: 2.52s    remaining: 613ms
1608:   learn: 3296.5167491 total: 2.52s    remaining: 612ms
1609:   learn: 3295.8563649 total: 2.52s    remaining: 610ms
1610:   learn: 3295.8494358 total: 2.52s    remaining: 608ms
1611:   learn: 3294.8414772 total: 2.52s    remaining: 607ms
1612:   learn: 3294.7052746 total: 2.52s    remaining: 606ms
1613:   learn: 3292.9427939 total: 2.52s    remaining: 604ms
1614:   learn: 3290.8777820 total: 2.53s    remaining: 603ms
1615:   learn: 3290.2602050 total: 2.53s    remaining: 601ms
1616:   learn: 3290.1507549 total: 2.53s    remaining: 600ms
1617:   learn: 3289.8034961 total: 2.53s    remaining: 598ms
1618:   learn: 3287.2757282 total: 2.54s    remaining: 597ms
1619:   learn: 3286.3824528 total: 2.54s    remaining: 595ms
1620:   learn: 3286.0591981 total: 2.54s    remaining: 593ms
1621:   learn: 3285.7938179 total: 2.54s    remaining: 592ms
1622:   learn: 3285.7938179 total: 2.54s    remaining: 590ms
1623:   learn: 3285.7938179 total: 2.54s    remaining: 588ms
1624:   learn: 3285.7921888 total: 2.54s    remaining: 587ms
1625:   learn: 3285.7808692 total: 2.54s    remaining: 585ms
1626:   learn: 3285.7808692 total: 2.54s    remaining: 583ms
1627:   learn: 3285.6991139 total: 2.54s    remaining: 582ms
1628:   learn: 3285.6384378 total: 2.55s    remaining: 580ms
1629:   learn: 3285.6384378 total: 2.55s    remaining: 578ms
1630:   learn: 3284.5288549 total: 2.55s    remaining: 577ms
1631:   learn: 3284.1414311 total: 2.55s    remaining: 575ms
1632:   learn: 3284.0838173 total: 2.55s    remaining: 574ms
1633:   learn: 3284.0065353 total: 2.56s    remaining: 572ms
1634:   learn: 3284.0065353 total: 2.56s    remaining: 571ms
1635:   learn: 3283.8020325 total: 2.56s    remaining: 569ms
1636:   learn: 3279.9206222 total: 2.56s    remaining: 568ms
1637:   learn: 3279.9206222 total: 2.56s    remaining: 566ms
1638:   learn: 3279.8859464 total: 2.56s    remaining: 564ms
1639:   learn: 3279.8859464 total: 2.56s    remaining: 563ms
1640:   learn: 3279.8832386 total: 2.56s    remaining: 561ms
1641:   learn: 3279.0485989 total: 2.56s    remaining: 559ms
1642:   learn: 3278.8821714 total: 2.57s    remaining: 558ms
1643:   learn: 3278.8711028 total: 2.57s    remaining: 556ms
1644:   learn: 3277.1513013 total: 2.57s    remaining: 555ms
1645:   learn: 3275.8510292 total: 2.57s    remaining: 553ms
1646:   learn: 3275.6650452 total: 2.57s    remaining: 552ms
1647:   learn: 3275.6650452 total: 2.57s    remaining: 550ms
1648:   learn: 3275.3498004 total: 2.58s    remaining: 548ms
1649:   learn: 3274.9740567 total: 2.58s    remaining: 547ms
1650:   learn: 3274.7822665 total: 2.58s    remaining: 545ms
1651:   learn: 3274.6167592 total: 2.58s    remaining: 544ms
1652:   learn: 3274.3646848 total: 2.58s    remaining: 542ms
1653:   learn: 3274.1047843 total: 2.58s    remaining: 541ms
1654:   learn: 3273.1818950 total: 2.59s    remaining: 539ms
1655:   learn: 3273.1252249 total: 2.59s    remaining: 538ms
1656:   learn: 3273.1252249 total: 2.59s    remaining: 536ms
1657:   learn: 3271.8492413 total: 2.59s    remaining: 534ms
1658:   learn: 3271.8492413 total: 2.59s    remaining: 533ms
1659:   learn: 3271.6288756 total: 2.59s    remaining: 531ms
1660:   learn: 3270.5058777 total: 2.6s remaining: 530ms
1661:   learn: 3270.2210417 total: 2.6s remaining: 528ms
1662:   learn: 3270.1062275 total: 2.6s remaining: 527ms
1663:   learn: 3268.8241585 total: 2.6s remaining: 525ms
1664:   learn: 3266.3782201 total: 2.6s remaining: 524ms
1665:   learn: 3266.1759854 total: 2.6s remaining: 522ms
1666:   learn: 3265.9703532 total: 2.61s    remaining: 521ms
1667:   learn: 3265.8494761 total: 2.61s    remaining: 519ms
1668:   learn: 3265.4209061 total: 2.61s    remaining: 518ms
1669:   learn: 3265.4095181 total: 2.61s    remaining: 516ms
1670:   learn: 3265.3124921 total: 2.61s    remaining: 514ms
1671:   learn: 3265.1019024 total: 2.61s    remaining: 513ms
1672:   learn: 3265.1019024 total: 2.61s    remaining: 511ms
1673:   learn: 3264.8856079 total: 2.62s    remaining: 510ms
1674:   learn: 3264.1545710 total: 2.62s    remaining: 508ms
1675:   learn: 3263.4951654 total: 2.62s    remaining: 507ms
1676:   learn: 3263.3284898 total: 2.62s    remaining: 505ms
1677:   learn: 3263.0894233 total: 2.62s    remaining: 504ms
1678:   learn: 3261.6791751 total: 2.63s    remaining: 502ms
1679:   learn: 3261.6382914 total: 2.63s    remaining: 500ms
1680:   learn: 3260.9623079 total: 2.63s    remaining: 499ms
1681:   learn: 3260.5195101 total: 2.63s    remaining: 497ms
1682:   learn: 3260.5195101 total: 2.63s    remaining: 496ms
1683:   learn: 3260.4429661 total: 2.63s    remaining: 494ms
1684:   learn: 3259.2850353 total: 2.63s    remaining: 493ms
1685:   learn: 3259.1184729 total: 2.64s    remaining: 491ms
1686:   learn: 3257.4318582 total: 2.64s    remaining: 490ms
1687:   learn: 3256.3432607 total: 2.64s    remaining: 488ms
1688:   learn: 3256.1738614 total: 2.64s    remaining: 487ms
1689:   learn: 3256.0401169 total: 2.64s    remaining: 485ms
1690:   learn: 3256.0141182 total: 2.64s    remaining: 483ms
1691:   learn: 3255.6800659 total: 2.65s    remaining: 482ms
1692:   learn: 3255.3824190 total: 2.65s    remaining: 480ms
1693:   learn: 3255.3824190 total: 2.65s    remaining: 479ms
1694:   learn: 3255.3198326 total: 2.65s    remaining: 477ms
1695:   learn: 3255.0116992 total: 2.65s    remaining: 476ms
1696:   learn: 3254.4885471 total: 2.65s    remaining: 474ms
1697:   learn: 3253.9981370 total: 2.66s    remaining: 472ms
1698:   learn: 3253.7226823 total: 2.66s    remaining: 471ms
1699:   learn: 3252.0418807 total: 2.66s    remaining: 469ms
1700:   learn: 3251.9126909 total: 2.66s    remaining: 468ms
1701:   learn: 3251.7482284 total: 2.66s    remaining: 466ms
1702:   learn: 3251.7482284 total: 2.66s    remaining: 465ms
1703:   learn: 3251.4825436 total: 2.67s    remaining: 463ms
1704:   learn: 3251.4825436 total: 2.67s    remaining: 461ms
1705:   learn: 3251.0752854 total: 2.67s    remaining: 460ms
1706:   learn: 3251.0323167 total: 2.67s    remaining: 458ms
1707:   learn: 3250.9870171 total: 2.67s    remaining: 457ms
1708:   learn: 3250.9870171 total: 2.67s    remaining: 455ms
1709:   learn: 3250.8926521 total: 2.67s    remaining: 454ms
1710:   learn: 3250.8926521 total: 2.67s    remaining: 452ms
1711:   learn: 3250.6317391 total: 2.68s    remaining: 450ms
1712:   learn: 3250.2868656 total: 2.68s    remaining: 449ms
1713:   learn: 3247.8370753 total: 2.68s    remaining: 447ms
1714:   learn: 3247.5119753 total: 2.68s    remaining: 446ms
1715:   learn: 3247.4487605 total: 2.69s    remaining: 444ms
1716:   learn: 3247.2618348 total: 2.69s    remaining: 443ms
1717:   learn: 3246.1160185 total: 2.69s    remaining: 441ms
1718:   learn: 3246.0611944 total: 2.69s    remaining: 440ms
1719:   learn: 3245.9436964 total: 2.69s    remaining: 438ms
1720:   learn: 3245.8172996 total: 2.69s    remaining: 437ms
1721:   learn: 3245.5221004 total: 2.69s    remaining: 435ms
1722:   learn: 3244.7470276 total: 2.7s remaining: 434ms
1723:   learn: 3244.5450469 total: 2.7s remaining: 432ms
1724:   learn: 3244.3835899 total: 2.7s remaining: 431ms
1725:   learn: 3243.7042952 total: 2.7s remaining: 429ms
1726:   learn: 3242.7265075 total: 2.7s remaining: 428ms
1727:   learn: 3242.7265036 total: 2.71s    remaining: 426ms
1728:   learn: 3242.6212553 total: 2.71s    remaining: 424ms
1729:   learn: 3242.6212553 total: 2.71s    remaining: 423ms
1730:   learn: 3242.6212553 total: 2.71s    remaining: 421ms
1731:   learn: 3242.5020831 total: 2.71s    remaining: 419ms
1732:   learn: 3242.2354098 total: 2.71s    remaining: 418ms
1733:   learn: 3242.1319816 total: 2.71s    remaining: 416ms
1734:   learn: 3239.9598138 total: 2.71s    remaining: 415ms
1735:   learn: 3239.9598138 total: 2.71s    remaining: 413ms
1736:   learn: 3239.9598138 total: 2.71s    remaining: 411ms
1737:   learn: 3238.4933588 total: 2.72s    remaining: 410ms
1738:   learn: 3238.4090395 total: 2.72s    remaining: 408ms
1739:   learn: 3237.9460828 total: 2.72s    remaining: 407ms
1740:   learn: 3237.9460828 total: 2.72s    remaining: 405ms
1741:   learn: 3237.5741813 total: 2.72s    remaining: 403ms
1742:   learn: 3237.5731105 total: 2.72s    remaining: 402ms
1743:   learn: 3236.6579709 total: 2.73s    remaining: 400ms
1744:   learn: 3236.6579709 total: 2.73s    remaining: 398ms
1745:   learn: 3236.6004231 total: 2.73s    remaining: 397ms
1746:   learn: 3236.5989813 total: 2.73s    remaining: 395ms
1747:   learn: 3235.7497974 total: 2.73s    remaining: 394ms
1748:   learn: 3235.6559333 total: 2.73s    remaining: 392ms
1749:   learn: 3235.6559333 total: 2.73s    remaining: 390ms
1750:   learn: 3235.6559333 total: 2.73s    remaining: 389ms
1751:   learn: 3234.7204734 total: 2.73s    remaining: 387ms
1752:   learn: 3234.0974067 total: 2.74s    remaining: 386ms
1753:   learn: 3232.7146744 total: 2.74s    remaining: 384ms
1754:   learn: 3232.0895286 total: 2.74s    remaining: 383ms
1755:   learn: 3231.0815741 total: 2.74s    remaining: 381ms
1756:   learn: 3230.3141273 total: 2.74s    remaining: 379ms
1757:   learn: 3230.1224354 total: 2.75s    remaining: 378ms
1758:   learn: 3229.9339115 total: 2.75s    remaining: 377ms
1759:   learn: 3227.6837115 total: 2.75s    remaining: 375ms
1760:   learn: 3227.1989900 total: 2.75s    remaining: 374ms
1761:   learn: 3227.1208964 total: 2.75s    remaining: 372ms
1762:   learn: 3227.1208964 total: 2.75s    remaining: 370ms
1763:   learn: 3227.1208964 total: 2.75s    remaining: 369ms
1764:   learn: 3227.1208964 total: 2.76s    remaining: 367ms
1765:   learn: 3226.9229197 total: 2.76s    remaining: 366ms
1766:   learn: 3226.8221035 total: 2.76s    remaining: 364ms
1767:   learn: 3226.8221035 total: 2.76s    remaining: 362ms
1768:   learn: 3226.8221035 total: 2.76s    remaining: 361ms
1769:   learn: 3226.7462898 total: 2.77s    remaining: 359ms
1770:   learn: 3226.6427809 total: 2.77s    remaining: 358ms
1771:   learn: 3226.5801495 total: 2.77s    remaining: 356ms
1772:   learn: 3225.3617666 total: 2.77s    remaining: 355ms
1773:   learn: 3225.1428621 total: 2.77s    remaining: 354ms
1774:   learn: 3224.9591976 total: 2.78s    remaining: 352ms
1775:   learn: 3224.9591976 total: 2.78s    remaining: 350ms
1776:   learn: 3224.6700894 total: 2.78s    remaining: 349ms
1777:   learn: 3224.6466400 total: 2.78s    remaining: 347ms
1778:   learn: 3224.6271374 total: 2.78s    remaining: 346ms
1779:   learn: 3224.0563186 total: 2.79s    remaining: 344ms
1780:   learn: 3222.5400069 total: 2.79s    remaining: 343ms
1781:   learn: 3222.4027209 total: 2.79s    remaining: 341ms
1782:   learn: 3222.4027209 total: 2.79s    remaining: 340ms
1783:   learn: 3222.4027209 total: 2.79s    remaining: 338ms
1784:   learn: 3222.2928774 total: 2.79s    remaining: 336ms
1785:   learn: 3221.8128906 total: 2.79s    remaining: 335ms
1786:   learn: 3221.7618866 total: 2.8s remaining: 333ms
1787:   learn: 3221.2949108 total: 2.8s remaining: 332ms
1788:   learn: 3221.2949108 total: 2.8s remaining: 330ms
1789:   learn: 3221.2240167 total: 2.8s remaining: 329ms
1790:   learn: 3221.0322063 total: 2.8s remaining: 327ms
1791:   learn: 3221.0322063 total: 2.8s remaining: 325ms
1792:   learn: 3220.9381865 total: 2.81s    remaining: 324ms
1793:   learn: 3220.9381865 total: 2.81s    remaining: 322ms
1794:   learn: 3220.9381865 total: 2.81s    remaining: 321ms
1795:   learn: 3220.9377104 total: 2.81s    remaining: 319ms
1796:   learn: 3220.7727369 total: 2.81s    remaining: 317ms
1797:   learn: 3220.7356709 total: 2.81s    remaining: 316ms
1798:   learn: 3220.7356709 total: 2.81s    remaining: 314ms
1799:   learn: 3220.6184967 total: 2.81s    remaining: 313ms
1800:   learn: 3220.6175269 total: 2.81s    remaining: 311ms
1801:   learn: 3220.1059973 total: 2.81s    remaining: 309ms
1802:   learn: 3220.1059973 total: 2.82s    remaining: 308ms
1803:   learn: 3217.1888413 total: 2.82s    remaining: 306ms
1804:   learn: 3217.1172900 total: 2.82s    remaining: 305ms
1805:   learn: 3217.0688467 total: 2.82s    remaining: 303ms
1806:   learn: 3216.7132980 total: 2.82s    remaining: 301ms
1807:   learn: 3216.3568737 total: 2.82s    remaining: 300ms
1808:   learn: 3216.3157387 total: 2.83s    remaining: 298ms
1809:   learn: 3216.3157387 total: 2.83s    remaining: 297ms
1810:   learn: 3216.0763913 total: 2.83s    remaining: 295ms
1811:   learn: 3216.0763913 total: 2.83s    remaining: 294ms
1812:   learn: 3216.0763913 total: 2.83s    remaining: 292ms
1813:   learn: 3215.6931887 total: 2.83s    remaining: 290ms
1814:   learn: 3215.6931887 total: 2.83s    remaining: 289ms
1815:   learn: 3214.2313706 total: 2.83s    remaining: 287ms
1816:   learn: 3213.7688487 total: 2.83s    remaining: 286ms
1817:   learn: 3213.4543847 total: 2.84s    remaining: 284ms
1818:   learn: 3212.0359410 total: 2.84s    remaining: 282ms
1819:   learn: 3211.4011396 total: 2.84s    remaining: 281ms
1820:   learn: 3211.2998259 total: 2.84s    remaining: 279ms
1821:   learn: 3211.2998259 total: 2.84s    remaining: 278ms
1822:   learn: 3211.1857236 total: 2.85s    remaining: 276ms
1823:   learn: 3211.1852452 total: 2.85s    remaining: 275ms
1824:   learn: 3211.0107423 total: 2.85s    remaining: 273ms
1825:   learn: 3210.4542562 total: 2.85s    remaining: 272ms
1826:   learn: 3210.1349881 total: 2.85s    remaining: 270ms
1827:   learn: 3210.1349881 total: 2.85s    remaining: 268ms
1828:   learn: 3210.1349881 total: 2.85s    remaining: 267ms
1829:   learn: 3209.7725069 total: 2.85s    remaining: 265ms
1830:   learn: 3208.8106518 total: 2.85s    remaining: 264ms
1831:   learn: 3208.4329045 total: 2.86s    remaining: 262ms
1832:   learn: 3208.3958028 total: 2.86s    remaining: 261ms
1833:   learn: 3208.3958028 total: 2.86s    remaining: 259ms
1834:   learn: 3208.0052413 total: 2.86s    remaining: 257ms
1835:   learn: 3208.0052413 total: 2.86s    remaining: 256ms
1836:   learn: 3208.0006715 total: 2.86s    remaining: 254ms
1837:   learn: 3208.0006715 total: 2.86s    remaining: 252ms
1838:   learn: 3207.6299710 total: 2.87s    remaining: 251ms
1839:   learn: 3207.0709428 total: 2.87s    remaining: 249ms
1840:   learn: 3206.2722778 total: 2.87s    remaining: 248ms
1841:   learn: 3205.9844701 total: 2.87s    remaining: 246ms
1842:   learn: 3205.9844701 total: 2.87s    remaining: 245ms
1843:   learn: 3205.9844701 total: 2.87s    remaining: 243ms
1844:   learn: 3205.9051384 total: 2.87s    remaining: 241ms
1845:   learn: 3205.5338684 total: 2.88s    remaining: 240ms
1846:   learn: 3205.3602770 total: 2.88s    remaining: 238ms
1847:   learn: 3205.2578576 total: 2.88s    remaining: 237ms
1848:   learn: 3203.8365263 total: 2.88s    remaining: 235ms
1849:   learn: 3203.0163520 total: 2.88s    remaining: 234ms
1850:   learn: 3202.9417611 total: 2.88s    remaining: 232ms
1851:   learn: 3202.9417611 total: 2.88s    remaining: 231ms
1852:   learn: 3201.1659404 total: 2.89s    remaining: 229ms
1853:   learn: 3200.6824813 total: 2.89s    remaining: 227ms
1854:   learn: 3200.4047298 total: 2.89s    remaining: 226ms
1855:   learn: 3200.2798995 total: 2.89s    remaining: 224ms
1856:   learn: 3200.0748374 total: 2.89s    remaining: 223ms
1857:   learn: 3199.9563505 total: 2.9s remaining: 221ms
1858:   learn: 3199.8089603 total: 2.9s remaining: 220ms
1859:   learn: 3199.8089603 total: 2.9s remaining: 218ms
1860:   learn: 3197.9298648 total: 2.9s remaining: 217ms
1861:   learn: 3197.7025775 total: 2.9s remaining: 215ms
1862:   learn: 3197.3721597 total: 2.9s remaining: 214ms
1863:   learn: 3197.3140130 total: 2.9s remaining: 212ms
1864:   learn: 3196.0015779 total: 2.91s    remaining: 210ms
1865:   learn: 3195.3910311 total: 2.91s    remaining: 209ms
1866:   learn: 3195.3308914 total: 2.91s    remaining: 207ms
1867:   learn: 3195.2076011 total: 2.91s    remaining: 206ms
1868:   learn: 3194.7759795 total: 2.91s    remaining: 204ms
1869:   learn: 3192.4044117 total: 2.92s    remaining: 203ms
1870:   learn: 3192.3708795 total: 2.92s    remaining: 201ms
1871:   learn: 3192.3708795 total: 2.92s    remaining: 199ms
1872:   learn: 3192.2939071 total: 2.92s    remaining: 198ms
1873:   learn: 3192.2895993 total: 2.92s    remaining: 196ms
1874:   learn: 3191.9587267 total: 2.92s    remaining: 195ms
1875:   learn: 3191.9567183 total: 2.92s    remaining: 193ms
1876:   learn: 3191.8971818 total: 2.92s    remaining: 192ms
1877:   learn: 3191.1792680 total: 2.93s    remaining: 190ms
1878:   learn: 3191.0838705 total: 2.93s    remaining: 189ms
1879:   learn: 3190.8872837 total: 2.93s    remaining: 187ms
1880:   learn: 3190.8872837 total: 2.93s    remaining: 185ms
1881:   learn: 3190.3398846 total: 2.93s    remaining: 184ms
1882:   learn: 3190.3178516 total: 2.93s    remaining: 182ms
1883:   learn: 3190.3178516 total: 2.94s    remaining: 181ms
1884:   learn: 3190.3178516 total: 2.94s    remaining: 179ms
1885:   learn: 3190.1615305 total: 2.94s    remaining: 178ms
1886:   learn: 3189.2103039 total: 2.94s    remaining: 176ms
1887:   learn: 3188.4273779 total: 2.94s    remaining: 174ms
1888:   learn: 3188.4238113 total: 2.94s    remaining: 173ms
1889:   learn: 3188.2809772 total: 2.94s    remaining: 171ms
1890:   learn: 3187.9026207 total: 2.94s    remaining: 170ms
1891:   learn: 3187.7516608 total: 2.95s    remaining: 168ms
1892:   learn: 3187.0001016 total: 2.95s    remaining: 167ms
1893:   learn: 3186.8764795 total: 2.95s    remaining: 165ms
1894:   learn: 3186.1777226 total: 2.95s    remaining: 164ms
1895:   learn: 3185.9146383 total: 2.95s    remaining: 162ms
1896:   learn: 3185.8595390 total: 2.96s    remaining: 160ms
1897:   learn: 3185.6498040 total: 2.96s    remaining: 159ms
1898:   learn: 3185.4838792 total: 2.96s    remaining: 157ms
1899:   learn: 3185.1089346 total: 2.96s    remaining: 156ms
1900:   learn: 3184.9103971 total: 2.96s    remaining: 154ms
1901:   learn: 3184.9103971 total: 2.96s    remaining: 153ms
1902:   learn: 3184.7112840 total: 2.96s    remaining: 151ms
1903:   learn: 3184.4933206 total: 2.97s    remaining: 150ms
1904:   learn: 3184.2238274 total: 2.97s    remaining: 148ms
1905:   learn: 3183.9800255 total: 2.97s    remaining: 147ms
1906:   learn: 3183.8295774 total: 2.97s    remaining: 145ms
1907:   learn: 3182.8877936 total: 2.97s    remaining: 143ms
1908:   learn: 3182.8877936 total: 2.97s    remaining: 142ms
1909:   learn: 3182.8605341 total: 2.98s    remaining: 140ms
1910:   learn: 3182.7561028 total: 2.98s    remaining: 139ms
1911:   learn: 3182.6976531 total: 2.98s    remaining: 137ms
1912:   learn: 3182.4886802 total: 2.98s    remaining: 136ms
1913:   learn: 3182.4267129 total: 2.98s    remaining: 134ms
1914:   learn: 3181.8080179 total: 2.98s    remaining: 133ms
1915:   learn: 3181.8080179 total: 2.98s    remaining: 131ms
1916:   learn: 3181.5897020 total: 2.99s    remaining: 129ms
1917:   learn: 3181.3470077 total: 2.99s    remaining: 128ms
1918:   learn: 3180.6396235 total: 2.99s    remaining: 126ms
1919:   learn: 3180.4227108 total: 2.99s    remaining: 125ms
1920:   learn: 3179.2487757 total: 3s   remaining: 123ms
1921:   learn: 3178.8277430 total: 3s   remaining: 122ms
1922:   learn: 3178.8277430 total: 3s   remaining: 120ms
1923:   learn: 3178.8277430 total: 3s   remaining: 118ms
1924:   learn: 3178.8277430 total: 3s   remaining: 117ms
1925:   learn: 3178.6801247 total: 3s   remaining: 115ms
1926:   learn: 3177.4687686 total: 3s   remaining: 114ms
1927:   learn: 3176.8356898 total: 3s   remaining: 112ms
1928:   learn: 3176.7893483 total: 3s   remaining: 111ms
1929:   learn: 3176.6002622 total: 3.01s    remaining: 109ms
1930:   learn: 3175.5122001 total: 3.01s    remaining: 108ms
1931:   learn: 3175.5115561 total: 3.01s    remaining: 106ms
1932:   learn: 3175.3155671 total: 3.01s    remaining: 104ms
1933:   learn: 3175.0862539 total: 3.01s    remaining: 103ms
1934:   learn: 3173.7085725 total: 3.02s    remaining: 101ms
1935:   learn: 3173.6273355 total: 3.02s    remaining: 99.7ms
1936:   learn: 3173.6273355 total: 3.02s    remaining: 98.1ms
1937:   learn: 3172.2604329 total: 3.02s    remaining: 96.6ms
1938:   learn: 3170.7569996 total: 3.02s    remaining: 95ms
1939:   learn: 3170.7210008 total: 3.02s    remaining: 93.4ms
1940:   learn: 3170.6571722 total: 3.02s    remaining: 91.9ms
1941:   learn: 3170.4286382 total: 3.02s    remaining: 90.3ms
1942:   learn: 3170.4038996 total: 3.02s    remaining: 88.7ms
1943:   learn: 3167.9652011 total: 3.03s    remaining: 87.2ms
1944:   learn: 3167.3331960 total: 3.03s    remaining: 85.6ms
1945:   learn: 3167.0481107 total: 3.03s    remaining: 84.1ms
1946:   learn: 3165.3433385 total: 3.03s    remaining: 82.5ms
1947:   learn: 3163.1094795 total: 3.03s    remaining: 81ms
1948:   learn: 3163.0667467 total: 3.04s    remaining: 79.4ms
1949:   learn: 3163.0667467 total: 3.04s    remaining: 77.8ms
1950:   learn: 3162.4798653 total: 3.04s    remaining: 76.3ms
1951:   learn: 3161.3348713 total: 3.04s    remaining: 74.7ms
1952:   learn: 3161.3117989 total: 3.04s    remaining: 73.2ms
1953:   learn: 3160.8023680 total: 3.04s    remaining: 71.6ms
1954:   learn: 3160.1140905 total: 3.04s    remaining: 70.1ms
1955:   learn: 3158.9981598 total: 3.05s    remaining: 68.5ms
1956:   learn: 3156.8978382 total: 3.05s    remaining: 67ms
1957:   learn: 3156.7772601 total: 3.05s    remaining: 65.4ms
1958:   learn: 3156.5825227 total: 3.05s    remaining: 63.9ms
1959:   learn: 3156.1921972 total: 3.05s    remaining: 62.3ms
1960:   learn: 3155.5738299 total: 3.06s    remaining: 60.8ms
1961:   learn: 3154.9745268 total: 3.06s    remaining: 59.2ms
1962:   learn: 3154.9745268 total: 3.06s    remaining: 57.7ms
1963:   learn: 3154.9321185 total: 3.06s    remaining: 56.1ms
1964:   learn: 3154.9193510 total: 3.06s    remaining: 54.5ms
1965:   learn: 3153.3045270 total: 3.06s    remaining: 53ms
1966:   learn: 3153.1427141 total: 3.06s    remaining: 51.4ms
1967:   learn: 3152.9119379 total: 3.07s    remaining: 49.9ms
1968:   learn: 3152.9117927 total: 3.07s    remaining: 48.3ms
1969:   learn: 3152.9117927 total: 3.07s    remaining: 46.7ms
1970:   learn: 3152.8367126 total: 3.07s    remaining: 45.2ms
1971:   learn: 3152.8124488 total: 3.07s    remaining: 43.6ms
1972:   learn: 3152.5892578 total: 3.07s    remaining: 42.1ms
1973:   learn: 3152.4632281 total: 3.08s    remaining: 40.5ms
1974:   learn: 3152.4632281 total: 3.08s    remaining: 38.9ms
1975:   learn: 3152.4610389 total: 3.08s    remaining: 37.4ms
1976:   learn: 3152.4070619 total: 3.08s    remaining: 35.8ms
1977:   learn: 3151.5088242 total: 3.08s    remaining: 34.3ms
1978:   learn: 3151.3192003 total: 3.08s    remaining: 32.7ms
1979:   learn: 3151.0934751 total: 3.08s    remaining: 31.2ms
1980:   learn: 3151.0934751 total: 3.09s    remaining: 29.6ms
1981:   learn: 3150.9537433 total: 3.09s    remaining: 28ms
1982:   learn: 3150.9537433 total: 3.09s    remaining: 26.5ms
1983:   learn: 3150.8674274 total: 3.09s    remaining: 24.9ms
1984:   learn: 3150.8674274 total: 3.09s    remaining: 23.4ms
1985:   learn: 3149.2328055 total: 3.09s    remaining: 21.8ms
1986:   learn: 3149.0072684 total: 3.09s    remaining: 20.2ms
1987:   learn: 3148.3315876 total: 3.1s remaining: 18.7ms
1988:   learn: 3147.7977344 total: 3.1s remaining: 17.1ms
1989:   learn: 3147.6247163 total: 3.1s remaining: 15.6ms
1990:   learn: 3146.5977276 total: 3.1s remaining: 14ms
1991:   learn: 3146.1891474 total: 3.1s remaining: 12.5ms
1992:   learn: 3146.1621749 total: 3.11s    remaining: 10.9ms
1993:   learn: 3144.2741570 total: 3.11s    remaining: 9.36ms
1994:   learn: 3144.2189615 total: 3.11s    remaining: 7.8ms
1995:   learn: 3143.8690645 total: 3.11s    remaining: 6.24ms
1996:   learn: 3143.3502296 total: 3.12s    remaining: 4.68ms
1997:   learn: 3142.8227286 total: 3.12s    remaining: 3.12ms
1998:   learn: 3142.8227286 total: 3.12s    remaining: 1.56ms
1999:   learn: 3142.6323020 total: 3.12s    remaining: 0us</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lec11_More boosting models_files/figure-html/cell-24-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display" data-execution_count="126">
<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>BayesSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),
              estimator=&lt;catboost.core.CatBoostRegressor object at 0x000001C05095EFD0&gt;,
              n_iter=200, n_jobs=-1, random_state=1,
              scoring='neg_root_mean_squared_error',
              search_spaces={'colsample_bylevel': Real(low=0.1, high=1.0, prior='uniform', transform='normalize'),
                             'learning_rate': Real(low=0.0001, high=1.0, prior='uniform', transform='normalize'),
                             'n_estimators': Integer(low=2, high=2000, prior='uniform', transform='normalize'),
                             'num_leaves': Integer(low=4, high=64, prior='uniform', transform='normalize'),
                             'reg_lambda': Real(low=0, high=10000.0, prior='uniform', transform='normalize'),
                             'subsample': Real(low=0.1, high=1.0, prior='uniform', transform='normalize')})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">BayesSearchCV</label><div class="sk-toggleable__content"><pre>BayesSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),
              estimator=&lt;catboost.core.CatBoostRegressor object at 0x000001C05095EFD0&gt;,
              n_iter=200, n_jobs=-1, random_state=1,
              scoring='neg_root_mean_squared_error',
              search_spaces={'colsample_bylevel': Real(low=0.1, high=1.0, prior='uniform', transform='normalize'),
                             'learning_rate': Real(low=0.0001, high=1.0, prior='uniform', transform='normalize'),
                             'n_estimators': Integer(low=2, high=2000, prior='uniform', transform='normalize'),
                             'num_leaves': Integer(low=4, high=64, prior='uniform', transform='normalize'),
                             'reg_lambda': Real(low=0, high=10000.0, prior='uniform', transform='normalize'),
                             'subsample': Real(low=0.1, high=1.0, prior='uniform', transform='normalize')})</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: CatBoostRegressor</label><div class="sk-toggleable__content"><pre>&lt;catboost.core.CatBoostRegressor object at 0x000001C05095EFD0&gt;</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">CatBoostRegressor</label><div class="sk-toggleable__content"><pre>&lt;catboost.core.CatBoostRegressor object at 0x000001C05095EFD0&gt;</pre></div></div></div></div></div></div></div></div></div></div>
</div>
</div>
</section>
<section id="tuning-tips" class="level3" data-number="13.2.4">
<h3 data-number="13.2.4" class="anchored" data-anchor-id="tuning-tips"><span class="header-section-number">13.2.4</span> Tuning Tips</h3>
<p>Check the <a href="https://catboost.ai/en/docs/references/training-parameters/common">documentation</a> for some tuning tips.</p>
<ol type="1">
<li><p>It is not recommended to use values greater than 64 for <code>num_leaves</code>, since it can significantly slow down the training process.</p></li>
<li><p>The maximum possible value of <code>max_depth</code> is 16.</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Lec9_XGBoost.html" class="pagination-link" aria-label="XGBoost">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">XGBoost</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Lec10_Ensemble.html" class="pagination-link" aria-label="Ensemble modeling">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Ensemble modeling</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>