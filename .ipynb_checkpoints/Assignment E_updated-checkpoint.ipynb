{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cfb58366",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Assignment E (Section 22)\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d50fa",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity. \n",
    "\n",
    "2. Do not write your name on the assignment.\n",
    "\n",
    "3. Write your code in the *Code* cells and your answer in the *Markdown* cells of the Jupyter notebook. Ensure that the solution is written neatly enough to understand and grade.\n",
    "\n",
    "4. Use [Quarto](https://quarto.org/docs/output-formats/html-basics.html) to print the *.ipynb* file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: `quarto render filename.ipynb --to html`. Submit the HTML file.\n",
    "\n",
    "5. The assignment is worth 100 points, and is due on **Tuesday, 7th March 2023 at 11:59 pm**. \n",
    "\n",
    "6. **Five points are properly formatting the assignment**. The breakdown is as follows:\n",
    "- Must be an HTML file rendered using Quarto (1 pt). *If you have a Quarto issue, you must mention the issue & quote the error you get when rendering using Quarto in the comments section of Canvas, and submit the ipynb file.* \n",
    "- No name can be written on the assignment, nor can there be any indicator of the student’s identity—e.g. printouts of the working directory should not be included in the final submission  (1 pt)\n",
    "- There aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.) (1 pt)\n",
    "- Final answers of each question are written in Markdown cells (1 pt).\n",
    "- There is no piece of unnecessary / redundant code, and no unnecessary / redundant text (1 pt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898583e",
   "metadata": {},
   "source": [
    "##  Calculating Root Mean Square Error (RMSE) in Sklearn {-}\n",
    "\n",
    "`sklearn.metrics` has `mean_squared_error` function with a `squared` kwarg (default to `True`). Setting `squared` to `False` will return the RMSE\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = mean_squared_error(y_actual, y_predicted, squared=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85370d0",
   "metadata": {},
   "source": [
    "## Energy model {-}\n",
    "\n",
    "The datasets *ENB2012_Train.csv* and *ENB2012_Test.csv* provide data on energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. Below is the description of the data columns:\n",
    "\n",
    "1. `X1`: Relative Compactness\n",
    "2. `X2`: Surface Area\n",
    "3. `X3`: Wall Area\n",
    "4. `X4`: Roof Area\n",
    "5. `X5`: Overall Height\n",
    "6. `X6`: Orientation\n",
    "7. `X7`: Glazing Area\n",
    "8. `X8`: Glazing Area Distribution\n",
    "9. `y1`: Heating Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a43f4b",
   "metadata": {},
   "source": [
    "## E.1.1\n",
    "Suppose that we want to implement the best subset selection algorithm to find the first order predictors (`X1`-`X8`) that can predict heating load (`y1`). How many models for $E$(`y1`) are possible, if the model includes (i) one variable, (ii) three variables, and (iii) eight variables? Show your steps without running any code. \n",
    "\n",
    "Note: The notation $E$(`y1`) means the expected value of `y1` or the mean of `y1`.\n",
    "\n",
    "*(3 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23cce00",
   "metadata": {},
   "source": [
    "## E.1.2\n",
    "Implement the best subset selection algorithm to find the *best* first-order predictors of heating load `y1`. \n",
    "\n",
    "Note: \n",
    "\n",
    "1. Use *ENB2012_Train.csv* and consider only the first-order terms. \n",
    "\n",
    "2. Use the BIC criterion for model selection.\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f7fe29",
   "metadata": {},
   "source": [
    "## E.1.3 \n",
    "Should $R$-squared be used to select from among a set of models with different numbers of predictors? Justify your answer. \n",
    "\n",
    "*(1 point for answer, 2 points for justification)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364c4cb1",
   "metadata": {},
   "source": [
    "## E.1.4\n",
    "Calculate the RMSE of the model found in E.2. Compare it with the RMSE of the model using all first-order predictors. You will find that the two RMSEs are similar. Seems like the best subset model didn't help improve prediction.\n",
    "\n",
    "1. Why did the best subset model not help improve prediction accuracy as compared to the model with all the predictors?\n",
    "\n",
    "2. Does the best subset model provide a more accurate inference as compared to the model with all the predictors? Why or why npt? \n",
    "\n",
    "Hint: **V**ery **I**mportant **F**act!\n",
    "\n",
    "*(2 points for computing the RMSEs, 3 + 3 points for justifications)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d3448f",
   "metadata": {},
   "source": [
    "## E.1.5\n",
    "Let us consider adding all the 2-factor interactions of the predictors in the model. Answer the following questions without running code.\n",
    "\n",
    "1. How many predictors do we have in total?\n",
    "\n",
    "2. Assume best subset selection is used. How many models are fitted in total? \n",
    "\n",
    "3. Assume forward selection is used. How many models are fitted in total?\n",
    "\n",
    "4. Assume backward selection is used. How many models are fitted in total? \n",
    "\n",
    "5. How many models will be developed in the iteration that contains exactly 10 predictors in each model – for best subsets, fwd/bwd regression? \n",
    "\n",
    "6. With [sklearn.feature_selection.SequentialFeatureSelector](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector), how many models will be deleloped when setting the `n_features_to_select` to 10 for forward selection and backward selection respectively?\n",
    "\n",
    "*(6*2 = 12 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf86f55",
   "metadata": {},
   "source": [
    "## E.1.6\n",
    "\n",
    "Use forward selection to find the *best* first-order predictors and 2-factor interactions of the predictors of `y1` (Heating Load). \n",
    "\n",
    "*(5 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709b8347",
   "metadata": {},
   "source": [
    "## E.1.7\n",
    "\n",
    "Use forward selection in [sklearn.feature_selection.SequentialFeatureSelector](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector) to find the *best* first-order predictors and 2-factor interactions of the predictors of `y1` (Heating Load), setting the `n_features_to_select` to the number of predictors of the best model found in E.1.6. \n",
    "\n",
    "Is the best subset found using sklearn the same as the one found in E.1.5. why or why not?\n",
    "\n",
    "*(5 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5af50",
   "metadata": {},
   "source": [
    "## E.1.8\n",
    "\n",
    "Calculate the RMSE of the model found in E.1.7. Compare it with:\n",
    "\n",
    "1. the RMSE of model you found in E.1.2 and,\n",
    "\n",
    "2. the RMSE of the model using all the predictors and all their 2-factor interaction terms. \n",
    "\n",
    "Among the 4 models (the model developed in E.1.2, the model developed in E.1.7, the model that has all the predictors and all their 2-factor interactions), discuss which model will you prefer for prediction, and which model will you prefer for inference, and why?\n",
    "\n",
    "\n",
    "\n",
    "*(2 points for computing the RMSEs, 3 + 3 points for discussion)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dabdd5",
   "metadata": {},
   "source": [
    "## E.1.9\n",
    "Assume that we found another dataset of 32 variabels on the same set of 768 buildings (542 for training) that we would want to add into our model. We want find the \"best\" model of all 40 predictors and their 2-factor interaction terms. Would you choose forward or backward selection? Justify your answer. \n",
    "\n",
    "*(1 point for answer, 4 points for justification)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcefecc",
   "metadata": {},
   "source": [
    "## Planetary radius model {-}\n",
    "See https://exoplanetarchive.ipac.caltech.edu (for context/source). We are using the Composite Planetary Systems dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745acc7",
   "metadata": {},
   "source": [
    "## E.2.1\n",
    "Say we’re interested in modeling the radius of exoplanets in kilometers, which is named as `pl_rade` in the data. Note that the variable `pl_rade` captures the radius of each planet as a proportion of Earth’s radius, which is approximately 6,378.1370 km. \n",
    "\n",
    "Develop a linear regression model to predict `pl_rade` using all the variables in *train_CompositePlanetarySystems.csv* except `pl_name`, `disc_facility` and `disc_locale`. Find the RMSE (Root mean squared error) of the model on *test1_CompositePlanetarySystems.csv* and *test2_CompositePlanetarySystems.csv*. \n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb5e3b7",
   "metadata": {},
   "source": [
    "## E.2.2\n",
    "Develop a ridge regression model to predict `pl_rade` using all the variables in *train_CompositePlanetarySystems.csv* except `pl_name`, `disc_facility` and `disc_locale`. What is the optimal value of the tuning parameter $\\lambda$?\n",
    "\n",
    "**Hint:** You may use the following grid of lambda values to find the optimal $\\lambda$: \n",
    "`alphas = 10**np.linspace(2,0.5,200)*0.5`\n",
    "\n",
    "Remember to standardize data before fitting the ridge regression model\n",
    "\n",
    "\n",
    "*(5 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a96d6",
   "metadata": {},
   "source": [
    "## E.2.3\n",
    "Use the optimal value of $\\lambda$ found in the previous question to develop a ridge regression model. What is the RMSE of the model on *test1_CompositePlanetarySystems.csv* and *test2_CompositePlanetarySystems.csv*?\n",
    "\n",
    "*(5 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7cc71b",
   "metadata": {},
   "source": [
    "## E.2.4\n",
    "Note that ridge regression has a much lower RMSE on test datasets as compared to Ordinary least squares (OLS) regression. Shrinking the coefficients has reduced the variance of the estimated coefficents with a little increase in bias, thereby improving the model fit. Appreciate it. Which are the top two predictors for which the coefficients have shrunk the most? \n",
    "\n",
    "To answer this question, find the ridge regression estimates for $\\lambda = 10^{-10}$ *(almost zero regularization)*. Treat these estimates as OLS estimates and find the predictors for which these estimates have shrunk the most as compared to the model developed in E.2.3.\n",
    "\n",
    "*(4 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c0f23",
   "metadata": {},
   "source": [
    "## E.2.5\n",
    "Why do you think the coefficients of the two variables identified in the previous question shrunk the most?\n",
    "\n",
    "*(4 points for justification - including code used)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b323ed",
   "metadata": {},
   "source": [
    "## E.2.6\n",
    "Develop a lasso model to predict `pl_rade` using all the variables in *train_CompositePlanetarySystems.csv* except `pl_name`, `disc_facility` and `disc_locale`. What is the optimal value of the tuning parameter $\\lambda$?\n",
    "\n",
    "**Hint:** You may use the following grid of lambda values to find the optimal $\\lambda$: \n",
    "`alphas = 10**np.linspace(0,-2.5,200)*0.5`\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64faaf4",
   "metadata": {},
   "source": [
    "## E.2.7\n",
    "Use the optimal value of $\\lambda$ found in the previous question to develop a lasso model. What is the RMSE of the model on *test1_CompositePlanetarySystems.csv* and *test2_CompositePlanetarySystems.csv*?\n",
    "\n",
    "*(5 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c4e29a",
   "metadata": {},
   "source": [
    "## E.2.8\n",
    "Note that lasso has a much lower RMSE on test datasets as compared to Ordinary least squares (OLS) regression. Shrinking the coefficients has improved the model fit. Appreciate it. Which variables have been eliminated by lasso? \n",
    "\n",
    "To answer this question, find the predictors whose coefficients are 0 in the lasso model. \n",
    "\n",
    "*(2 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8f456",
   "metadata": {},
   "source": [
    "## E.3\n",
    "\n",
    "We haves used *car_features_train.csv* and *car_prices_train.csv* in class notes to predict car `price`. Based on correlation with `price`, the four most relevant continuous predictors to predict car price are `year`, `mpg`, `mileage`, and `engineSize`. In this question, you will use $K$-fold cross validation to find out the relevant interactions of these predictors and the relevant interactions of the polynomial transformations of these predictors for predicting car `price`. We'll consider quadratic and cubic transfromations of each predictor, and the interactions of these transformed predictors. For example, some of the interaction terms that you will consider are (year$^2$), (year)(mpg), (year$^2$)(mpg), (year)(mpg)(mileage), (year)(mpg$^2$)(mileage), (year)(mpg$^2$)(mileage)(engineSize$^3$), etc. The highest degree interaction term will be of degree 12 - (year$^3$)(mpg$^3$)(mileage$^3$)(engineSize$^3$), and the lowest degree interaction terms will be of degree two, such as (engineSize$^2$) or (engineSize)(mpg), etc.\n",
    "\n",
    "The algorithm to find out the relevant interactions using $K$-fold cross validation is as follows. Most of the algorithm is already coded for you. You need to code only part 2 as indicated below.\n",
    "\n",
    "1. Start with considering interactions of degree `d` = 2:\n",
    "\n",
    "2. **Find out the 5-fold cross validation RMSE if an interaction of degree `d` is added to the model** *(You need to code only this part)*.\n",
    " \n",
    "3. Repeat step (2) for all possible interactions of degree `d`.\n",
    "\n",
    "4. Include the interaction of degree `d` in the model that leads to the highest reduction in the 5-fold cross validation error as compared to the previous model *(forward stepwise selection based on K-fold cross validation)*\n",
    "\n",
    "5. Repeat steps 2-4 until no more reduction is possible in the 5-fold cross validation RMSE.\n",
    "    \n",
    "6. If `d` = 12, then stop, otherwise increment `d` by one, and repeat steps 2-5.\n",
    "\n",
    "The above algorithm is coded below. The algorithm calls a function `KFoldCV` to compute the 5-fold cross validation RMSE given the interaction terms already selected in the model as `selected_interactions`, and the interaction term to be tested as `interaction_being_tested`. The function must return the 5-fold cross validation RMSE if `interaction_being_tested` is included to the model consisting of `year`, `mpg`, `mileage`, and `engineSize` in addition to the already added interactions in `selected_interactions`. The features for which you need to find the $5$-fold cross validation RMSE will be `year`+`mpg`+`mileage`+`engineSize'+selected_interactions+interaction_being_tested`\n",
    "\n",
    "You need to do the following:\n",
    "\n",
    "1. Fill out the function `KFoldCV`. \n",
    "\n",
    "2. Execute the code to obtain the relevant interactions in `selected_interactions`. Print out the object `selected_interactions`.\n",
    "\n",
    "3. Fit the model with the four predictors, the `selected_interactions` and compute the RMSE on test data.\n",
    "\n",
    "**Relevance of this question to the [linear regression prediction problem](https://www.kaggle.com/competitions/data-science-2-linear-regression-2023-bank-loans):** Once you figure out the four most useful predictors to predict `money_made_inv`, use this algorithm to find out their useful interactions. Combine the model with the EDA-based insight of developing the model only where `out_prncp_inv`>0, and you should get a RMSE of less than 400 on the public leaderboard! *(This algorithm is inspired by Victoria Shi's solution to the linear regression prediction problem)*. \n",
    "\n",
    "Note that this brute-force approach of finding relevant interactions may work sometimes, especially when $n>>p$ *(the number of observations are much higher than the number of predictors)*. However, in certain problems, a few minutes spent on EDA to figure out transformations, etc. will help develop a better model than this brute force approach. For example, EDA-based transformations helped you get a RMSE of less than $350k on question [C.1.6](https://nustat.github.io/STAT303-2-class-notes/Assignment%20C.html#section-5), which is not possible with this approach.\n",
    "\n",
    "*(10 (filling out the function) + 1 + 1 points)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae77e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c7978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the train dataset\n",
    "predictor_set = ['year','mpg','engineSize','mileage']\n",
    "trainf = pd.read_csv('./Datasets/Car_features_train.csv',index_col=0)\n",
    "trainp = pd.read_csv('./Datasets/Car_prices_train.csv',index_col=0)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "def make_dataset(features_df, target_df, max_degree=3):\n",
    "  poly = PolynomialFeatures(max_degree, include_bias=False)\n",
    "  X=poly.fit_transform(features_df[predictor_set].values)\n",
    "  df = pd.DataFrame(X, columns=poly.get_feature_names_out(predictor_set), index=features_df.index)\n",
    "  df['price']=target_df\n",
    "  df=df.sample(frac=1)\n",
    "  return df\n",
    "train=make_dataset(trainf,trainp, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5ebdbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this function - that is all you need to do to make the code work!\n",
    "\n",
    "# The function must return the mean 5-fold cross validation RMSE for the model\n",
    "# that has the 'selected_interactions', and the 'interaction_being_tested'\n",
    "def KFoldCV(selected_interactions, interaction_being_tested=None):\n",
    "  \"\"\"\n",
    "  All the variable names can be found in `train` dataframe.\n",
    "  selected_interactions: List[String] ->  the list of variable names that current selected\n",
    "  interaction_being_tested: String    ->  a single variable name that are testing.\n",
    "  return: float -> mean of RSME of 5-folder validation.\n",
    "  \"\"\"\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "326771ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially, RMSE=9561.448654675505, features=['year', 'mpg', 'engineSize', 'mileage']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1815/1815 [00:40<00:00, 45.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code implements the algorithm of systematically considering interactions of degree 2 and going upto \n",
    "# the interaction of degree 12\n",
    "history=[]\n",
    "\n",
    "selected_interactions = list(predictor_set)\n",
    "cv_previous_model = KFoldCV(selected_interactions = selected_interactions, interaction_being_tested = None)\n",
    "history.append([cv_previous_model, \",\".join(selected_interactions)])\n",
    "\n",
    "print(\"Initially, RMSE={}, features={}\".format(cv_previous_model, selected_interactions))\n",
    "\n",
    "candidates = [col for col in train.columns if col not in predictor_set +['price']]\n",
    "\n",
    "for interaction_being_tested in tqdm(candidates):\n",
    "  cv=KFoldCV(selected_interactions.copy(), interaction_being_tested)\n",
    "  if cv<cv_previous_model:\n",
    "    selected_interactions.append(interaction_being_tested)\n",
    "    cv_previous_model=cv \n",
    "    history.append([cv_previous_model, \",\".join(selected_interactions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbab55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
