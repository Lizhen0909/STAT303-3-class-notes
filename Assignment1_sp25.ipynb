{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7fc45304",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Assignment 1\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    self-contained: true\n",
    "    number-sections: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672791b9",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity. \n",
    "\n",
    "2. Write your code in the **Code cells** and your answers in the **Markdown cells** of the Jupyter notebook. Ensure that the solution is written neatly enough to for the graders to understand and follow.\n",
    "\n",
    "3. Use [Quarto](https://quarto.org/docs/output-formats/html-basics.html) to render the **.ipynb** file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: `quarto render filename.ipynb --to html`. Submit the HTML file.\n",
    "\n",
    "4. The assignment is worth 100 points, and is due on **Thursday, 11th April 2025 at 11:59 pm**. \n",
    "\n",
    "5. **Five points are properly formatting the assignment**. The breakdown is as follows:\n",
    "    - Must be an HTML file rendered using Quarto **(2 points)**. *If you have a Quarto issue, you must mention the issue & quote the error you get when rendering using Quarto in the comments section of Canvas, and submit the ipynb file.* \n",
    "    - There aren‚Äôt excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren‚Äôt long printouts of which iteration a loop is on, there aren‚Äôt long sections of commented-out code, etc.) **(1 point)**\n",
    "    - Final answers to each question are written in the Markdown cells. **(1 point)**\n",
    "    - There is no piece of unnecessary / redundant code, and no unnecessary / redundant text. **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae5120",
   "metadata": {},
   "source": [
    "## 1) Bias-Variance Trade-off for Regression **(50 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988fbe55",
   "metadata": {},
   "source": [
    "The main goal of this question is to understand and visualize the bias-variance trade-off in a regression model by performing repetitive simulations.\n",
    "\n",
    "The conceptual clarity about bias and variance will help with the main logic behind creating many models that will come up later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dce7cd",
   "metadata": {},
   "source": [
    "### a) Define the True Relationship (Signal)\n",
    "\n",
    "First, you need to implement the underlying true relationship (Signal) you want to sample data from. Assume that the function is the [Bukin function](https://www.sfu.ca/~ssurjano/bukin6.html). Implement it as a user-defined function and run it with the test cases below to make sure it is implemented correctly. **(5 points)**\n",
    "\n",
    "**Note:** It would be more useful to have only one input to the function. You can treat the input as an array of two elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0572db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bukin(np.array([1,2]))) # The output should be 141.177\n",
    "print(Bukin(np.array([6,-4]))) # The output should be 208.966\n",
    "print(Bukin(np.array([0,1]))) # The output should be 100.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8788939",
   "metadata": {},
   "source": [
    "### b) Generate Test Set (No Noise)\n",
    "\n",
    "Generate a **noiseless** test set with **100 observations** sampled from the true underlying function. This test set will be used to evaluate **bias and variance**, so make sure it follows the correct data generation process. \n",
    "\n",
    "**(5 points)**\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Do not use loops** for this question.\n",
    "- `.apply` will be especially helpful (and often simpler).\n",
    "\n",
    "**Data generation assumptions:**\n",
    "\n",
    "- Use `np.random.seed(100)` for reproducibility.\n",
    "- The first predictor, $x_1$, should be drawn from a **uniform distribution** over the interval $[-15, -5]$, i.e., $x_1 \\sim U[-15, -5]$.\n",
    "- The second predictor, $x_2$, should be drawn from a **uniform distribution** over the interval $[-3, 3]$, i.e., $x_2 \\sim U[-3, 3]$.\n",
    "- Compute the true function values using the underlying model as your response $y$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1561b204",
   "metadata": {},
   "source": [
    "### c) Initialize Results DataFrame\n",
    "\n",
    "Create an empty DataFrame with the following columns: **degree**, **bias_sq**, **var**, and **mse**.  \n",
    "You will use this DataFrame to store the results of your bias-variance tradeoff analysis, which will be used for generating plots and interpreting model performance.\n",
    "\n",
    "**(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b247107",
   "metadata": {},
   "source": [
    "### d) Generate Training Sets (With Noise)\n",
    "\n",
    "To estimate the **bias** and **variance** of a Linear Regression model fitted on noisy data from the underlying Bukin function, follow these steps:\n",
    "\n",
    "\n",
    "**üîÅ Generate 100 Training Sets:**\n",
    "\n",
    "- Create **100 independent training datasets**, each containing **100 observations** (same size as the test set).\n",
    "- For each training set:\n",
    "  - Use `np.random.seed(i)` to ensure reproducibility, where `i` is the dataset index (0 to 99).\n",
    "  - Draw predictors from the same distributions as in the test set.\n",
    "  - Add **Gaussian noise** with mean 0 and **standard deviation 10**, i.e., $\\mathcal{N}(0, 10)$, to the target values.\n",
    "\n",
    "\n",
    "\n",
    "**üìà Train Polynomial Models (Degrees 1 to 7):**\n",
    "\n",
    "- For each training set, train polynomial models of degrees **1 through 7**.\n",
    "- Use polynomial feature transformations that include both:\n",
    "  - **Higher-order terms** (e.g., $x_1^2$, $x_2^3$)\n",
    "  - **Interaction terms** (e.g., $x_1 \\cdot x_2$)\n",
    "- Use the **same fixed, noiseless test set** to generate predictions from each model.\n",
    "\n",
    "\n",
    "\n",
    "**üìä Estimate Bias¬≤, Variance, and MSE for Each Degree:**\n",
    "\n",
    "- For each **test point**, you will obtain **100 predicted values** (one from each trained model).\n",
    "- Use these predictions to compute the following quantities **per degree** (averaged over all test points):\n",
    "  - **Bias squared**\n",
    "  - **Variance**\n",
    "  - **Mean Squared Error (MSE)**\n",
    "- Store these values in your results DataFrame for plotting and analysis.\n",
    "\n",
    "**(25 points)**\n",
    "\n",
    "\n",
    "### üí° Reminder: Computing MSE on the Noiseless Test Set\n",
    "\n",
    "When computing the **MSE**, you should **not** include the irreducible error (noise variance). Here's why:\n",
    "\n",
    "- The **irreducible error** ($\\sigma^2 = 100$) comes from the noise **in the training data**.\n",
    "- The **test set is noiseless**, so your predictions are evaluated against the **true function values**.\n",
    "- Therefore:\n",
    "\n",
    "$\n",
    "  \\text{MSE} = \\text{Bias}^2 + \\text{Variance}\n",
    " $\n",
    "\n",
    "**‚úÖ Conclusion:**  \n",
    "The MSE you compute is the **expected prediction error** on noiseless test data.  \n",
    "You should **only sum the estimated bias¬≤ and variance** ‚Äî no additional noise term is needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac6d193",
   "metadata": {},
   "source": [
    "### e) Visualize Bias-Variance Tradeoff\n",
    "\n",
    "Using the results stored in your summary DataFrame, create a line plot showing how the following quantities change with the **degree** of the polynomial model:\n",
    "\n",
    "- bias squared\n",
    "- variance\n",
    "- mse ‚Äî computed as the sum of bias squared and variance\n",
    "\n",
    "**(5 points)**\n",
    "\n",
    "\n",
    "**Plot requirements:**\n",
    "\n",
    "- The x-axis should represent the **polynomial degree**.\n",
    "- The y-axis should represent the **error values**.\n",
    "- Include a **legend** that clearly labels each line: bias¬≤, variance, and mse.  \n",
    "  **(2 points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4133fe",
   "metadata": {},
   "source": [
    "### f) Identify the Optimal Model\n",
    "\n",
    "- What is the **optimal polynomial degree** based on the lowest mean squared error (mse)?  \n",
    "  **(2 points)**\n",
    "\n",
    "- Report the corresponding values of:  \n",
    "  - **bias squared**  \n",
    "  - **variance**  \n",
    "  - **mean squared error (mse)**  \n",
    "  for that optimal degree.  \n",
    "  **(3 points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901566b",
   "metadata": {},
   "source": [
    "## 2) Building a Low-Bias-Low-Variance Model via Regularization (50 points)\n",
    "\n",
    "The main goal of this question is to further reduce the **total error** by applying **regularization**. Specifically, you'll implement a **low-bias, low-variance** model for the underlying function and the noisy data.\n",
    "\n",
    "\n",
    "\n",
    "### a) Why Regularization?\n",
    "\n",
    "Explain why the model with the optimal degree (as identified in Question 1) is **not guaranteed** to be the true low-bias-low-variance model.  \n",
    "Why might **regularization** still be necessary to improve generalization performance?\n",
    "\n",
    "**(5 points)**\n",
    "\n",
    "\n",
    "### b) Which Degrees to Exclude?\n",
    "\n",
    "Before repeating the process from Question 1, carefully examine the plot and results from **1e** and **1f**. Identify which polynomial degrees should be **excluded** from regularization experiments because they are already too simple or too complex.\n",
    "\n",
    "Explain which degrees you will exclude and **why**, considering how **regularization affects bias and variance**.\n",
    "\n",
    "**(10 points)**\n",
    "\n",
    "\n",
    "\n",
    "### c) Apply Ridge Regularization\n",
    "\n",
    "Repeat the steps from **1c** and **1d**, but this time using **Ridge regression** instead of ordinary least squares.\n",
    "\n",
    "- **Exclude** the degrees you identified in **2b**, as well as **degree 7** (to avoid extreme overfitting).\n",
    "- Use **5-fold cross-validation** to tune the regularization hyperparameter.\n",
    "- Use `neg_root_mean_squared_error` as the scoring metric for cross-validation.\n",
    "- Try regularization strengths in the range `[1, 100]`.\n",
    "\n",
    "**(10 points)**\n",
    "\n",
    "\n",
    "\n",
    "### d) Visualize Regularized Results\n",
    "\n",
    "Repeat the visualization from **1e**, but using the results obtained from **2c** (Ridge regression).\n",
    "\n",
    "Plot:\n",
    "- **bias squared**\n",
    "- **variance**\n",
    "- **mse**\n",
    "\n",
    "against the polynomial **degree**, using regularized models.\n",
    "\n",
    "**(10 points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb923103",
   "metadata": {},
   "source": [
    "### e) Evaluate the Regularized Model\n",
    "\n",
    "- What is the **degree** of the optimal Ridge Regression model based on the lowest total error?  \n",
    "  **(3 points)**\n",
    "\n",
    "- What are the corresponding values of:  \n",
    "  - **bias-squared**  \n",
    "  - **variance**  \n",
    "  - **mse**  \n",
    "  for that optimal Ridge model?  \n",
    "  **(3 points)**\n",
    "\n",
    "- Compare these results to those of the optimal **Linear Regression** model from Question 1.  \n",
    "  How did **regularization** affect the bias, variance, and total error?  \n",
    "  **(4 points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139496ef",
   "metadata": {},
   "source": [
    "### f) Interpreting the Impact of Regularization\n",
    "\n",
    "- Was the **regularization successful** in reducing the **total error** of the regression model?  \n",
    "  **(2 points)**\n",
    "\n",
    "- Based on the results from **2e**, explain how **bias** and **variance** changed with regularization.  \n",
    "  How did these changes contribute to the final total error?  \n",
    "  **(3 points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b52c89",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
