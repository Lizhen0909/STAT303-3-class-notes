{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4b9feeda",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"LightGBM and CatBoost\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "    toc-depth: 4\n",
    "    jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b194faa9",
   "metadata": {},
   "source": [
    "## XGBoost's Strength\n",
    "\n",
    "* **Robustness**: XGBoost works well across many types of datasets, making it a solid all-around choice.\n",
    "* **Regularization**: Built-in techniques help prevent overfitting, which can make it easier for beginners.\n",
    "If you need speed with big data, LightGBM is your pick. For versatility and reliability, XGBoost has the edge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31570850",
   "metadata": {},
   "source": [
    "## LightGBM's Edge\n",
    "\n",
    "* **Speed**: LightGBM uses histogram-based algorithms to speed things up, reducing memory usage. It‚Äôs 7x faster than XGBoost in some cases.\n",
    "* **Leaf-Wise Growth**: It grows trees leaf by leaf, focusing on the best branches, leading to better accuracy but potential overfitting.\n",
    "* **Big Data**: LightGBM is ideal for massive datasets with thousands of features, where XGBoost may slow down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d163aa",
   "metadata": {},
   "source": [
    "## What is LightGBM?\n",
    "\n",
    "**LightGBM** (Light Gradient Boosting Machine) is a high-performance gradient boosting framework developed by Microsoft in 2017. LightGBM outperforms XGBoost in terms of compuational speed, and provides comparable accuracy in general. It is designed for:\n",
    "\n",
    "- **Large-scale datasets** with many rows and features  \n",
    "- **High speed and memory efficiency**, often outperforming XGBoost in training time  \n",
    "- **Native support for categorical features** (Note: XGBoost added this starting in version 1.5.0)  \n",
    "- **Support for parallel, distributed, and GPU training** (XGBoost offers similar capabilities)\n",
    "\n",
    "Read the [LightGBM paper](https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910b876",
   "metadata": {},
   "source": [
    "## Similarities with XGBoost\n",
    "\n",
    "###  Histogram-Based Algorithm\n",
    "- LightGBM bins continuous features into discrete histograms, enabling **faster and more memory-efficient split finding**.\n",
    "- It leverages **histogram subtraction** to efficiently compute histograms for child nodes by reusing information from the parent node.\n",
    "\n",
    "###  Objective Function\n",
    "\n",
    "LightGBM uses the same regularized loss function structure as other gradient boosting frameworks:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}^{(t)} = \\sum_{i=1}^n l(y_i, \\hat{y}_i^{(t-1)} + f_t(x_i)) + \\Omega(f_t)\n",
    "$$\n",
    "\n",
    "This allows flexible optimization for regression, classification, and ranking tasks.\n",
    "\n",
    "###  Second-Order Taylor Approximation\n",
    "\n",
    "To simplify optimization, LightGBM uses a **second-order Taylor expansion** of the loss function:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}^{(t)} \\approx \\sum_{i=1}^n \\left[ g_i f_t(x_i) + \\frac{1}{2} h_i f_t(x_i)^2 \\right] + \\Omega(f_t)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $g_i$ = First-order gradient (i.e., gradient of the loss)  \n",
    "- $h_i$ = Second-order gradient (i.e., Hessian of the loss)\n",
    "\n",
    "This approach improves convergence and stability during training.\n",
    "\n",
    "###  Regularization (Same as XGBoost)\n",
    "- LightGBM supports **L1 and L2 regularization** via `lambda_l1` and `lambda_l2`.\n",
    "- It also includes structural regularization parameters like `min_data_in_leaf` to reduce overfitting by controlling tree complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cab06e",
   "metadata": {},
   "source": [
    "##  What Makes LightGBM Unique?\n",
    "\n",
    "LightGBM often outperforms XGBoost in **training speed** and **memory efficiency**, thanks to several key innovations:\n",
    "\n",
    "\n",
    "###  Leaf-Wise Tree Growth\n",
    "\n",
    "- LightGBM splits the **leaf with the largest potential loss reduction**, unlike XGBoost‚Äôs **level-wise** approach.\n",
    "- This leads to **lower loss per tree**, making learning more efficient ‚Äî though it may **overfit** without proper regularization.\n",
    "- Main controls:\n",
    "  - `num_leaves`: primary control for tree complexity\n",
    "  - `max_depth`: optional constraint to prevent overfitting\n",
    "\n",
    "\n",
    "###  GOSS (Gradient-based One-Side Sampling)\n",
    "\n",
    "- GOSS improves speed by:\n",
    "  - **Retaining all instances with large gradients** (i.e., high error)\n",
    "  - **Randomly sampling those with small gradients**\n",
    "- This reduces the dataset size while maintaining accurate split decisions.\n",
    "\n",
    "In gradient boosting, the tree is fit to the **negative gradient** of the loss:\n",
    "\n",
    "$$\n",
    "r_m = -\\left[ \\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)} \\right]_{f = f_{m-1}}\n",
    "$$\n",
    "\n",
    "Observations with larger gradients have more influence on reducing the loss ‚Äî GOSS prioritizes those.\n",
    "\n",
    "- Hyperparameters for GOSS:\n",
    "   - `boosting_type='goss'`: activates GOSS instead of traditional random sampling\n",
    "   - `top_rate`: fraction of data with the largest gradients to keep (e.g., `0.2`)\n",
    "   - `other_rate`: fraction of data with smaller gradients to sample (e.g., `0.1`)\n",
    "\n",
    "\n",
    "\n",
    "###  EFB (Exclusive Feature Bundling)\n",
    "\n",
    "- EFB compresses **high-dimensional sparse feature spaces** by bundling features that are **mutually exclusive** (i.e., rarely non-zero at the same time).\n",
    "- This is particularly effective in datasets with **many categorical variables** or **one-hot encoded features**.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "| feature1 | feature2 | feature_bundle |\n",
    "|----------|----------|----------------|\n",
    "| 0        | 2        | 6              |\n",
    "| 0        | 1        | 5              |\n",
    "| 0        | 2        | 6              |\n",
    "| 1        | 0        | 1              |\n",
    "| 2        | 0        | 2              |\n",
    "| 3        | 0        | 3              |\n",
    "| 4        | 0        | 4              |\n",
    "\n",
    "Here, `feature1` and `feature2` never overlap in non-zero values, so they can be safely merged into a single bundled feature.\n",
    "\n",
    "- Hyperparameter for EFB:\n",
    "   - `enable_bundle`: set to `true` (default) to enable automatic exclusive feature bundling\n",
    "\n",
    "\n",
    "Together, these optimizations make LightGBM especially well-suited for **large-scale, sparse, tabular datasets**, offering both **speed and scalability** without significant loss in accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774de8f",
   "metadata": {},
   "source": [
    "## Using LightGBM\n",
    "\n",
    "\n",
    "Although **LightGBM is not part of Scikit-learn**, it provides a **Scikit-learn-compatible API** through the `lightgbm.sklearn` module. This allows you to use LightGBM models seamlessly with Scikit-learn tools such as `Pipeline`, `GridSearchCV`, and `cross_val_score`.\n",
    "\n",
    "The main classes are:\n",
    "\n",
    "- [`LGBMRegressor`](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html): for regression tasks  \n",
    "- [`LGBMClassifier`](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html): for classification tasks\n",
    "\n",
    "To install the package:\n",
    "\n",
    "\n",
    "``` python\n",
    "pip install lightgbm\n",
    "```\n",
    "> **Note:** LightGBM is a separate library, not part of Scikit-learn, but it provides a **Scikit-learn-compatible API** via `LGBMClassifier` and `LGBMRegressor`.  \n",
    "> This makes it easy to integrate LightGBM models into Scikit-learn workflows such as `Pipeline`, `GridSearchCV`, and `cross_val_score`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09726b8b",
   "metadata": {},
   "source": [
    "### Core LightGBM Hyperparameters\n",
    "\n",
    "####  Core Tree Structure\n",
    "\n",
    "- `num_leaves`: Maximum number of leaves (terminal nodes) per tree.\n",
    "- `min_data_in_leaf`: Minimum number of data points required in a leaf.\n",
    "- `max_depth`: Maximum depth of a tree (used to control overfitting).\n",
    "\n",
    "\n",
    "\n",
    "####  Learning Control and Regularization\n",
    "\n",
    "- `learning_rate (Œ∑)`: Shrinks the contribution of each tree.\n",
    "- `n_estimators`: Number of boosting rounds.\n",
    "- `lambda_l1` / `lambda_l2`: L1 and L2 regularization on leaf weights.\n",
    "- `min_gain_to_split`: Minimum loss reduction required to make a further split (structure regularization).\n",
    "\n",
    "\n",
    "\n",
    "####  Data Handling\n",
    "\n",
    "- `feature_fraction`: Fraction of features randomly sampled for each tree (a.k.a. `colsample_bytree` in XGBoost).\n",
    "- `bagging_fraction`: Fraction of data randomly sampled for each iteration.\n",
    "- `bagging_freq`: Frequency (in iterations) to perform bagging.\n",
    "- `categorical_feature`: Specifies which features are categorical (enables native handling).\n",
    "\n",
    "\n",
    "\n",
    "####  Speed vs. Accuracy Trade-offs\n",
    "\n",
    "- `max_bin`: Number of bins used to bucket continuous features.\n",
    "- `data_sample_strategy` : `bagging` or `goss`\n",
    "- `top_rate` *(`goss` only)*: Fraction of instances with the largest gradients to keep.\n",
    "- `other_rate` *(`goss` only)*: Fraction of small-gradient instances to randomly sample.\n",
    "-`enable_bundle`: set this to true to spped up the training for sparse datasets\n",
    "\n",
    "\n",
    "####  Optimization Control\n",
    "\n",
    "- `boosting`: Type of boosting algorithm (`gbdt`, `dart`, `rf`, etc.).\n",
    "- `early_stopping_rounds`: Stops training if the validation score doesn‚Äôt improve over a set number of rounds.\n",
    "\n",
    "\n",
    "####  Imbalanced Data\n",
    "\n",
    "- `scale_pos_weight`: Manually sets the weight for the positive class in binary classification.\n",
    "- `is_unbalance`: Automatically adjusts class weights based on the training data distribution.\n",
    "\n",
    "> ‚ö†Ô∏è These two options are **mutually exclusive** ‚Äî use **only one**. If both are set, `scale_pos_weight` takes priority.\n",
    "\n",
    "For full details and advanced options, see the [LightGBM Parameters Guide](https://lightgbm.readthedocs.io/en/latest/Parameters.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f819f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram, plot_convergence\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c74843",
   "metadata": {},
   "source": [
    "We'll continue to use the same datasets that we have been using throughout the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9036ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vw</td>\n",
       "      <td>Beetle</td>\n",
       "      <td>2014</td>\n",
       "      <td>Manual</td>\n",
       "      <td>55457</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>30</td>\n",
       "      <td>65.3266</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vauxhall</td>\n",
       "      <td>GTC</td>\n",
       "      <td>2017</td>\n",
       "      <td>Manual</td>\n",
       "      <td>15630</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>47.2049</td>\n",
       "      <td>1.4</td>\n",
       "      <td>10998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>merc</td>\n",
       "      <td>G Class</td>\n",
       "      <td>2012</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>43000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>570</td>\n",
       "      <td>25.1172</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audi</td>\n",
       "      <td>RS5</td>\n",
       "      <td>2019</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>10</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>30.5593</td>\n",
       "      <td>2.9</td>\n",
       "      <td>51990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>merc</td>\n",
       "      <td>X-CLASS</td>\n",
       "      <td>2018</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>14000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>240</td>\n",
       "      <td>35.7168</td>\n",
       "      <td>2.3</td>\n",
       "      <td>28990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      brand     model  year transmission  mileage fuelType  tax      mpg  \\\n",
       "0        vw    Beetle  2014       Manual    55457   Diesel   30  65.3266   \n",
       "1  vauxhall       GTC  2017       Manual    15630   Petrol  145  47.2049   \n",
       "2      merc   G Class  2012    Automatic    43000   Diesel  570  25.1172   \n",
       "3      audi       RS5  2019    Automatic       10   Petrol  145  30.5593   \n",
       "4      merc   X-CLASS  2018    Automatic    14000   Diesel  240  35.7168   \n",
       "\n",
       "   engineSize  price  \n",
       "0         1.6   7490  \n",
       "1         1.4  10998  \n",
       "2         3.0  44990  \n",
       "3         2.9  51990  \n",
       "4         2.3  28990  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "car = pd.read_csv('Datasets/car.csv')\n",
    "car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db6b5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car.drop(columns=['price'])\n",
    "y = car['price']\n",
    "\n",
    "# extract the categorical columns and put them in a list\n",
    "categorical_feature = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# extract the numerical columns and put them in a list\n",
    "numerical_feature = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# convert the categorical columns to category type\n",
    "for col in categorical_feature:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c772c1",
   "metadata": {},
   "source": [
    "###  Building a Baseline Model Using LightGBM‚Äôs Native Categorical Feature Support\n",
    "\n",
    "LightGBM provides **built-in support for handling categorical features**, eliminating the need for manual encoding (like one-hot or ordinal encoding). By directly passing categorical column names or indices to the model, LightGBM can internally apply efficient encoding and optimized split finding for categorical variables.\n",
    "\n",
    "In this section, we'll use this native capability to **quickly build a baseline model**, taking advantage of LightGBM‚Äôs efficiency with structured data that includes categorical columns.\n",
    "\n",
    "This baseline model serves as a **starting point** for comparison against more advanced tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38736472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Baseline LightGBM Model =====\n",
      "Test RMSE: 3680.8999\n",
      "Test R¬≤: 0.9538\n",
      "CPU times: total: 875 ms\n",
      "Wall time: 82.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ===== 1. Baseline Model =====\n",
    "print(\"\\n===== Baseline LightGBM Model =====\")\n",
    "# Initialize the LightGBM regressor\n",
    "model = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "# Train the model with categorical features specified\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    categorical_feature=categorical_feature\n",
    ")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output results\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test R¬≤: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c4a044",
   "metadata": {},
   "source": [
    "###  Enabling GOSS and EFB in LightGBM\n",
    "\n",
    "By default, LightGBM uses:\n",
    "\n",
    "```python\n",
    "data_sample_strategy = 'bagging'\n",
    "```\n",
    "To enable **GOSS (Gradient-based One-Side Sampling)** ‚Äî a faster sampling strategy that prioritizes high-gradient instances ‚Äî set:\n",
    "\n",
    "```python\n",
    "boosting_type = 'goss'\n",
    "```\n",
    "When using GOSS, you should also configure:\n",
    "\n",
    "* `top_rate`: Fraction of data with the largest gradients to retain (e.g., 0.2)\n",
    "\n",
    "* `other_rate`: Fraction of small-gradient data to randomly sample (e.g., 0.1)\n",
    "\n",
    "LightGBM also enables **EFB (Exclusive Feature Bundling)** by default:\n",
    "\n",
    "```python\n",
    "enable_bundle = True\n",
    "```\n",
    "\n",
    "This optimization reduces dimensionality by bundling mutually exclusive sparse features, such as those resulting from one-hot encoding.\n",
    "\n",
    "‚ö†Ô∏è Note: In our car dataset, the data size is small and there are only a few categorical features, so these optimizations may not have a noticeable impact.\n",
    "However, for large-scale datasets with many categorical features, enabling GOSS and EFB is highly recommended to improve training efficiency and reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1677750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== LightGBM with GOSS Sampling =====\n",
      "Test RMSE (GOSS): 3510.7726\n",
      "Test R¬≤ (GOSS): 0.9580\n",
      "CPU times: total: 766 ms\n",
      "Wall time: 79.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ===== 2. LightGBM with GOSS Sampling =====\n",
    "print(\"\\n===== LightGBM with GOSS Sampling =====\")\n",
    "\n",
    "# Initialize the LightGBM regressor with GOSS\n",
    "model_goss = lgb.LGBMRegressor(\n",
    "    boosting_type='goss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model with categorical features specified\n",
    "model_goss.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    categorical_feature=categorical_feature\n",
    ")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_goss = model_goss.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rmse_goss = root_mean_squared_error(y_test, y_pred_goss)\n",
    "r2_goss = r2_score(y_test, y_pred_goss)\n",
    "\n",
    "# Output results\n",
    "print(f\"Test RMSE (GOSS): {rmse_goss:.4f}\")\n",
    "print(f\"Test R¬≤ (GOSS): {r2_goss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f91c63",
   "metadata": {},
   "source": [
    "###  Tuning `top_rate` and `other_rate` in GOSS\n",
    "\n",
    "Even with this small dataset, we observed a **shorter execution time** and a **slight improvement in performance** using GOSS. Next, we'll tune the `top_rate` and `other_rate` parameters to see if we can further boost the model's performance.\n",
    "\n",
    "> ‚ö†Ô∏è **Note:** When using `boosting_type='goss'`, LightGBM requires that  \n",
    "> **`top_rate + other_rate ‚â§ 1.0`**  \n",
    "> This constraint ensures that the combined sample used for training does not exceed the size of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09e449da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  OrderedDict({'other_rate': 0.33986603248215197, 'top_rate': 0.31901459322046166})\n",
      "Test RMSE (GOSS with tuning): 3458.7664\n",
      "Test R¬≤ (GOSS with tuning): 0.9592\n"
     ]
    }
   ],
   "source": [
    "# tuning the top_rate and other_rate parameters\n",
    "# Initialize the LightGBM regressor with GOSS\n",
    "model_goss_tune = lgb.LGBMRegressor(\n",
    "    boosting_type='goss',\n",
    "    random_state=42\n",
    ")\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'top_rate': Real(0.1, 0.6, prior='uniform'),\n",
    "    'other_rate': Real(0.1, 0.4, prior='uniform'),\n",
    "}\n",
    "# Initialize the BayesSearchCV object\n",
    "opt = BayesSearchCV(\n",
    "    model_goss_tune,\n",
    "    param_grid,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "# Fit the model\n",
    "opt.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    categorical_feature=categorical_feature\n",
    ")\n",
    "# the best parameters\n",
    "print(\"Best parameters found: \", opt.best_params_)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_opt = opt.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rmse_opt = root_mean_squared_error(y_test, y_pred_opt)\n",
    "r2_opt = r2_score(y_test, y_pred_opt)\n",
    "# Output results\n",
    "print(f\"Test RMSE (GOSS with tuning): {rmse_opt:.4f}\")\n",
    "print(f\"Test R¬≤ (GOSS with tuning): {r2_opt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537963ac",
   "metadata": {},
   "source": [
    "### Optimizing LightGBM with Categorical Features and BayesSearchCV\n",
    "\n",
    "`BayesSearchCV` from `scikit-optimize` provides an efficient way to tune hyperparameters. Here's how to set this up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35e60b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: OrderedDict({'learning_rate': 0.31777940485083805, 'max_depth': 5, 'min_data_in_leaf': 47, 'n_estimators': 369, 'num_leaves': 20, 'other_rate': 0.4, 'top_rate': 0.6})\n",
      "Best Score: -3361.8218393725633\n",
      "RMSE (Bayesian Optimized): 3071.418344800289\n",
      "R2 Score (Bayesian Optimized): 0.9678447743461689\n",
      "CPU times: total: 49.4 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ===== 2. Hyperparameter Tuning with Bayesian Optimization =====\n",
    "# Define the parameter space for Bayesian optimization\n",
    "param_space = {\n",
    "    'num_leaves': Integer(20, 100),\n",
    "    'max_depth': Integer(5, 50),\n",
    "    'min_data_in_leaf': Integer(1, 100),\n",
    "    'learning_rate': Real(0.01, 0.5, prior='uniform'),\n",
    "    'n_estimators': Integer(50, 500),\n",
    "    'top_rate': Real(0.1, 0.6, prior='uniform'),\n",
    "    'other_rate': Real(0.1, 0.4, prior='uniform'),\n",
    "}\n",
    "# Create the Bayesian search object\n",
    "bayes_search = BayesSearchCV(\n",
    "    # using verbose=-1 to suppress warnings\n",
    "    # using n_jobs=-1 to use all available cores\n",
    "    # using random_state=42 for reproducibility\n",
    "    estimator=lgb.LGBMRegressor( categorical_feature=categorical_feature, random_state=42, boosting_type='goss', verbose=-1),\n",
    "    # Define the parameter space for Bayesian optimization\n",
    "    search_spaces=param_space,\n",
    "    n_iter=50,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "# Fit the Bayesian search object to the training data\n",
    "bayes_search.fit(X_train, y_train)\n",
    "# Get the best parameters and score\n",
    "best_params = bayes_search.best_params_\n",
    "best_score = bayes_search.best_score_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score}\")\n",
    "# Get the best model\n",
    "best_model = bayes_search.best_estimator_\n",
    "# Make predictions on the test set\n",
    "y_pred_bayes = best_model.predict(X_test)\n",
    "# Calculate RMSE and R2 score for the best model\n",
    "rmse_bayes = root_mean_squared_error(y_test, y_pred_bayes)\n",
    "r2_bayes = r2_score(y_test, y_pred_bayes)\n",
    "print(f\"RMSE (Bayesian Optimized): {rmse_bayes}\")\n",
    "print(f\"R2 Score (Bayesian Optimized): {r2_bayes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1830fb",
   "metadata": {},
   "source": [
    "Using GOSS and Feature Estimation by Bagging (FEB) led to a slight improvement in performance compared to XGBoost, while also reducing the time required for cross-validation tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b16144",
   "metadata": {},
   "source": [
    "##  CatBoost\n",
    "\n",
    "###  What is CatBoost?\n",
    "\n",
    "**CatBoost** (short for *Categorical Boosting*) is a high-performance gradient boosting framework developed by **Yandex**, specifically designed to handle datasets with **categorical features** without requiring manual preprocessing.\n",
    "\n",
    "Like XGBoost and LightGBM, it is based on gradient boosting over decision trees, but CatBoost introduces **key innovations** that make it robust, easy to use, and effective out of the box‚Äîparticularly on tabular data.\n",
    "\n",
    "\n",
    "\n",
    "###  What Makes CatBoost Unique?\n",
    "\n",
    "CatBoost offers several innovations that distinguish it from other boosting frameworks:\n",
    "\n",
    "\n",
    "\n",
    "####  Native Categorical Feature Encoding\n",
    "\n",
    "CatBoost can **natively process categorical features** using an approach based on **ordered target statistics**, which:\n",
    "\n",
    "- Avoids target leakage during training\n",
    "- Typically outperforms traditional encodings like one-hot or label encoding\n",
    "- Requires **no manual preprocessing** ‚Äî simply specify the categorical columns\n",
    "\n",
    "\n",
    "\n",
    "####  Ordered Boosting (vs. Standard Boosting)\n",
    "\n",
    "Traditional gradient boosting algorithms often suffer from **prediction shift**, a form of overfitting that occurs when the model uses the same data to compute residuals and to fit new trees.\n",
    "\n",
    "CatBoost addresses this with **ordered boosting**, a permutation-driven strategy that builds each tree on one subset of data and computes residuals on another (unseen) subset.\n",
    "\n",
    "Recall that gradient boosting fits trees on the gradient of the loss function:\n",
    "\n",
    "$$\n",
    "r_m = -\\left[ \\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)} \\right]_{f = f_{m-1}}\n",
    "$$\n",
    "\n",
    "In classic boosting, this gradient is calculated using the same training observations that were used to fit the model, which leads to target leakage.\n",
    "\n",
    "In contrast, CatBoost:\n",
    "\n",
    "- Shuffles the data at each iteration\n",
    "- Computes residuals for an observation **only from prior observations** in the permutation\n",
    "- Ensures that **each gradient estimate is based on unseen data**\n",
    "\n",
    "This significantly improves the model‚Äôs **generalizability** and reduces overfitting, especially on **small or noisy datasets**.\n",
    "\n",
    "\n",
    "\n",
    "####  Symmetric (Oblivious) Trees\n",
    "\n",
    "CatBoost builds **symmetric (oblivious) decision trees**, where the same splitting condition is applied across each level of the tree. This structure results in:\n",
    "\n",
    "- **Faster inference times**\n",
    "- **Compact model size**\n",
    "- **Improved regularization**, due to the constrained tree structure\n",
    "\n",
    "These trees are particularly well-suited for deployment scenarios where prediction speed matters.\n",
    "\n",
    "\n",
    "\n",
    "Together, these innovations make CatBoost a strong candidate for modeling **high-dimensional, categorical, and imbalanced tabular data**, even with minimal feature engineering or hyperparameter tuning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The authors have also shown that CatBoost performs better than XGBoost and LightGBM without tuning, i.e., with default hyperparameter settings.\n",
    "\n",
    "Read the [CatBoost paper](https://proceedings.neurips.cc/paper_files/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf) for more details.\n",
    "\n",
    "Here is a good [blog](https://neptune.ai/blog/when-to-choose-catboost-over-xgboost-or-lightgbm) listing the key features of CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3a95a",
   "metadata": {},
   "source": [
    "##  Installing and Using CatBoost with Scikit-Learn API\n",
    "\n",
    "CatBoost provides a **scikit-learn-compatible API** through `CatBoostClassifier` and `CatBoostRegressor`, which makes it easy to integrate into pipelines and use with tools like `GridSearchCV`, `cross_val_score`, and `train_test_split`.\n",
    "\n",
    "###  Installation\n",
    "\n",
    "To install CatBoost, run:\n",
    "\n",
    "``` python\n",
    "pip install catboost\n",
    "```\n",
    "> üí° GPU users: CatBoost automatically detects and uses GPU if available. You can explicitly enable it with `task_type='GPU'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c009a2",
   "metadata": {},
   "source": [
    "### CatBoost for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d987907",
   "metadata": {},
   "source": [
    "Let us check the performance of `CatBoostRegressor()` without tuning, i.e., with default hyperparameter settings on our car dataset\n",
    "\n",
    "The parameter `cat_features` will be used to specify the indices of the categorical predictors for target encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf0a6c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (CatBoost): 3307.2604\n",
      "Test R¬≤ (CatBoost): 0.9627\n"
     ]
    }
   ],
   "source": [
    "# build a catboostregressor model\n",
    "from catboost import CatBoostRegressor\n",
    "# Initialize the CatBoost regressor\n",
    "model_cat = CatBoostRegressor(\n",
    "    cat_features=categorical_feature,\n",
    "    random_seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_cat.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "y_pred_cat = model_cat.predict(X_test)\n",
    "# Calculate evaluation metrics\n",
    "rmse_cat = root_mean_squared_error(y_test, y_pred_cat)\n",
    "r2_cat = r2_score(y_test, y_pred_cat)\n",
    "# Output results\n",
    "print(f\"Test RMSE (CatBoost): {rmse_cat:.4f}\")\n",
    "print(f\"Test R¬≤ (CatBoost): {r2_cat:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895c618",
   "metadata": {},
   "source": [
    "Even with default hyperparameter settings, CatBoost has outperformed both XGBoost and LightGBM in terms of test RMSE and R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c009cc0",
   "metadata": {},
   "source": [
    "### Tuning `CatBoostRegressor` with Optuna\n",
    "\n",
    "You can tune the hyperparameters of `CatBoostRegressor` using Optuna, just as you would for XGBoost or LightGBM. However, CatBoost uses a different set of hyperparameters. \n",
    "\n",
    "For example, it does **not** include:\n",
    "\n",
    "- `reg_alpha`: L1 regularization on leaf weights  \n",
    "- `colsample_bytree`: Subsample ratio of columns when constructing each tree\n",
    "\n",
    "These parameters are available in XGBoost and LightGBM but are not part of CatBoost‚Äôs configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6403528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 03:37:01,074] A new study created in memory with name: no-name-782044d9-7185-49f6-a68b-ddc83fa639a4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 03:37:20,600] Trial 0 finished with value: -2592.5059280623623 and parameters: {'learning_rate': 0.07952470550019325, 'depth': 8, 'l2_leaf_reg': 0.001114023475261074, 'min_data_in_leaf': 27, 'border_count': 83, 'bagging_temperature': 0.5317851293779137, 'random_strength': 0.0005861214502486961, 'grow_policy': 'Depthwise'}. Best is trial 0 with value: -2592.5059280623623.\n",
      "[I 2025-05-14 03:37:31,837] Trial 1 finished with value: -2556.728680370376 and parameters: {'learning_rate': 0.245419708648389, 'depth': 7, 'l2_leaf_reg': 3.3386247434742167, 'min_data_in_leaf': 15, 'border_count': 100, 'bagging_temperature': 0.5050586506217019, 'random_strength': 0.0004718975881753086, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:37:40,883] Trial 2 finished with value: -2682.6259877001603 and parameters: {'learning_rate': 0.1520719761941552, 'depth': 8, 'l2_leaf_reg': 0.0046149514168069014, 'min_data_in_leaf': 8, 'border_count': 178, 'bagging_temperature': 0.24466088131049457, 'random_strength': 0.015640185801924847, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:38:15,606] Trial 3 finished with value: -2808.7037865332763 and parameters: {'learning_rate': 0.06614862212494911, 'depth': 10, 'l2_leaf_reg': 0.7245780669681481, 'min_data_in_leaf': 19, 'border_count': 34, 'bagging_temperature': 0.8902029685133379, 'random_strength': 0.013193287592498581, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:38:30,461] Trial 4 finished with value: -2740.549186918632 and parameters: {'learning_rate': 0.2585298479851385, 'depth': 7, 'l2_leaf_reg': 0.12149380817119523, 'min_data_in_leaf': 24, 'border_count': 61, 'bagging_temperature': 0.7820109206688168, 'random_strength': 0.00013909547722379054, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:39:21,344] Trial 5 finished with value: -2699.921784155897 and parameters: {'learning_rate': 0.1558390710067145, 'depth': 8, 'l2_leaf_reg': 2.8639962432617574e-06, 'min_data_in_leaf': 21, 'border_count': 129, 'bagging_temperature': 0.27054829342202646, 'random_strength': 1.0090519644888372, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:39:33,102] Trial 6 finished with value: -2761.634505100397 and parameters: {'learning_rate': 0.29273701564295207, 'depth': 8, 'l2_leaf_reg': 0.0001383950532512802, 'min_data_in_leaf': 29, 'border_count': 53, 'bagging_temperature': 0.543935579774364, 'random_strength': 1.3150608041342185e-05, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:39:42,048] Trial 7 finished with value: -2796.3445154770925 and parameters: {'learning_rate': 0.1985854921483664, 'depth': 5, 'l2_leaf_reg': 0.0017893237819096464, 'min_data_in_leaf': 24, 'border_count': 228, 'bagging_temperature': 0.6563761366663239, 'random_strength': 3.830259157708319e-05, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:40:06,522] Trial 8 finished with value: -2736.652008119944 and parameters: {'learning_rate': 0.12981791308255294, 'depth': 9, 'l2_leaf_reg': 3.6626986581511205, 'min_data_in_leaf': 14, 'border_count': 169, 'bagging_temperature': 0.26693935389565604, 'random_strength': 6.108854259908809e-08, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:40:33,641] Trial 9 finished with value: -2625.6156037888204 and parameters: {'learning_rate': 0.05266635206771846, 'depth': 10, 'l2_leaf_reg': 8.431301598557988e-05, 'min_data_in_leaf': 22, 'border_count': 38, 'bagging_temperature': 0.20458732239577748, 'random_strength': 0.00026802410291762685, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:40:53,462] Trial 10 finished with value: -2802.6759048814906 and parameters: {'learning_rate': 0.2321480916058081, 'depth': 5, 'l2_leaf_reg': 1.9294653593783387e-08, 'min_data_in_leaf': 2, 'border_count': 110, 'bagging_temperature': 0.024153475153251502, 'random_strength': 3.071215792269348e-07, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:41:09,188] Trial 11 finished with value: -2626.5794465595454 and parameters: {'learning_rate': 0.0931538267421292, 'depth': 7, 'l2_leaf_reg': 0.044383501183871764, 'min_data_in_leaf': 13, 'border_count': 94, 'bagging_temperature': 0.46970044709843706, 'random_strength': 0.010496613104965287, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:42:21,080] Trial 12 finished with value: -2623.594568822965 and parameters: {'learning_rate': 0.013207489266983119, 'depth': 6, 'l2_leaf_reg': 6.27769599914231e-07, 'min_data_in_leaf': 10, 'border_count': 82, 'bagging_temperature': 0.4901244457515505, 'random_strength': 2.391770871806472e-06, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:42:39,928] Trial 13 finished with value: -2840.1838885804445 and parameters: {'learning_rate': 0.20525833721959236, 'depth': 4, 'l2_leaf_reg': 5.674336337792675, 'min_data_in_leaf': 29, 'border_count': 137, 'bagging_temperature': 0.672572957300273, 'random_strength': 0.0022624464321546684, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:42:58,745] Trial 14 finished with value: -2655.490477601683 and parameters: {'learning_rate': 0.10736768228799226, 'depth': 6, 'l2_leaf_reg': 0.01831562504579733, 'min_data_in_leaf': 17, 'border_count': 82, 'bagging_temperature': 0.4256033457922353, 'random_strength': 6.775957335351946, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:43:07,127] Trial 15 finished with value: -2789.7188981990007 and parameters: {'learning_rate': 0.17513907427821254, 'depth': 9, 'l2_leaf_reg': 6.515138402249421e-06, 'min_data_in_leaf': 7, 'border_count': 169, 'bagging_temperature': 0.9865139963615146, 'random_strength': 0.14575672222120323, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:43:41,175] Trial 16 finished with value: -2621.361959827787 and parameters: {'learning_rate': 0.2821616638222643, 'depth': 6, 'l2_leaf_reg': 0.33163654681962784, 'min_data_in_leaf': 26, 'border_count': 115, 'bagging_temperature': 0.6342355083316009, 'random_strength': 0.001346200849628001, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: -2556.728680370376.\n",
      "[I 2025-05-14 03:44:43,383] Trial 17 finished with value: -2556.489614367946 and parameters: {'learning_rate': 0.01940229207182844, 'depth': 9, 'l2_leaf_reg': 0.0010525861450567827, 'min_data_in_leaf': 12, 'border_count': 72, 'bagging_temperature': 0.3496687786887461, 'random_strength': 4.041308474367292e-06, 'grow_policy': 'Depthwise'}. Best is trial 17 with value: -2556.489614367946.\n",
      "[I 2025-05-14 03:45:42,592] Trial 18 finished with value: -2866.4522097973445 and parameters: {'learning_rate': 0.01596497708445574, 'depth': 9, 'l2_leaf_reg': 1.1159472661594606e-08, 'min_data_in_leaf': 4, 'border_count': 248, 'bagging_temperature': 0.3623887368574112, 'random_strength': 2.1384578490475107e-06, 'grow_policy': 'Depthwise'}. Best is trial 17 with value: -2556.489614367946.\n",
      "[I 2025-05-14 03:46:46,564] Trial 19 finished with value: -2708.191790901802 and parameters: {'learning_rate': 0.24477192572019485, 'depth': 7, 'l2_leaf_reg': 2.3098308271653418e-05, 'min_data_in_leaf': 12, 'border_count': 59, 'bagging_temperature': 0.0711240090347467, 'random_strength': 5.019623855651714e-08, 'grow_policy': 'Lossguide'}. Best is trial 17 with value: -2556.489614367946.\n",
      "[I 2025-05-14 03:47:09,708] Trial 20 finished with value: -2629.0927431412074 and parameters: {'learning_rate': 0.045281219242332915, 'depth': 10, 'l2_leaf_reg': 0.010169259979428625, 'min_data_in_leaf': 17, 'border_count': 190, 'bagging_temperature': 0.13109532595280188, 'random_strength': 5.725889350557309e-06, 'grow_policy': 'Depthwise'}. Best is trial 17 with value: -2556.489614367946.\n",
      "[I 2025-05-14 03:47:28,038] Trial 21 finished with value: -2662.8455154565036 and parameters: {'learning_rate': 0.08417126506035016, 'depth': 8, 'l2_leaf_reg': 0.0006641702867048814, 'min_data_in_leaf': 16, 'border_count': 95, 'bagging_temperature': 0.3550175252017867, 'random_strength': 6.473733730238062e-05, 'grow_policy': 'Depthwise'}. Best is trial 17 with value: -2556.489614367946.\n",
      "[I 2025-05-14 03:48:22,098] Trial 22 finished with value: -2553.5175758331197 and parameters: {'learning_rate': 0.02854304599072048, 'depth': 9, 'l2_leaf_reg': 0.0004429789647772918, 'min_data_in_leaf': 10, 'border_count': 67, 'bagging_temperature': 0.5558186913583201, 'random_strength': 0.0014086113230469067, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:49:10,065] Trial 23 finished with value: -2567.391805156711 and parameters: {'learning_rate': 0.026764961342591816, 'depth': 9, 'l2_leaf_reg': 4.0555978330521646e-07, 'min_data_in_leaf': 10, 'border_count': 68, 'bagging_temperature': 0.5904786989858626, 'random_strength': 0.003513242023709581, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:49:22,054] Trial 24 finished with value: -2622.624216994232 and parameters: {'learning_rate': 0.11762433128006189, 'depth': 7, 'l2_leaf_reg': 0.00011122236949708718, 'min_data_in_leaf': 6, 'border_count': 112, 'bagging_temperature': 0.7681535959955343, 'random_strength': 6.673067700091263e-07, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:49:53,628] Trial 25 finished with value: -2566.687493479829 and parameters: {'learning_rate': 0.0428655871308162, 'depth': 9, 'l2_leaf_reg': 1.2056415233295121, 'min_data_in_leaf': 11, 'border_count': 146, 'bagging_temperature': 0.38006611000782997, 'random_strength': 0.09046406371852381, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:50:02,251] Trial 26 finished with value: -2832.1352269234903 and parameters: {'learning_rate': 0.1970147411078323, 'depth': 10, 'l2_leaf_reg': 0.07162501984849304, 'min_data_in_leaf': 14, 'border_count': 48, 'bagging_temperature': 0.7456911509314165, 'random_strength': 1.598786064756365e-05, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:50:40,171] Trial 27 finished with value: -2601.1648427815717 and parameters: {'learning_rate': 0.038043609585293056, 'depth': 7, 'l2_leaf_reg': 1.6824470580542856e-05, 'min_data_in_leaf': 9, 'border_count': 69, 'bagging_temperature': 0.4427744483199044, 'random_strength': 0.00030247232285297106, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:51:03,817] Trial 28 finished with value: -2723.539972578103 and parameters: {'learning_rate': 0.063339552281372, 'depth': 9, 'l2_leaf_reg': 0.0033137305082140056, 'min_data_in_leaf': 5, 'border_count': 100, 'bagging_temperature': 0.5728331614449053, 'random_strength': 0.08608571674502018, 'grow_policy': 'SymmetricTree'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:51:44,354] Trial 29 finished with value: -2903.438265613962 and parameters: {'learning_rate': 0.22327494818582883, 'depth': 8, 'l2_leaf_reg': 0.00046397471558624393, 'min_data_in_leaf': 19, 'border_count': 77, 'bagging_temperature': 0.33115797120918855, 'random_strength': 0.001283308483124051, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:51:53,564] Trial 30 finished with value: -3143.416961771734 and parameters: {'learning_rate': 0.2615824515538357, 'depth': 8, 'l2_leaf_reg': 2.6721859802422237e-07, 'min_data_in_leaf': 2, 'border_count': 150, 'bagging_temperature': 0.5255403450913998, 'random_strength': 3.7142097112219726e-07, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:53:18,711] Trial 31 finished with value: -2620.1543675837006 and parameters: {'learning_rate': 0.036092954832845386, 'depth': 9, 'l2_leaf_reg': 1.6375335570564933, 'min_data_in_leaf': 11, 'border_count': 126, 'bagging_temperature': 0.4070745587934888, 'random_strength': 1.0037092538282515e-08, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:53:59,231] Trial 32 finished with value: -2566.1296831641434 and parameters: {'learning_rate': 0.06594270014769671, 'depth': 9, 'l2_leaf_reg': 0.5692095900658858, 'min_data_in_leaf': 12, 'border_count': 208, 'bagging_temperature': 0.3165260807907623, 'random_strength': 0.06397745585020524, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:54:35,567] Trial 33 finished with value: -2638.995606936495 and parameters: {'learning_rate': 0.07724237363909499, 'depth': 8, 'l2_leaf_reg': 0.2844212377732495, 'min_data_in_leaf': 15, 'border_count': 204, 'bagging_temperature': 0.16971199093261635, 'random_strength': 0.04813732436092434, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:56:06,127] Trial 34 finished with value: -2647.590494720153 and parameters: {'learning_rate': 0.06460022496756479, 'depth': 10, 'l2_leaf_reg': 6.601504952572579, 'min_data_in_leaf': 8, 'border_count': 215, 'bagging_temperature': 0.280595071181398, 'random_strength': 0.5822640982430759, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 03:56:26,769] Trial 35 finished with value: -2625.921488111509 and parameters: {'learning_rate': 0.14705058259331355, 'depth': 10, 'l2_leaf_reg': 0.017914490598987375, 'min_data_in_leaf': 13, 'border_count': 39, 'bagging_temperature': 0.3287024903377104, 'random_strength': 0.008267542278170484, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:00:07,278] Trial 36 finished with value: -2713.318053553942 and parameters: {'learning_rate': 0.011286702277088917, 'depth': 8, 'l2_leaf_reg': 0.2339927288492896, 'min_data_in_leaf': 18, 'border_count': 243, 'bagging_temperature': 0.5034843298839619, 'random_strength': 0.00055952127058293, 'grow_policy': 'SymmetricTree'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:01:52,318] Trial 37 finished with value: -2599.3830690422274 and parameters: {'learning_rate': 0.026614468934226813, 'depth': 9, 'l2_leaf_reg': 0.006370159217597417, 'min_data_in_leaf': 8, 'border_count': 97, 'bagging_temperature': 0.855566752212292, 'random_strength': 8.32305758695803e-05, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:02:36,816] Trial 38 finished with value: -2610.623762642826 and parameters: {'learning_rate': 0.09686963957512237, 'depth': 7, 'l2_leaf_reg': 0.0014074747896680212, 'min_data_in_leaf': 21, 'border_count': 71, 'bagging_temperature': 0.7156956610821732, 'random_strength': 0.018501470320959317, 'grow_policy': 'SymmetricTree'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:03:07,048] Trial 39 finished with value: -2671.015969019692 and parameters: {'learning_rate': 0.16854993390170198, 'depth': 6, 'l2_leaf_reg': 0.6496465232605684, 'min_data_in_leaf': 15, 'border_count': 53, 'bagging_temperature': 0.22219445776878718, 'random_strength': 0.7258361806395729, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:04:30,028] Trial 40 finished with value: -2575.0422520898715 and parameters: {'learning_rate': 0.13301237034987956, 'depth': 8, 'l2_leaf_reg': 0.00025678296288065243, 'min_data_in_leaf': 13, 'border_count': 129, 'bagging_temperature': 0.5756243041812479, 'random_strength': 1.949907402720845e-05, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:05:48,971] Trial 41 finished with value: -2642.556436107284 and parameters: {'learning_rate': 0.049948179063764114, 'depth': 9, 'l2_leaf_reg': 1.5618546291904019, 'min_data_in_leaf': 11, 'border_count': 158, 'bagging_temperature': 0.3964202751479039, 'random_strength': 2.393747505741706, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:06:46,627] Trial 42 finished with value: -2598.4755135822797 and parameters: {'learning_rate': 0.0580674532442787, 'depth': 9, 'l2_leaf_reg': 1.8177693207658425, 'min_data_in_leaf': 11, 'border_count': 187, 'bagging_temperature': 0.29635746209371416, 'random_strength': 0.21208291644651261, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:07:19,719] Trial 43 finished with value: -2657.7880298639225 and parameters: {'learning_rate': 0.07363937743695215, 'depth': 10, 'l2_leaf_reg': 0.04359530886331162, 'min_data_in_leaf': 9, 'border_count': 217, 'bagging_temperature': 0.44664672961449514, 'random_strength': 0.04495554133929357, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:09:46,045] Trial 44 finished with value: -2691.606927827555 and parameters: {'learning_rate': 0.029786575860281366, 'depth': 9, 'l2_leaf_reg': 9.943736562101853, 'min_data_in_leaf': 12, 'border_count': 152, 'bagging_temperature': 0.36930442821158393, 'random_strength': 0.0038218125123354175, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:10:38,605] Trial 45 finished with value: -2616.0330119726023 and parameters: {'learning_rate': 0.046671945704494774, 'depth': 8, 'l2_leaf_reg': 0.12115447142224317, 'min_data_in_leaf': 14, 'border_count': 140, 'bagging_temperature': 0.48481335723150554, 'random_strength': 0.3294399030680058, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:12:54,361] Trial 46 finished with value: -2590.002658938037 and parameters: {'learning_rate': 0.025820733438051514, 'depth': 10, 'l2_leaf_reg': 1.0279696260416582, 'min_data_in_leaf': 16, 'border_count': 85, 'bagging_temperature': 0.2455200340992076, 'random_strength': 0.00015044433051361004, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:13:57,004] Trial 47 finished with value: -2635.6488533277184 and parameters: {'learning_rate': 0.09024036605373528, 'depth': 7, 'l2_leaf_reg': 5.4022309753871646e-05, 'min_data_in_leaf': 19, 'border_count': 43, 'bagging_temperature': 0.5347005159269773, 'random_strength': 0.017468337161715447, 'grow_policy': 'SymmetricTree'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:14:16,489] Trial 48 finished with value: -2832.750001651622 and parameters: {'learning_rate': 0.29562301087772724, 'depth': 9, 'l2_leaf_reg': 4.218536936460986, 'min_data_in_leaf': 10, 'border_count': 232, 'bagging_temperature': 0.6069911018530717, 'random_strength': 1.9157498081287359, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n",
      "[I 2025-05-14 04:14:46,553] Trial 49 finished with value: -2609.0502948976673 and parameters: {'learning_rate': 0.10265216059916468, 'depth': 8, 'l2_leaf_reg': 0.6037874295139654, 'min_data_in_leaf': 7, 'border_count': 122, 'bagging_temperature': 0.39641107195397474, 'random_strength': 0.0009672456521149151, 'grow_policy': 'Depthwise'}. Best is trial 22 with value: -2553.5175758331197.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import create_study\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# create a validation set for early stopping\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "#convert to Catboost pool\n",
    "train_pool = Pool(X_train, y_train, cat_features=categorical_feature)\n",
    "valid_pool = Pool(X_valid, y_valid, cat_features=categorical_feature)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 30),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        \n",
    "        # Fixed parameters\n",
    "        'iterations': 3000,  # Set to a high number, early stopping will determine the actual number\n",
    "        'verbose': False,\n",
    "        'random_seed': 42\n",
    "    }\n",
    "    \n",
    "    # Create and train the model with early stopping\n",
    "    model = CatBoostRegressor(**params)\n",
    "    \n",
    "    # Use early stopping to prevent overfitting\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=valid_pool,\n",
    "        early_stopping_rounds=20,  # Stop if no improvement for 50 rounds\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_pred = model.predict(valid_pool)\n",
    "    val_rmse = root_mean_squared_error(y_valid, y_pred)\n",
    "    \n",
    "    # Return negative RMSE (for maximization)\n",
    "    return -val_rmse\n",
    "\n",
    "# Create and run the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e347a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.02854304599072048, 'depth': 9, 'l2_leaf_reg': 0.0004429789647772918, 'min_data_in_leaf': 10, 'border_count': 67, 'bagging_temperature': 0.5558186913583201, 'random_strength': 0.0014086113230469067, 'grow_policy': 'Depthwise'}\n",
      "Best trial: FrozenTrial(number=22, state=1, values=[-2553.5175758331197], datetime_start=datetime.datetime(2025, 5, 14, 3, 47, 28, 39246), datetime_complete=datetime.datetime(2025, 5, 14, 3, 48, 22, 98057), params={'learning_rate': 0.02854304599072048, 'depth': 9, 'l2_leaf_reg': 0.0004429789647772918, 'min_data_in_leaf': 10, 'border_count': 67, 'bagging_temperature': 0.5558186913583201, 'random_strength': 0.0014086113230469067, 'grow_policy': 'Depthwise'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'depth': IntDistribution(high=10, log=False, low=4, step=1), 'l2_leaf_reg': FloatDistribution(high=10.0, log=True, low=1e-08, step=None), 'min_data_in_leaf': IntDistribution(high=30, log=False, low=1, step=1), 'border_count': IntDistribution(high=255, log=False, low=32, step=1), 'bagging_temperature': FloatDistribution(high=1.0, log=False, low=0.0, step=None), 'random_strength': FloatDistribution(high=10.0, log=True, low=1e-08, step=None), 'grow_policy': CategoricalDistribution(choices=('SymmetricTree', 'Depthwise', 'Lossguide'))}, trial_id=22, value=None)\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters and train final model with early stopping\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Get the best trial\n",
    "best_trial = study.best_trial\n",
    "print(\"Best trial:\", best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58e1c2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48750, 17949, 22995, ..., 27300,  7952, 13498], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "700beb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of trees used: 466\n",
      "Test RMSE: 3042.9611\n",
      "Test R¬≤: 0.9684\n"
     ]
    }
   ],
   "source": [
    "# Use column indices instead of names\n",
    "cat_feature_indices = [X_train.columns.get_loc(col) for col in categorical_feature]\n",
    "\n",
    "# Add iterations parameter back for final model\n",
    "best_params['iterations'] = 3000  # High number, early stopping will be used\n",
    "\n",
    "# create a train+validation set for final model\n",
    "train_val_pool = Pool(\n",
    "    np.vstack((X_train, X_valid)),\n",
    "    np.concatenate((y_train, y_valid)),\n",
    "    cat_features=cat_feature_indices\n",
    ")\n",
    "\n",
    "# Create a test pool\n",
    "test_pool = Pool(X_test, y_test, cat_features=categorical_feature)\n",
    "\n",
    "# Train final model on combined train+validation data\n",
    "final_model = CatBoostRegressor(**best_params)\n",
    "final_model.fit(\n",
    "    train_val_pool,\n",
    "    eval_set=test_pool,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Get actual number of trees used after early stopping\n",
    "actual_iterations = final_model.tree_count_\n",
    "print(f\"Actual number of trees used: {actual_iterations}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "test_rmse = root_mean_squared_error(y_test, y_pred_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Test R¬≤: {test_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c35df952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          -2592.5059280623623,
          -2556.728680370376,
          -2682.6259877001603,
          -2808.7037865332763,
          -2740.549186918632,
          -2699.921784155897,
          -2761.634505100397,
          -2796.3445154770925,
          -2736.652008119944,
          -2625.6156037888204,
          -2802.6759048814906,
          -2626.5794465595454,
          -2623.594568822965,
          -2840.1838885804445,
          -2655.490477601683,
          -2789.7188981990007,
          -2621.361959827787,
          -2556.489614367946,
          -2866.4522097973445,
          -2708.191790901802,
          -2629.0927431412074,
          -2662.8455154565036,
          -2553.5175758331197,
          -2567.391805156711,
          -2622.624216994232,
          -2566.687493479829,
          -2832.1352269234903,
          -2601.1648427815717,
          -2723.539972578103,
          -2903.438265613962,
          -3143.416961771734,
          -2620.1543675837006,
          -2566.1296831641434,
          -2638.995606936495,
          -2647.590494720153,
          -2625.921488111509,
          -2713.318053553942,
          -2599.3830690422274,
          -2610.623762642826,
          -2671.015969019692,
          -2575.0422520898715,
          -2642.556436107284,
          -2598.4755135822797,
          -2657.7880298639225,
          -2691.606927827555,
          -2616.0330119726023,
          -2590.002658938037,
          -2635.6488533277184,
          -2832.750001651622,
          -2609.0502948976673
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          -2592.5059280623623,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.728680370376,
          -2556.489614367946,
          -2556.489614367946,
          -2556.489614367946,
          -2556.489614367946,
          -2556.489614367946,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197,
          -2553.5175758331197
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "random_strength (FloatDistribution): 0.002233799707746103<extra></extra>",
          "l2_leaf_reg (FloatDistribution): 0.04323416555068531<extra></extra>",
          "depth (IntDistribution): 0.05754643936775967<extra></extra>",
          "border_count (IntDistribution): 0.06528494979325045<extra></extra>",
          "grow_policy (CategoricalDistribution): 0.08049413617680277<extra></extra>",
          "bagging_temperature (FloatDistribution): 0.09979658097457865<extra></extra>",
          "min_data_in_leaf (IntDistribution): 0.22780463848559765<extra></extra>",
          "learning_rate (FloatDistribution): 0.42360528994357916<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "<0.01",
          "0.04",
          "0.06",
          "0.07",
          "0.08",
          "0.10",
          "0.23",
          "0.42"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.002233799707746103,
          0.04323416555068531,
          0.05754643936775967,
          0.06528494979325045,
          0.08049413617680277,
          0.09979658097457865,
          0.22780463848559765,
          0.42360528994357916
         ],
         "y": [
          "random_strength",
          "l2_leaf_reg",
          "depth",
          "border_count",
          "grow_policy",
          "bagging_temperature",
          "min_data_in_leaf",
          "learning_rate"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = optuna.visualization.plot_optimization_history(study)\n",
    "fig1.show()\n",
    "    \n",
    "fig2 = optuna.visualization.plot_param_importances(study)\n",
    "fig2.show()\n",
    "    \n",
    "# Plot feature importance from the final model\n",
    "feature_importance = final_model.get_feature_importance()\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx])\n",
    "plt.yticks(range(len(sorted_idx)), np.array(range(X.shape[1]))[sorted_idx])\n",
    "plt.title('CatBoost Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77739800",
   "metadata": {},
   "source": [
    "It takes 2 minutes to tune CatBoost, which is higher than LightGBM and lesser than XGBoost. CatBoost falls in between LightGBM and XGBoost in terms of speed. However, it is likely to be more accurate than XGBoost and LighGBM, and likely to require lesser tuning as compared to XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134a836",
   "metadata": {},
   "source": [
    "Check the [documentation](https://catboost.ai/en/docs/references/training-parameters/common) for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff1eeb",
   "metadata": {},
   "source": [
    "###  When to Use **CatBoost** Over **XGBoost**\n",
    "\n",
    "- When your dataset contains **many categorical features**  \n",
    "- **CatBoost** tends to perform well **out of the box** with minimal hyperparameter tuning, making it more user-friendly for quick experimentation or deployment  \n",
    "- CatBoost‚Äôs **GPU implementation** is optimized for handling categorical data efficiently, and can **outperform XGBoost** on datasets dominated by categorical variables  \n",
    "  > While both libraries support GPU acceleration, CatBoost's architecture is particularly well-suited for categorical-heavy tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39185a87",
   "metadata": {},
   "source": [
    "##  Handling Imbalanced Classification: XGBoost vs. LightGBM vs. CatBoost\n",
    "\n",
    "Imbalanced classification occurs when one class significantly outnumbers the other (e.g., fraud detection, disease diagnosis). Each boosting library offers tools to address this issue.\n",
    "\n",
    "\n",
    "\n",
    "###  XGBoost\n",
    "\n",
    "- **Parameter**: `scale_pos_weight`\n",
    "  - Formula:  \n",
    "    $$\n",
    "    \\texttt{scale\\_pos\\_weight} = \\frac{\\text{Number of negative samples}}{\\text{Number of positive samples}}\n",
    "    $$\n",
    "  - Increases the gradient of the positive class during training.\n",
    "- **Additional Strategies**:\n",
    "  - Use custom `eval_metric` (e.g., `\"auc\"`, `\"aucpr\"`, or `\"logloss\"`)\n",
    "  - Apply early stopping on validation AUC\n",
    "\n",
    "\n",
    "\n",
    "###  LightGBM\n",
    "\n",
    "- **Parameter**: `scale_pos_weight` (same as in XGBoost)\n",
    "- **Alternative**: `is_unbalance = TRUE`\n",
    "  - Automatically adjusts class weights based on distribution\n",
    "- **Other Tips**:\n",
    "  - Use `metric = \"auc\"` or `\"binary_logloss\"` for better guidance during training\n",
    "  - Resampling techniques also compatible\n",
    "\n",
    "\n",
    "\n",
    "###  CatBoost\n",
    "\n",
    "- **Parameter**: `class_weights`\n",
    "  - Accepts a numeric vector (e.g., `class_weights = c(1, 5)` for [negative, positive])\n",
    "  - Directly modifies the loss function to emphasize minority class\n",
    "- **Advantages**:\n",
    "  - More flexible than `scale_pos_weight`\n",
    "  - Works well with default settings\n",
    "- **Other Tips**:\n",
    "  - Use `loss_function = \"Logloss\"` and `eval_metric = \"AUC\"` for binary classification\n",
    "\n",
    "\n",
    "\n",
    "###  Summary\n",
    "\n",
    "| Library   | Imbalance Handling Parameter          | Default Support        | Recommended Metric         |\n",
    "|-----------|----------------------------------------|-------------------------|-----------------------------|\n",
    "| XGBoost   | `scale_pos_weight`                    | No                      | `auc`, `aucpr`              |\n",
    "| LightGBM  | `scale_pos_weight`, `is_unbalance`    | Yes (with flag)         | `auc`, `binary_logloss`     |\n",
    "| CatBoost  | `class_weights`                       | Yes                     | `Logloss`, `AUC`            |\n",
    "\n",
    "### Common Strategies Across All Libraries\n",
    "\n",
    "* **Evaluation Metrics:** Use metrics like **F1-score**, **AUC-PR** (Area Under the Precision-Recall Curve), or **Matthews Correlation Coefficient (MCC)** instead of accuracy.\n",
    "* **Threshold Tuning:** Adjust the decision threshold to prioritize precision or recall.\n",
    "* **Stratified Sampling:** Ensure balanced splits during train-test splits or cross-validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bedc733",
   "metadata": {},
   "source": [
    "##  Summary: XGBoost vs. LightGBM vs. CatBoost\n",
    "\n",
    "Gradient boosting is a powerful ensemble technique, and XGBoost, LightGBM, and CatBoost are three of its most widely used implementations. Each has unique strengths and is well-suited to different use cases.\n",
    "\n",
    "###  XGBoost\n",
    "\n",
    "- **Strengths**: Robust, well-documented, strong performance on structured/tabular data  \n",
    "- **Split Finding**: Level-wise tree growth  \n",
    "- **Regularization**: Explicit L1 and L2 regularization  \n",
    "- **Flexibility**: Highly customizable with many hyperparameters  \n",
    "- **Best for**: General-purpose tabular data, especially when you have time to tune parameters\n",
    "\n",
    "###  LightGBM\n",
    "\n",
    "- **Strengths**: Fast training, low memory usage, excellent scalability  \n",
    "- **Split Finding**: Leaf-wise tree growth with depth control  \n",
    "- **Binning**: Uses histogram-based algorithm with `max_bin` to speed up training  \n",
    "- **Best for**: Large-scale datasets, high-dimensional features, and when training speed matters\n",
    "\n",
    "###  CatBoost\n",
    "\n",
    "- **Strengths**: Handles categorical features natively, works well with minimal tuning  \n",
    "- **Boosting Innovation**: Uses *ordered boosting* to prevent prediction shift  \n",
    "- **Categorical Encoding**: No need for manual preprocessing ‚Äî uses target-based encoding internally  \n",
    "- **Best for**: Datasets with many categorical variables or limited time for tuning\n",
    "\n",
    "\n",
    "\n",
    "###  Final Thoughts\n",
    "All three libraries are powerful and battle-tested. Here's a rough guideline:\n",
    "\n",
    "- **Use XGBoost** if you want control, flexibility, and a well-documented standard\n",
    "- **Use LightGBM** when training speed and large data scalability are your top priorities\n",
    "- **Use CatBoost** when working with many categorical features or seeking strong baseline results with minimal tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd7460",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [LightGBM Paper (Original NIPS 2017)](https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf)\n",
    "* [LightGBM Official Website](https://lightgbm.readthedocs.io/)\n",
    "* [CatBoost Paper (arXiv)](https://arxiv.org/abs/1810.11363)\n",
    "* [CatBoost Official Website](https://catboost.ai/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
