{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bd972c94",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Assignment E\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a5837",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity. \n",
    "\n",
    "2. Write your code in the *Code* cells and your answer in the *Markdown* cells of the Jupyter notebook. Ensure that the solution is written neatly enough to understand and grade.\n",
    "\n",
    "3. Use [Quarto](https://quarto.org/docs/output-formats/html-basics.html) to print the *.ipynb* file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: `quarto render filename.ipynb --to html`. Submit the HTML file.\n",
    "\n",
    "4. The assignment is worth 100 points, and is due on **Monday, 5th June 2023 at 11:59 pm**. \n",
    "\n",
    "5. All the estimated code execution times in this assignment are based of an instance of *n1-standard-32 (32 cores virtual machine)* on Google colab.\n",
    "\n",
    "6. **Five points are properly formatting the assignment**. The breakdown is as follows:\n",
    "- Must be an HTML file rendered using Quarto (2 pts).\n",
    "- There aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.) (1 pt)\n",
    "- Final answers of each question are written in Markdown cells (1 pt).\n",
    "- There is no piece of unnecessary / redundant code, and no unnecessary / redundant text (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108aa2fa",
   "metadata": {},
   "source": [
    "## Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88646788",
   "metadata": {},
   "source": [
    "### Ensembling\n",
    "\n",
    "Is it possible for an ensemble model to perform worse than one or more of the individual models? Why or Why not?\n",
    "\n",
    "*(1 + 4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66ef2f",
   "metadata": {},
   "source": [
    "### Ensemble fail\n",
    "If an ensemble model does perform worse than one or more of the individual models, then what should be the course of action?\n",
    "\n",
    "*(3 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b697b3",
   "metadata": {},
   "source": [
    "## Regression Problem - Miami housing\n",
    "### Data preparation\n",
    "Read the data *miami-housing.csv*. Check the description of the variables [here](https://www.kaggle.com/datasets/deepcontractor/miami-housing-dataset). Split the data into 60% train and 40% test. Use `random_state = 45`. The response is `SALE_PRC`, and the rest of the columns are predictors, except `PARCELNO`. Print the shape of the predictors dataframe of the train data.\n",
    "\n",
    "*(1 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a34ecb",
   "metadata": {},
   "source": [
    "### MARS model\n",
    "Develop a MARS model to predict `SALE_PRC` based on all the predictors. Compute the MAE on test data.\n",
    "\n",
    "Assume that you have used `GridSearchCV` to tune the `max_degree` hyperparameter of the model, and the optimal value comes out to be `max_degree = 3`. Use this value to train the model. \n",
    "\n",
    "*Estimated code execution time: 1 minute*\n",
    "\n",
    "The test MAE should be around **$55,000**. \n",
    "\n",
    "*(2 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33223d6b",
   "metadata": {},
   "source": [
    "### Bagged MARS model\n",
    "Bag 20 MARS model with the same value of `max_degree`, and report the test MAE based on the bagged MARS model.\n",
    "\n",
    "*Estimated code execution time: 5 minutes*\n",
    "\n",
    "The test MAE should be around **$51,000**. \n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b922d",
   "metadata": {},
   "source": [
    "### Voting ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc433c",
   "metadata": {},
   "source": [
    "Develop a voting ensemble model with:\n",
    "\n",
    "1. The bagged MARS model developed in [E.2.3](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#bagged-mars-model), \n",
    "\n",
    "2. The tuned bagged tree model developed in [C.1.6.2](https://nustat.github.io/STAT303-3-class-notes/Assignment%20C.html#tuning-the-hyperparameters)\n",
    "\n",
    "3. The tuned random forest model developed in [C.1.8.1](https://nustat.github.io/STAT303-3-class-notes/Assignment%20C.html#tuning-random-forest)\n",
    "\n",
    "4. The tuned AdaBoost model developed in [D.2.2](https://nustat.github.io/STAT303-3-class-notes/Assignment%20D.html#adaboost-hyperparameter-tuning)\n",
    "\n",
    "5. The tuned Gradient boosting model *(with Huber loss)* developed in [D.2.6](https://nustat.github.io/STAT303-3-class-notes/Assignment%20D.html#gradient-boosting-huber-loss-hyperparameter-tuning)\n",
    "\n",
    "6. The tuned XGBoost model developed in [D.2.10](https://nustat.github.io/STAT303-3-class-notes/Assignment%20D.html#xgboost-hyperparameter-tuning)\n",
    "\n",
    "Report the MAE of each of the above models *(1-6)*, and the voting ensemble.\n",
    "\n",
    "The MAE of the voting ensemble is likely to be higher than some of the individual models, as these models have a broad range of MAEs *(see equation 10.1 in [class notes](https://nustat.github.io/STAT303-3-class-notes/Lec10_Ensemble.html))*.\n",
    "\n",
    "*Note:*\n",
    "\n",
    "*1. If you had replaced the boosting models in (5) and (6) with other boosting models, you can use those.*\n",
    "\n",
    "*2. You may either use the function `VotingRegressor()` or just take the average of the predictions of all the models and compute the MAE. The latter will be quicker as you have already fitted the individual models to compute their predictions and respective MAEs, so you don't need to fit the models again with `VotingRegressor()`*\n",
    "\n",
    "*(6 + 4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c2be9",
   "metadata": {},
   "source": [
    "### Voting ensemble with good models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a598110",
   "metadata": {},
   "source": [
    "Only ensemble those models that have comparable MAEs and relatively low MAEs. These are likely to be models (5) and (6) in the previous question ([E.2.4](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble)). Report the MAE of this voting ensemble.\n",
    "\n",
    "This ensemble is likely to have a lower MAE than each of the models *1-6* in the previous question ([E.2.4](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble)).\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab21e73",
   "metadata": {},
   "source": [
    "### Stacking ensemble with Linear regression\n",
    "\n",
    "Develop a linear regression metamodel based on models *1-6* in [E.2.4](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble). Report the MAE of the metamodel on test data. Which model has the highest weight in the ensemble?\n",
    "\n",
    "*Note:*\n",
    "\n",
    "1. You may use the `StackingRegressor()` function. However, as the next set of questions ask you to develop different metamodels based on the models *1-6* in [E.2.4](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble), using the `StackingRegressor()` will be inefficient as it will involve fitting each of the individual models every time it is called.\n",
    "\n",
    "2. A faster way will be to use the `cross_val_predict()` function to compute th 5-fold cross-validated predictions from each of the models *1-6*, consider these predictions from the 6 models as 6 different predictors, and fit the metamodel. Once computed, these cross-validated predictions can be used with different metamodels without the need of fitting the individual models repeatedly with `StackingRegressor()`.\n",
    "\n",
    "*(8 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd907131",
   "metadata": {},
   "source": [
    "### Stacking ensemble with Lasso\n",
    "Develop a lasso metamodel based on models *1-6* in [E.2.4](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble). Tune the hyperparameter `C` for the lasso metamodel. Report the MAE of the metamodel on test data. \n",
    "\n",
    "*(6 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a211a7",
   "metadata": {},
   "source": [
    "### Stacking ensemble with MARS\n",
    "Develop a MARS metamodel based on models *1-6* in [E.2.4](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble). Take `max_degree = 1`. In general, the optimal degree of a MARS metamodel will be 1. This is because the metamodel is based on very strong predictors, and thus increasing its complexity is likely to overfit. Of course, in rare cases the optimal degree may be greater than 1. Report the MAE of the metamodel on test data.\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad011c83",
   "metadata": {},
   "source": [
    "### Stacking ensemble with Random Forest\n",
    "Develop a Random forest metamodel based on models *1-6* in [E.2.4](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble). Tune the `max_samples` hyperparameter of the metamodel. Report the MAE of the metamodel on test data. \n",
    "\n",
    "*(6 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5407f7",
   "metadata": {},
   "source": [
    "### Stacking ensemble with XGBoost\n",
    "Develop a XGBoost metamodel based on models *1-6* in [E.2.4](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble). Tuning the metamodel is optional. Report the MAE of the metamodel on test data. \n",
    "\n",
    "*(5 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b28b9",
   "metadata": {},
   "source": [
    "### Ensemble of ensembles\n",
    "Develop a voting ensemble of the previous 5 stacking ensembles *(i.e., the stacking ensembles in E.2.6, E.2.7, E.2.8, E.2.9, and E.2.10)*. Report the MAE of the meta-metamodel on test data.\n",
    "\n",
    "This must be your best model with the least MAE, which must be less than $41,500. \n",
    "\n",
    "*(5 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ae154",
   "metadata": {},
   "source": [
    "## Classification - Term deposit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b9e803",
   "metadata": {},
   "source": [
    "The data for this question is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls, where bank clients were called to subscribe for a term deposit. \n",
    "\n",
    "There is a train data - *train.csv*, which you will use to develop a model. There is a test data - *test.csv*, which you will use to test your model. Each dataset has the following attributes about the clients called in the marketing campaign:\n",
    "\n",
    "1. `age`: Age of the client\n",
    "\n",
    "2. `education`: Education level of the client \n",
    "\n",
    "3. `day`: Day of the month the call is made\n",
    "\n",
    "4. `month`: Month of the call \n",
    "\n",
    "5. `y`: did the client subscribe to a term deposit? \n",
    "\n",
    "6. `duration`: Call duration, in seconds. This attribute highly affects the output target (e.g., if `duration`=0 then `y`='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call `y` is obviously known. Thus, this input should only be included for inference purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "(Raw data source: [Source](https://archive.ics.uci.edu/ml/datasets/bank+marketing). Do not use the raw data source for this assignment. It is just for reference.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2b007",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Convert all the categorical predictors in the data to dummy variables. Note that `month` and `education` are categorical variables.\n",
    "\n",
    "*(1 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bad75b",
   "metadata": {},
   "source": [
    "### Voting ensemble - hard voting\n",
    "Develop a voting ensemble *(hard voting)* based on the models in:\n",
    "\n",
    "1. Tuned Generalized additive model in [B.4](https://nustat.github.io/STAT303-3-class-notes/Assignment%20B.html#gam-for-classification)\n",
    "\n",
    "2. Tuned Random Forest model in [C.2.3](https://nustat.github.io/STAT303-3-class-notes/Assignment%20C.html#random-forest-1)\n",
    "\n",
    "3. Tuned boosting model in [D.3.2](https://nustat.github.io/STAT303-3-class-notes/Assignment%20D.html#boosting)\n",
    "\n",
    "Report the accuracy and recall on test data for each of the individual models *(1-3)*, and the hard voting ensemble.\n",
    "\n",
    "*(7 points - 3 points for reporting the accuracy and recall for the individual models, 2 points for taking the majority vote of predicted class, 2 points for reporting accuracy and recall on test data)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615a044",
   "metadata": {},
   "source": [
    "### Voting ensemble - soft voting\n",
    "Develop a soft voting ensemble based on models *1-3* in [E.3.2](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble---hard-voting). Tune the decision threshold probability of the soft-voting ensemble to achieve the highest possible accuracy for a minimum recall of 65%. Note that the test data much be untouched while tuning. Report the accuracy and recall of the soft-voting ensemble on test data.\n",
    "\n",
    "*Note:*\n",
    "\n",
    "*1. Use the cross-validated predicted probabilities of models 1-3 in [E.3.2](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble---hard-voting) to find the average cross-validated probability.*\n",
    "\n",
    "*2. Plot the cross-validated accuracy and recall against decision threshold probability. Tune the decision threshold probability based on the plot, or the data underlying the plot to achieve the required trade-off between recall and accuracy.*\n",
    "\n",
    "*(8 points - 3 points for computing the average probability, 3 points for tuning the decision threshold probability, 2 points for reporting the accuracy and recall on test data)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685bf78",
   "metadata": {},
   "source": [
    "### Stacking ensemble - Logistic regression\n",
    "\n",
    "Develop and tune a stacking ensemble based on models *1-3* in [E.3.2](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble---hard-voting) with logistic regression as the metamodel. Tune the hyperparameter `C` and the decision threshold probability to maximize accuracy for a recall of at least 65%.\n",
    "\n",
    "Report the accuracy and recall on test data for the ensemble.\n",
    "\n",
    "*(8 points - 3 points for tuning `C`, 3 points for tuning the decision threshold probability, 2 points for reporting accuracy and recall on test data)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb63186",
   "metadata": {},
   "source": [
    "### Stacking ensemble - Random forest\n",
    "\n",
    "Develop and tune a stacking ensemble based on them models *1-3* in [E.3.2](https://nustat.github.io/STAT303-3-class-notes/Assignment%20E.html#voting-ensemble---hard-voting) with random forest as the metamodel. Tune the hyperparameter `max_features` to maximize accuracy for a recall of at least 65%.\n",
    "\n",
    "Report the accuracy and recall on test data for the ensemble.\n",
    "\n",
    "*(8 points - 3 points for tuning `max_features`, 3 points for tuning the decision threshold probability, 2 points for reporting accuracy and recall on test data)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
