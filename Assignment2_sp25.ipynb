{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c7e736f1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Assignment 2\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9490a",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity. \n",
    "\n",
    "2. Write your code in the **Code cells** and your answers in the **Markdown cells** of the Jupyter notebook. Ensure that the solution is written neatly enough to for the graders to understand and follow.\n",
    "\n",
    "3. Use [Quarto](https://quarto.org/docs/output-formats/html-basics.html) to render the **.ipynb** file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: `quarto render filename.ipynb --to html`. Submit the HTML file.\n",
    "\n",
    "4. The assignment is worth 100 points, and is due on **Monday, 18th April 2025 at 11:59 pm**. \n",
    "\n",
    "5. **Five points are properly formatting the assignment**. The breakdown is as follows:\n",
    "    - Must be an HTML file rendered using Quarto **(1 point)**. *If you have a Quarto issue, you must mention the issue & quote the error you get when rendering using Quarto in the comments section of Canvas, and submit the ipynb file.* \n",
    "    - No name can be written on the assignment, nor can there be any indicator of the studentâ€™s identityâ€”e.g. printouts of the working directory should not be included in the final submission.  **(1 point)**\n",
    "    - There arenâ€™t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there arenâ€™t long printouts of which iteration a loop is on, there arenâ€™t long sections of commented-out code, etc.) **(1 point)**\n",
    "    - Final answers to each question are written in the Markdown cells. **(1 point)**\n",
    "    - There is no piece of unnecessary / redundant code, and no unnecessary / redundant text. **(1 point)**\n",
    "\n",
    "6.  The maximum possible score in the assigment is 103+5 = 108 out of 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5605f510",
   "metadata": {},
   "source": [
    "## 1) Optimizing KNN for Classification (71 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8239aaf",
   "metadata": {},
   "source": [
    "In this question, you will use **classification_data.csv**. Each row is a loan and the each column represents some financial information as follows:\n",
    "\n",
    "- `hi_int_prncp_pd`: Indicates if a high percentage of the repayments went to interest rather than principal. **This is the classification response.**\n",
    "\n",
    "- `out_prncp_inv`: Remaining outstanding principal for portion of total amount funded by investors\n",
    "\n",
    "- `loan_amnt`: The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.\n",
    "\n",
    "- `int_rate`: Interest Rate on the loan\n",
    "\n",
    "- `term`: The number of payments on the loan. Values are in months and can be either 36 or 60.\n",
    "\n",
    "As indicated above, `hi_int_prncp_pd` is the response and all the remaining columns are predictors. You will tune and train a K-Nearest Neighbors (KNN) classifier throughout this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f09d5",
   "metadata": {},
   "source": [
    "### a) Load the Dataset **(1 point)**\n",
    "\n",
    "Read the dataset into your notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d83cb",
   "metadata": {},
   "source": [
    "### b) Define Predictor and Response Variables **(1 point)**\n",
    "\n",
    "Create the **predictor** (features) and **response** (target) variables from the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974880e6",
   "metadata": {},
   "source": [
    "### c)  Split the Data into Training and Test Sets **(1 points)**\n",
    "\n",
    "Create the training and test datasets using the following specifications:\n",
    "\n",
    "- Use a **75%-25% split**.\n",
    "- Ensure that the **class ratio is preserved** in both training and test sets (i.e., stratify the split).\n",
    "- Set `random_state=45` for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c08695",
   "metadata": {},
   "source": [
    "### d) Check Class Ratios **(2 points)**\n",
    "\n",
    "Print the **class distribution** (ratios) for:\n",
    "\n",
    "- The entire dataset  \n",
    "- The training set  \n",
    "- The test set  \n",
    "\n",
    "This is to verify that the **class ratio is preserved** after splitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f010475",
   "metadata": {},
   "source": [
    "### e) Scale the Dataset **(2 points)**\n",
    "\n",
    "Use `StandardScaler` to scale the dataset in order to prepare it for KNN modeling. \n",
    "\n",
    "Scaling ensures that all features contribute equally to the distance calculations used by the KNN algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891635a0",
   "metadata": {},
   "source": [
    "### f) Set Up Cross-Validation **(2 points)**\n",
    "\n",
    "Before creating and tuning your model, you need to define cross-validation settings to ensure consistent and accurate evaluation across folds.\n",
    "\n",
    "Please follow these specifications:\n",
    "\n",
    "- Use **5 stratified folds** to preserve class distributions in each split.\n",
    "- **Shuffle** the data before splitting to introduce randomness.\n",
    "- Set `random_state=14` for reproducibility.\n",
    "\n",
    "**Note:** You must use these exact cross-validation settings throughout the rest of this question to maintain consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0c398",
   "metadata": {},
   "source": [
    "### g) Tune K for KNN Using Cross-Validation **(12 points)**\n",
    "\n",
    "Tune a **KNN Classifier** using cross-validation with the following specifications:\n",
    "\n",
    "- Use **every odd K value from 1 to 50** (inclusive).\n",
    "- Keep all other model settings at their defaults.\n",
    "- Use the **cross-validation settings** defined in part (f).\n",
    "- Evaluate performance using the **F1 score** as the metric.\n",
    "\n",
    "**(4 points)**\n",
    "\n",
    "Then, complete the following tasks:\n",
    "\n",
    "- Create a **plot of K values vs. cross-validation F1 scores** to visualize how K balances overfitting and underfitting. **(2 points)**\n",
    "- Print the **best average cross-validation F1 score**. **(1 points)**\n",
    "- Report the **K value corresponding to the best F1 score**. **(1 points)**\n",
    "- Determine whether this is the **only K value** that results in the best F1 score. Use code to justify your answer. **(2 points)**\n",
    "- Reflect on whether **accuracy** is a good metric for tuning the model in this case. Explain your reasoning. **(2 points)**\n",
    "\n",
    "**ðŸ’¡ Hint:**  \n",
    "\n",
    "In addition to reporting the best `K` and best F1 score, you may also want to examine the full cross-validation results to check if other K values achieved the same F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57138757",
   "metadata": {},
   "source": [
    "### h) Optimize the Classification Threshold **(4 points)**\n",
    "\n",
    "Using the **optimal K value** you identified in part (g), optimize the classification **threshold** to maximize the cross-validation F1 score.\n",
    "\n",
    "#### Specifications:\n",
    "- Search across all possible threshold values using a **step size of 0.05**.\n",
    "- Use the **cross-validation settings** defined in part (f).\n",
    "- Evaluate performance using the **F1 score**, consistent with part (g).\n",
    "\n",
    "#### Tasks:\n",
    "- Visualize the **F1 score vs. different threshold values**. **(2 points)**\n",
    "- Identify and report the **best threshold** that yields the highest F1 score. **(1 points)**\n",
    "- Output the **best cross-validation F1 score**. **(1 points)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750e84a",
   "metadata": {},
   "source": [
    "### i) Evaluate the Tuning Method **(2 points)**\n",
    "\n",
    "Is the method we used in parts (g) and (h) **guaranteed** to find the best combination of **K** and **threshold**, i.e., to tune the classifier to its optimal values?  \n",
    "**(1 point)**\n",
    "\n",
    "Justify your answer.  \n",
    "**(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b129db",
   "metadata": {},
   "source": [
    "### j)  Evaluate Tuned Classifier on Test Set **(3 points)**\n",
    "\n",
    "Using the **tuned KNN classifier** and the **optimal threshold** you identified, evaluate the model on the **test set**. Report the following metrics:\n",
    "\n",
    "- F1 Score  \n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- AUC  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20462f7",
   "metadata": {},
   "source": [
    "### k) Jointly Tune K and Threshold **(6 points)**\n",
    "\n",
    "Now, tune **K** and the **classification threshold simultaneously**, rather than sequentially.\n",
    "\n",
    "- Use the same settings from the previous parts (i.e., odd K values from 1 to 50, threshold step size of 0.05, F1 score as the metric, and the same cross-validation strategy).\n",
    "- Identify the **best F1 score**, along with the **K value and threshold** that produce it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d787bf05",
   "metadata": {},
   "source": [
    "### l)  Visualize Cross-Validation Results with a Heatmap **(3 points)**\n",
    "\n",
    "Create a **heatmap** to visualize the cross-validation results in two dimensions.\n",
    "\n",
    "- The **x-axis** should represent the **K values**.\n",
    "- The **y-axis** should represent the **threshold values**.\n",
    "- The color should represent the **F1 score**.\n",
    "\n",
    "**Note:** This question only requires **one line of code**. Youâ€™ll need to recall a **data visualization function** and a **data reshaping method** from 303-1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994b0f3",
   "metadata": {},
   "source": [
    "### m)  Compare Joint vs. Sequential Tuning Results **(4 points)**\n",
    "\n",
    "- How does the **best cross-validation F1 score** from part (k) compare to the scores from parts (g) and (h)? **(1 point)**\n",
    "- Did the **optimal K value** and **threshold** change when tuning them jointly? **(1 point)**\n",
    "- Explain **why or why not**. Consider how tuning the two parameters together might impact the result. **(2 points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddaab37",
   "metadata": {},
   "source": [
    "### n) Evaluate Final Tuned Model on Test Set **(3 points)**\n",
    "\n",
    "Using the **tuned classifier and threshold** from part (k), evaluate the model on the **test set**. Report the following metrics:\n",
    "\n",
    "- F1 Score  \n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- AUC  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad805352",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### o) Compare Tuning Strategies and Computational Cost **(3 points)**\n",
    "\n",
    "Compare the tuning approach used in parts **(g) & (h)** (separate tuning of K and threshold) with the approach in **part (k)** (joint tuning of K and threshold) in terms of **computational cost**.\n",
    "\n",
    "- How many **K and threshold combinations** did you evaluate in each approach? **(2 points)**\n",
    "- Based on this comparison and your answer from part (l), explain the **main trade-off** involved in model tuning (e.g., between computation and performance). **(2 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d331e",
   "metadata": {},
   "source": [
    "### p) Tune K Using Multiple Metrics **(5 points)**\n",
    "\n",
    "`GridSearchCV` or `cross_val_score` only allows tuning based on a **single metric**. In this part, youâ€™ll practice tuning hyperparameters while evaluating **multiple metrics** simultaneously.\n",
    "\n",
    "Cross-validate a **KNN classifier** using the following specifications:\n",
    "\n",
    "- Use **every odd K value from 1 to 50** (inclusive), and keep all other hyperparameters at their default settings.\n",
    "- Apply the **cross-validation settings** from part (f).\n",
    "- Evaluate the model using **accuracy**, **precision**, and **recall** as metrics **at the same time**.\n",
    "\n",
    "Save the cross-validation results into a **DataFrame**, and compute the **average score for each metric**, and visualize how these metrics change with different values of K.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee32f6c",
   "metadata": {},
   "source": [
    "### q) Optimize for Precision with Recall Constraint **(4 point)**\n",
    "\n",
    "Identify the **K value** that yields the **highest precision**, while maintaining a **recall of at least 75%**.  \n",
    "**(3 points)**\n",
    "\n",
    "Then, print the **average cross-validation metrics** (accuracy, precision, recall) for that K value.  \n",
    "**(1 point)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ab15eb",
   "metadata": {},
   "source": [
    "### r) Tune Threshold for Maximum Precision **(3 point)**\n",
    "\n",
    "Using the **optimal K value** identified in part (q), find the **threshold** that maximizes **cross-validation precision**, following the specifications below:\n",
    "\n",
    "- Evaluate all possible threshold values with a **step size of 0.05**.\n",
    "- Use the **cross-validation settings** from part (f).\n",
    "\n",
    "Then:\n",
    "- Print the **best cross-validation precision**. \n",
    "- Report the **threshold value** that achieves this precision. \n",
    "\n",
    "**Note:** This task is very similar to part (h), but itâ€™s important for the next part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803faff5",
   "metadata": {},
   "source": [
    "### s) Evaluate Precision-Optimized Model on Test Set **(2 points)**\n",
    "\n",
    "Using the **tuned classifier and threshold** from parts (q) and (r), evaluate the model on the **test set**. Report the following metrics:\n",
    "\n",
    "- Test Accuracy  \n",
    "- Test Precision  \n",
    "- Test Recall  \n",
    "- Test AUC  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad58f5",
   "metadata": {},
   "source": [
    "### t) Final Reflection: Comparing Tuning Strategies  **(3 points)**\n",
    "\n",
    "You have now tuned your KNN classifier using **three different strategies**:\n",
    "\n",
    "1. **Sequential tuning** of K and threshold based on **F1 score** (parts gâ€“h)\n",
    "2. **Joint tuning** of K and threshold using **F1 score** (part k)\n",
    "3. Tuning based on **multiple metrics**, selecting the K with the **highest precision** while maintaining **recall â‰¥ 75%** (parts pâ€“r)\n",
    "\n",
    "Reflect on the following:\n",
    "\n",
    "- Which tuning strategy led to the **best overall performance on the test set**, based on the metrics you care about most?\n",
    "- Which strategy would you choose in a real-world application, and why?\n",
    "- What are the **trade-offs** between tuning for F1 score versus prioritizing precision or recall individually?\n",
    "\n",
    "\n",
    "\n",
    "**Note:** This is an open-ended question. As long as your reasoning makes sense, you will receive full credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82924b9-f181-43a7-8243-d3202f1a1b3e",
   "metadata": {},
   "source": [
    "## 2) Tuning a KNN Regressor on Bank Loan Data (32 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd00165-069a-4454-a508-372ff4496972",
   "metadata": {},
   "source": [
    "In this question, you will use **bank_loan_train_data.csv** to tune *(the model hyperparameters)* and train the model. Each row is a loan and the each column represents some financial information as follows:\n",
    "\n",
    "- `money_made_inv`: Indicates the amount of money made by the bank on the loan. **This is the regression response.**\n",
    "\n",
    "- `out_prncp_inv`: Remaining outstanding principal for portion of total amount funded by investors\n",
    "\n",
    "- `loan_amnt`: The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.\n",
    "\n",
    "- `int_rate`: Interest Rate on the loan\n",
    "\n",
    "- `term`: The number of payments on the loan. Values are in months and can be either 36 or 60\n",
    "\n",
    "- `mort_acc`: The number of mortgage accounts\n",
    "\n",
    "- `application_type_Individual`: 1 if the loan is an individual application or a joint application with two co-borrowers\n",
    "\n",
    "- `tot_cur_bal`: Total current balance of all accounts\n",
    "\n",
    "- `pub_rec`: Number of derogatory public records\n",
    "\n",
    "As indicated above, `money_made_inv` is the response and all the remaining columns are predictors. You will tune and train a K-Nearest Neighbors (KNN) regressor throughout this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706273ce",
   "metadata": {},
   "source": [
    "###  a) Split, Scale, and Tune a KNN Regressor **(15 point)**\n",
    "\n",
    "Create the **training and test datasets** using the following specifications:\n",
    "\n",
    "- Use an **80%-20% split**.\n",
    "- Set `random_state=1` for reproducibility.\n",
    "\n",
    "Then, **scale your data**, as KNN is sensitive to the scale of input features.\n",
    "\n",
    "Next, you will **tune a KNN Regressor** by searching for the optimal hyperparameters using three search approaches: **Grid Search**, **Random Search**, and **Bayesian Search**.\n",
    "\n",
    "#### Cross-Validation Setting\n",
    "\n",
    "You should use **5-fold cross-validation**, with the following specifications:\n",
    "\n",
    "- The data should be **shuffled** before splitting  \n",
    "- Use `random_state=1` to ensure **reproducibility**\n",
    "\n",
    "####  Hyperparameters to Tune:\n",
    "\n",
    "You will tune the following hyperparameters for the KNN Regressor:\n",
    "\n",
    "1. `n_neighbors`: Number of nearest neighbors \n",
    "2. `p`: Power parameter for the Minkowski distance  \n",
    "3. `weights`: Weight function used in prediction  \n",
    " \n",
    "You must consider the following **5 types of weights**:\n",
    "\n",
    "- `'uniform'`: All neighbors are weighted equally  \n",
    "- `'distance'`: Weight is inversely proportional to distance  \n",
    "- Custom weight functions:\n",
    "  - $\\propto \\frac{1}{\\text{distance}^2}$\n",
    "  - $\\propto \\frac{1}{\\text{distance}^3}$\n",
    "  - $\\propto \\frac{1}{\\text{distance}^4}$\n",
    "\n",
    "For **each search method** (Grid Search, Random Search, Bayesian Search), report the following:\n",
    "\n",
    "- `best_params_`: The best combination of hyperparameters  \n",
    "- `best_score_`: Cross-validated RMSE on the training set  \n",
    "- **Test RMSE** obtained from the best model  \n",
    "- **Execution time** for the search process \n",
    "\n",
    "**Hint:**\n",
    "\n",
    "Define **three custom weight functions** as shown below:\n",
    "\n",
    "```\n",
    "def dist_power_2(distance):\n",
    "    return 1 / (1e-10 + distance**2)\n",
    "\n",
    "def dist_power_3(distance):\n",
    "    return 1 / (1e-10 + distance**3)\n",
    "\n",
    "def dist_power_4(distance):\n",
    "    return 1 / (1e-10 + distance**4)\n",
    "```\n",
    "\n",
    "Note the small constant `1e-10` helps avoid division by zero and numerical instability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e4c45",
   "metadata": {},
   "source": [
    "### b) Compare Tuning Approaches **(1 point)**\n",
    "\n",
    "Compare the results from part (2a) in terms of **execution time** and **model performance**.  \n",
    "Briefly discuss the **main trade-offs** among the three hyperparameter tuning approaches: Grid Search, Random Search, and Bayesian Search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975d622-1ea0-4170-a3ba-8a2592013f07",
   "metadata": {},
   "source": [
    "### c) Feature Selection and Hyperparameter Tuning with GridSearchCV **(15 point)**\n",
    "\n",
    "KNN performance can **deteriorate significantly** if irrelevant or noisy predictors are included. In this part, you will explore **feature selection** to improve model performance, followed by **hyperparameter tuning** using `GridSearchCV` (with `refit=True`).\n",
    "\n",
    "Try the following **four different feature selection approaches**:\n",
    "\n",
    "1. **Correlation-based filtering**:  \n",
    "   - Select features with an absolute correlation of at least **0.1** with the target variable.\n",
    "\n",
    "2. **Lasso regression for feature selection**:  \n",
    "   - Use `Lasso(alpha=50)` to select important features based on non-zero coefficients.\n",
    "\n",
    "3. **SelectKBest**:  \n",
    "   - Use `SelectKBest` with `f_regression`, selecting the **top 4** features.\n",
    "\n",
    "4. **Variance threshold**:  \n",
    "   - Use `VarianceThreshold(threshold=0.1)` to select features with sufficient variability.\n",
    "\n",
    "\n",
    "For **each approach**, perform hyperparameter tuning using **GridSearchCV**, and report:\n",
    "\n",
    "- The **best score** (cross-validated RMSE) on the **training set**\n",
    "- The **test RMSE** from the best model\n",
    "- The **best hyperparameters**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0a31c-23df-474e-984d-dbb842b864c8",
   "metadata": {},
   "source": [
    "### d) Compare Feature Selection Approaches **(1 point)**\n",
    "\n",
    "Create a **DataFrame** that summarizes the model performance from each feature selection method, including:\n",
    "\n",
    "- **Training RMSE**\n",
    "- **Test RMSE**\n",
    "\n",
    "Be sure to also include the results from the model trained **without any feature selection** for comparison.\n",
    "\n",
    "Then, briefly explain what you learned from this experiment.  \n",
    "For example: Did feature selection improve performance? Which method worked best?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5698f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
