<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>10&nbsp; XGBoost – Data Science III with python (Class notes)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./LightGBM_CatBoost.html" rel="next">
<link href="./Gradient_Boosting.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-8da5b4427184b79ecddefad3d342027e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./regression_tree_sp25.html">Tree based models</a></li><li class="breadcrumb-item"><a href="./XGBoost.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">XGBoost</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="https://statistics.northwestern.edu/" class="sidebar-logo-link">
      <img src="./NU_Stat_logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science III with python (Class notes)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Bias &amp; Variance; KNN</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Bias_variance_code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Bias-variance tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./KNN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">KNN</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Hyperparameter tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Hyperparameter tuning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Tree based models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression_tree_sp25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Classification _Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Classification trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bagging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Bagging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./random_forest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Random Forests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./adaboost.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Adaptive Boosting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Gradient_Boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gradient Boosting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./XGBoost.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">XGBoost</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LightGBM_CatBoost.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">LightGBM and CatBoost</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec10_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Ensemble modeling</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment1_sp25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Assignment 1</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment2_sp25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Assignment 2</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment3_sp25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Assignment 3</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment4_sp25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Assignment 4</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Datasets, assignment and project files</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-is-xgboost" id="toc-what-is-xgboost" class="nav-link active" data-scroll-target="#what-is-xgboost"><span class="header-section-number">10.1</span> What is XGBoost?</a></li>
  <li><a href="#xgboost-intuition" id="toc-xgboost-intuition" class="nav-link" data-scroll-target="#xgboost-intuition"><span class="header-section-number">10.2</span> XGBoost Intuition</a></li>
  <li><a href="#how-xgboost-works-regression-example" id="toc-how-xgboost-works-regression-example" class="nav-link" data-scroll-target="#how-xgboost-works-regression-example"><span class="header-section-number">10.3</span> How XGBoost Works (Regression Example)</a></li>
  <li><a href="#using-xgboost" id="toc-using-xgboost" class="nav-link" data-scroll-target="#using-xgboost"><span class="header-section-number">10.4</span> Using XGBoost</a></li>
  <li><a href="#core-hyperparameter-categories" id="toc-core-hyperparameter-categories" class="nav-link" data-scroll-target="#core-hyperparameter-categories"><span class="header-section-number">10.5</span> Core Hyperparameter Categories</a>
  <ul>
  <li><a href="#model-complexity" id="toc-model-complexity" class="nav-link" data-scroll-target="#model-complexity"><span class="header-section-number">10.5.1</span> Model Complexity</a></li>
  <li><a href="#learning-and-regularization" id="toc-learning-and-regularization" class="nav-link" data-scroll-target="#learning-and-regularization"><span class="header-section-number">10.5.2</span> Learning and Regularization</a></li>
  <li><a href="#regularization" id="toc-regularization" class="nav-link" data-scroll-target="#regularization"><span class="header-section-number">10.5.3</span> Regularization</a></li>
  <li><a href="#optimization-control" id="toc-optimization-control" class="nav-link" data-scroll-target="#optimization-control"><span class="header-section-number">10.5.4</span> Optimization Control</a></li>
  <li><a href="#baseline-model" id="toc-baseline-model" class="nav-link" data-scroll-target="#baseline-model"><span class="header-section-number">10.5.5</span> Baseline Model</a></li>
  <li><a href="#early-stopping-in-xgboost" id="toc-early-stopping-in-xgboost" class="nav-link" data-scroll-target="#early-stopping-in-xgboost"><span class="header-section-number">10.5.6</span> Early Stopping in XGBoost</a>
  <ul class="collapse">
  <li><a href="#how-it-works" id="toc-how-it-works" class="nav-link" data-scroll-target="#how-it-works"><span class="header-section-number">10.5.6.1</span> How It Works</a></li>
  <li><a href="#requirements" id="toc-requirements" class="nav-link" data-scroll-target="#requirements"><span class="header-section-number">10.5.6.2</span> Requirements</a></li>
  </ul></li>
  <li><a href="#gamma-in-xgboost" id="toc-gamma-in-xgboost" class="nav-link" data-scroll-target="#gamma-in-xgboost"><span class="header-section-number">10.5.7</span> <code>gamma</code> in XGBoost</a></li>
  <li><a href="#reg_lambda-and-reg_alpha-in-xgboost" id="toc-reg_lambda-and-reg_alpha-in-xgboost" class="nav-link" data-scroll-target="#reg_lambda-and-reg_alpha-in-xgboost"><span class="header-section-number">10.5.8</span> <code>reg_lambda</code> and <code>reg_alpha</code> in XGBoost</a></li>
  <li><a href="#exploring-regularization-hyperparameters-simultaneously" id="toc-exploring-regularization-hyperparameters-simultaneously" class="nav-link" data-scroll-target="#exploring-regularization-hyperparameters-simultaneously"><span class="header-section-number">10.5.9</span> Exploring Regularization Hyperparameters Simultaneously</a></li>
  <li><a href="#comprehensive-hyperparameter-tuning" id="toc-comprehensive-hyperparameter-tuning" class="nav-link" data-scroll-target="#comprehensive-hyperparameter-tuning"><span class="header-section-number">10.5.10</span> Comprehensive Hyperparameter Tuning</a>
  <ul class="collapse">
  <li><a href="#why-gridsearchcv-is-not-a-practical-option" id="toc-why-gridsearchcv-is-not-a-practical-option" class="nav-link" data-scroll-target="#why-gridsearchcv-is-not-a-practical-option"><span class="header-section-number">10.5.10.1</span> Why <code>GridSearchCV</code> Is Not a Practical Option</a></li>
  <li><a href="#smarter-tuning-with-optuna-or-bayessearchcv" id="toc-smarter-tuning-with-optuna-or-bayessearchcv" class="nav-link" data-scroll-target="#smarter-tuning-with-optuna-or-bayessearchcv"><span class="header-section-number">10.5.10.2</span> Smarter Tuning with Optuna or BayesSearchCV</a></li>
  <li><a href="#after-training-analyze-and-refine" id="toc-after-training-analyze-and-refine" class="nav-link" data-scroll-target="#after-training-analyze-and-refine"><span class="header-section-number">10.5.10.3</span> After Training: Analyze and Refine</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#xgboost-for-imbalanced-classification" id="toc-xgboost-for-imbalanced-classification" class="nav-link" data-scroll-target="#xgboost-for-imbalanced-classification"><span class="header-section-number">10.6</span> XGBoost for Imbalanced Classification</a>
  <ul>
  <li><a href="#common-strategies-across-libraries" id="toc-common-strategies-across-libraries" class="nav-link" data-scroll-target="#common-strategies-across-libraries"><span class="header-section-number">10.6.1</span> Common Strategies Across Libraries</a></li>
  <li><a href="#handling-class-imbalance-with-scale_pos_weight-in-xgboost" id="toc-handling-class-imbalance-with-scale_pos_weight-in-xgboost" class="nav-link" data-scroll-target="#handling-class-imbalance-with-scale_pos_weight-in-xgboost"><span class="header-section-number">10.6.2</span> Handling Class Imbalance with <code>scale_pos_weight</code> in XGBoost</a>
  <ul class="collapse">
  <li><a href="#what-does-scale_pos_weight-do" id="toc-what-does-scale_pos_weight-do" class="nav-link" data-scroll-target="#what-does-scale_pos_weight-do"><span class="header-section-number">10.6.2.1</span> What Does <code>scale_pos_weight</code> Do?</a></li>
  <li><a href="#when-to-use-it" id="toc-when-to-use-it" class="nav-link" data-scroll-target="#when-to-use-it"><span class="header-section-number">10.6.2.2</span> When to Use It</a></li>
  </ul></li>
  <li><a href="#how-to-set-it" id="toc-how-to-set-it" class="nav-link" data-scroll-target="#how-to-set-it"><span class="header-section-number">10.6.3</span> How to Set It</a></li>
  <li><a href="#using-scale_pos_weight" id="toc-using-scale_pos_weight" class="nav-link" data-scroll-target="#using-scale_pos_weight"><span class="header-section-number">10.6.4</span> Using <code>scale_pos_weight</code></a></li>
  <li><a href="#threshold-adjustment" id="toc-threshold-adjustment" class="nav-link" data-scroll-target="#threshold-adjustment"><span class="header-section-number">10.6.5</span> Threshold adjustment</a></li>
  <li><a href="#alternative-method-custom-instance-weights-sample_weight" id="toc-alternative-method-custom-instance-weights-sample_weight" class="nav-link" data-scroll-target="#alternative-method-custom-instance-weights-sample_weight"><span class="header-section-number">10.6.6</span> Alternative Method: Custom Instance Weights (<code>sample_weight</code>)</a></li>
  <li><a href="#scale_pos_weight-vs.-sample_weight" id="toc-scale_pos_weight-vs.-sample_weight" class="nav-link" data-scroll-target="#scale_pos_weight-vs.-sample_weight"><span class="header-section-number">10.6.7</span> <code>scale_pos_weight</code> vs.&nbsp;<code>sample_weight</code></a></li>
  </ul></li>
  <li><a href="#resources-for-learning-xgboost" id="toc-resources-for-learning-xgboost" class="nav-link" data-scroll-target="#resources-for-learning-xgboost"><span class="header-section-number">10.7</span> Resources for Learning XGBoost</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./regression_tree_sp25.html">Tree based models</a></li><li class="breadcrumb-item"><a href="./XGBoost.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">XGBoost</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">XGBoost</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="what-is-xgboost" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="what-is-xgboost"><span class="header-section-number">10.1</span> What is XGBoost?</h2>
<p><strong>XGBoost</strong> (Extreme Gradient Boosting) is a scalable and efficient implementation of gradient boosting developed by Tianqi Chen and Carlos Guestrin in 2016. It has become one of the most popular machine learning algorithms for structured/tabular data, widely used in Kaggle competitions and production environments.</p>
<p>Compared to vanilla Gradient Boosting, XGBoost includes additional system-level and algorithmic optimizations such as:</p>
<ul>
<li>Regularization (to reduce overfitting)</li>
<li>Tree pruning</li>
<li>Parallelized tree construction</li>
<li>Missing value handling</li>
<li>Out-of-core computation for large datasets</li>
</ul>
</section>
<section id="xgboost-intuition" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="xgboost-intuition"><span class="header-section-number">10.2</span> XGBoost Intuition</h2>
<p>XGBoost extends vanilla gradient boosting with:</p>
<ul>
<li><strong>Regularization</strong>: Penalizes complex models via L1/L2 terms in the loss function.</li>
<li><strong>Second-order optimization</strong>: Uses both gradients and hessians for faster convergence and more accurate splits.</li>
<li><strong>Split constraints</strong>: Prevents splits with insufficient gain (via <code>gamma</code>) during tree growth, avoiding the need for post-pruning.</li>
</ul>
</section>
<section id="how-xgboost-works-regression-example" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="how-xgboost-works-regression-example"><span class="header-section-number">10.3</span> How XGBoost Works (Regression Example)</h2>
<p>XGBoost minimizes the following <strong>regularized objective</strong> at each boosting round <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[
\mathcal{L}^{(t)} = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)) + \Omega(f_t)
\]</span></p>
<p>Where: - <span class="math inline">\(l\)</span> is a differentiable convex loss function (e.g., squared error) - <span class="math inline">\(f_t\)</span> is the prediction function at iteration <span class="math inline">\(t\)</span> (a tree) - <span class="math inline">\(\Omega(f_t) = \gamma T + \frac{1}{2} \lambda \sum w_j^2\)</span> is the regularization term (penalizes the number of leaves <span class="math inline">\(T\)</span> and leaf weights <span class="math inline">\(w_j\)</span>)</p>
<p>To simplify optimization, XGBoost applies a <strong>second-order Taylor approximation</strong> of the loss function:</p>
<p><span class="math display">\[
\mathcal{L}^{(t)} \approx \sum_{i=1}^n \left[ g_i f_t(x_i) + \frac{1}{2} h_i f_t(x_i)^2 \right] + \Omega(f_t)
\]</span></p>
<p>Where: - <span class="math inline">\(g_i = \frac{\partial l(y_i, \hat{y}_i)}{\partial \hat{y}_i}\)</span> is the first-order derivative (gradient) - <span class="math inline">\(h_i = \frac{\partial^2 l(y_i, \hat{y}_i)}{\partial \hat{y}_i^2}\)</span> is the second-order derivative (hessian)</p>
<p>XGBoost then chooses the <strong>tree structure and leaf values</strong> that minimize this approximate objective.</p>
</section>
<section id="using-xgboost" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="using-xgboost"><span class="header-section-number">10.4</span> Using XGBoost</h2>
<p>Although <strong>XGBoost is not part of Scikit-learn</strong>, it provides a <strong>Scikit-learn-compatible API</strong> through the <code>xgboost.sklearn</code> module. This allows you to use XGBoost models seamlessly with Scikit-learn tools such as <code>Pipeline</code>, <code>GridSearchCV</code>, and <code>cross_val_score</code>.</p>
<p>The main classes are:</p>
<ul>
<li><a href="https://xgboost.readthedocs.io/en/stable/python/python_api/xgboost.XGBRegressor.html"><code>XGBRegressor</code></a>: for regression tasks<br>
</li>
<li><a href="https://xgboost.readthedocs.io/en/stable/python/python_api/xgboost.XGBClassifier.html"><code>XGBClassifier</code></a>: for classification tasks</li>
</ul>
<p>To install the package:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install xgboost</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p><strong>Note:</strong> XGBoost is a separate library, not part of Scikit-learn, but it provides a <strong>Scikit-learn-compatible API</strong> via <code>XGBClassifier</code> and <code>XGBRegressor</code>.<br>
This makes it easy to integrate XGBoost models into Scikit-learn workflows such as <code>Pipeline</code>, <code>GridSearchCV</code>, and <code>cross_val_score</code>.</p>
</blockquote>
</section>
<section id="core-hyperparameter-categories" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="core-hyperparameter-categories"><span class="header-section-number">10.5</span> Core Hyperparameter Categories</h2>
<section id="model-complexity" class="level3" data-number="10.5.1">
<h3 data-number="10.5.1" class="anchored" data-anchor-id="model-complexity"><span class="header-section-number">10.5.1</span> Model Complexity</h3>
<ul>
<li><code>n_estimators</code>: Number of boosting rounds<br>
</li>
<li><code>max_depth</code>: Maximum depth of a tree<br>
</li>
<li><code>min_child_weight</code>: Minimum sum of instance weight needed in a child</li>
</ul>
</section>
<section id="learning-and-regularization" class="level3" data-number="10.5.2">
<h3 data-number="10.5.2" class="anchored" data-anchor-id="learning-and-regularization"><span class="header-section-number">10.5.2</span> Learning and Regularization</h3>
<ul>
<li><code>learning_rate</code> (<code>eta</code>): Shrinkage rate to scale each tree’s contribution<br>
</li>
<li><code>subsample</code>: Fraction of rows used per boosting round<br>
</li>
<li><code>colsample_bytree</code>: Fraction of features used per tree<br>
</li>
<li><code>colsample_bylevel</code>, <code>colsample_bynode</code>: Further control over feature subsampling</li>
</ul>
</section>
<section id="regularization" class="level3" data-number="10.5.3">
<h3 data-number="10.5.3" class="anchored" data-anchor-id="regularization"><span class="header-section-number">10.5.3</span> Regularization</h3>
<ul>
<li><code>gamma</code>: Minimum loss reduction required to make a further partition<br>
</li>
<li><code>reg_alpha</code>: L1 regularization term on weights (Lasso)<br>
</li>
<li><code>reg_lambda</code>: L2 regularization term on weights (Ridge)</li>
</ul>
</section>
<section id="optimization-control" class="level3" data-number="10.5.4">
<h3 data-number="10.5.4" class="anchored" data-anchor-id="optimization-control"><span class="header-section-number">10.5.4</span> Optimization Control</h3>
<ul>
<li><code>objective</code>: Loss function (e.g., <code>'reg:squarederror'</code>, <code>'binary:logistic'</code>)<br>
</li>
<li><code>tree_method</code>: Tree construction algorithm (<code>'auto'</code>, <code>'hist'</code>, <code>'gpu_hist'</code>)<br>
</li>
<li><code>early_stopping_rounds</code>: Stop if validation score doesn’t improve after N rounds</li>
</ul>
<p>However, there are other hyperparameters that can be tuned as well. Check out the list of all hyperparameters in the XGBoost <a href="https://xgboost.readthedocs.io/en/stable/python/python_api.html#">documentation</a>.</p>
<div id="f819f995" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder, StandardScaler</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> root_mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBRegressor, XGBClassifier</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt <span class="im">import</span> BayesSearchCV</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt.space <span class="im">import</span> Real, Categorical, Integer</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt.plots <span class="im">import</span> plot_objective, plot_histogram, plot_convergence</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython <span class="im">import</span> display</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a9036ef3" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>car <span class="op">=</span> pd.read_csv(<span class="st">'Datasets/car.csv'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>car.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">brand</th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">transmission</th>
<th data-quarto-table-cell-role="th">mileage</th>
<th data-quarto-table-cell-role="th">fuelType</th>
<th data-quarto-table-cell-role="th">tax</th>
<th data-quarto-table-cell-role="th">mpg</th>
<th data-quarto-table-cell-role="th">engineSize</th>
<th data-quarto-table-cell-role="th">price</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>vw</td>
<td>Beetle</td>
<td>2014</td>
<td>Manual</td>
<td>55457</td>
<td>Diesel</td>
<td>30</td>
<td>65.3266</td>
<td>1.6</td>
<td>7490</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>vauxhall</td>
<td>GTC</td>
<td>2017</td>
<td>Manual</td>
<td>15630</td>
<td>Petrol</td>
<td>145</td>
<td>47.2049</td>
<td>1.4</td>
<td>10998</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>merc</td>
<td>G Class</td>
<td>2012</td>
<td>Automatic</td>
<td>43000</td>
<td>Diesel</td>
<td>570</td>
<td>25.1172</td>
<td>3.0</td>
<td>44990</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>audi</td>
<td>RS5</td>
<td>2019</td>
<td>Automatic</td>
<td>10</td>
<td>Petrol</td>
<td>145</td>
<td>30.5593</td>
<td>2.9</td>
<td>51990</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>merc</td>
<td>X-CLASS</td>
<td>2018</td>
<td>Automatic</td>
<td>14000</td>
<td>Diesel</td>
<td>240</td>
<td>35.7168</td>
<td>2.3</td>
<td>28990</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="db6b5f99" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> car.drop(columns<span class="op">=</span>[<span class="st">'price'</span>])</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> car[<span class="st">'price'</span>]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify categorical and numerical columns</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> X.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>]).columns.tolist()</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>numerical_cols <span class="op">=</span> X.select_dtypes(exclude<span class="op">=</span>[<span class="st">'object'</span>]).columns.tolist()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s define some helper functions before building any models.</p>
<div id="342fefd3" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create preprocessing for numerical and categorical features</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> ColumnTransformer(</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    transformers<span class="op">=</span>[</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'num'</span>, <span class="st">'passthrough'</span>, numerical_cols),</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'cat'</span>, OneHotEncoder(handle_unknown<span class="op">=</span><span class="st">'ignore'</span>), categorical_cols)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to evaluate model</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model, X_test, y_test):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    rmse <span class="op">=</span> root_mean_squared_error(y_test, y_pred)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Root Mean Squared Error: </span><span class="sc">{</span>rmse<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"R² Score: </span><span class="sc">{</span>r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rmse,  r2</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to plot feature importance</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_feature_importance(model, preprocessor, X):</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(model, <span class="st">'feature_importances_'</span>):</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get feature names after one-hot encoding</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        cat_features <span class="op">=</span> preprocessor.named_transformers_[<span class="st">'cat'</span>].get_feature_names_out(categorical_cols)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        all_features <span class="op">=</span> np.append(numerical_cols, cat_features)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get feature importances</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        importances <span class="op">=</span> model.feature_importances_</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sort feature importances in descending order</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> np.argsort(importances)[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a DataFrame for easier visualization</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        importance_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Feature'</span>: all_features[indices][:<span class="dv">20</span>],  <span class="co"># Top 20 features</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Importance'</span>: importances[indices][:<span class="dv">20</span>]</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        importance_df <span class="op">=</span> importance_df.sort_values(by<span class="op">=</span><span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> importance_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="baseline-model" class="level3" data-number="10.5.5">
<h3 data-number="10.5.5" class="anchored" data-anchor-id="baseline-model"><span class="header-section-number">10.5.5</span> Baseline Model</h3>
<div id="fb031a85" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== 1. Baseline Model =====</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">===== Baseline XGBoost Model ====="</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>baseline_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor),</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'regressor'</span>, XGBRegressor(random_state<span class="op">=</span><span class="dv">42</span>))</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>baseline_pipeline.fit(X_train, y_train)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Baseline Model Evaluation:"</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>baseline_metrics <span class="op">=</span> evaluate_model(baseline_pipeline, X_test, y_test)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot feature importance for baseline model</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>baseline_importance <span class="op">=</span> plot_feature_importance(baseline_pipeline.named_steps[<span class="st">'regressor'</span>], </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>                                             baseline_pipeline.named_steps[<span class="st">'preprocessor'</span>], </span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>                                             X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
===== Baseline XGBoost Model =====

Baseline Model Evaluation:
Root Mean Squared Error: 3354.16
R² Score: 0.9617</code></pre>
</div>
</div>
</section>
<section id="early-stopping-in-xgboost" class="level3" data-number="10.5.6">
<h3 data-number="10.5.6" class="anchored" data-anchor-id="early-stopping-in-xgboost"><span class="header-section-number">10.5.6</span> Early Stopping in XGBoost</h3>
<p><strong>Early stopping</strong> is a technique that stops training when the model’s performance on a validation set stops improving, helping to prevent overfitting and reduce training time.</p>
<section id="how-it-works" class="level4" data-number="10.5.6.1">
<h4 data-number="10.5.6.1" class="anchored" data-anchor-id="how-it-works"><span class="header-section-number">10.5.6.1</span> How It Works</h4>
<p>At each boosting round, XGBoost tracks a performance metric (e.g., RMSE or log loss) on a <strong>validation set</strong>. If the metric doesn’t improve for a specified number of rounds (<code>early_stopping_rounds</code>), training is halted.</p>
<ul>
<li>Saves computation by avoiding unnecessary boosting rounds.</li>
<li>Returns the model from the best iteration (with the lowest validation error).</li>
</ul>
</section>
<section id="requirements" class="level4" data-number="10.5.6.2">
<h4 data-number="10.5.6.2" class="anchored" data-anchor-id="requirements"><span class="header-section-number">10.5.6.2</span> Requirements</h4>
<ul>
<li>You must provide an <strong><code>eval_set</code></strong> containing a validation set.</li>
<li>The evaluation metric must be one that XGBoost can track (<code>eval_metric</code> is optional but recommended).</li>
</ul>
<div id="53be44ec" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== 2. Early Stopping =====</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">===== XGBoost with Early Stopping ====="</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create validation set for early stopping</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>X_train_es, X_val, y_train_es, y_val <span class="op">=</span> train_test_split(X_train, y_train, test_size<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Preprocess the validation set</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>preprocessor_fit <span class="op">=</span> preprocessor.fit(X_train_es)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>X_train_es_transformed <span class="op">=</span> preprocessor_fit.transform(X_train_es)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>X_val_transformed <span class="op">=</span> preprocessor_fit.transform(X_val)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Train with early stopping</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>early_stop_model <span class="op">=</span> XGBRegressor(</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    early_stopping_rounds<span class="op">=</span><span class="dv">20</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>early_stop_model.fit(</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    X_train_es_transformed, y_train_es,</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    eval_set<span class="op">=</span>[(X_val_transformed, y_val)],</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">False</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
===== XGBoost with Early Stopping =====</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=20,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=1000,
             n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>XGBRegressor</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor">?<span>Documentation for XGBRegressor</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=20,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=1000,
             n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>
</div>
</div>
<div id="86c006fd" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Update the pipeline with the best model</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>early_stop_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor),</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'regressor'</span>, XGBRegressor(</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span>early_stop_model.best_iteration,  <span class="co"># Use the best number of iterations</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>early_stop_pipeline.fit(X_train, y_train)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Early Stopping Model Evaluation:"</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>early_stop_metrics <span class="op">=</span> evaluate_model(early_stop_pipeline, X_test, y_test)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best number of iterations: </span><span class="sc">{</span>early_stop_model<span class="sc">.</span>best_iteration<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Early Stopping Model Evaluation:
Root Mean Squared Error: 3332.03
R² Score: 0.9622
Best number of iterations: 193</code></pre>
</div>
</div>
</section>
</section>
<section id="gamma-in-xgboost" class="level3" data-number="10.5.7">
<h3 data-number="10.5.7" class="anchored" data-anchor-id="gamma-in-xgboost"><span class="header-section-number">10.5.7</span> <code>gamma</code> in XGBoost</h3>
<p><strong>Definition</strong>:<br>
<code>gamma</code> (also called <code>min_split_loss</code>) specifies the <strong>minimum loss reduction required</strong> to make a further partition (split) on a leaf node of the tree.</p>
<p><strong>How it works</strong>:</p>
<ul>
<li>During tree construction, XGBoost evaluates whether splitting a node reduces the overall training loss.</li>
<li>If the <strong>reduction in loss is less than <code>gamma</code></strong>, the split is <strong>discarded</strong>, and the node becomes a leaf.</li>
<li>Higher values of <code>gamma</code> make the algorithm more <strong>conservative</strong>, leading to <strong>simpler trees</strong>.</li>
</ul>
<p><strong>Formula</strong>:<br>
At each split, XGBoost calculates the gain (reduction in regularized loss):</p>
<p><span class="math display">\[
\text{Gain} = \frac{1}{2} \left( \frac{G_L^2}{H_L + \lambda} + \frac{G_R^2}{H_R + \lambda} - \frac{(G_L + G_R)^2}{H_L + H_R + \lambda} \right) - \gamma
\]</span></p>
<p>Where: - <span class="math inline">\(G_L\)</span>, <span class="math inline">\(H_L\)</span>: gradient and hessian sums for the <strong>left child</strong> - <span class="math inline">\(G_R\)</span>, <span class="math inline">\(H_R\)</span>: gradient and hessian sums for the <strong>right child</strong> - <span class="math inline">\(\lambda\)</span>: L2 regularization term - <span class="math inline">\(\gamma\)</span>: minimum loss reduction required to make a split</p>
<p><strong>Effect of <code>gamma</code></strong>:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 43%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th><code>gamma</code> Value</th>
<th>Behavior</th>
<th>Risk</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0 (default)</td>
<td>Most splits are allowed</td>
<td>Overfitting possible</td>
</tr>
<tr class="even">
<td>Moderate</td>
<td>Small-gain splits are blocked</td>
<td>More robust trees</td>
</tr>
<tr class="odd">
<td>High</td>
<td>Very few splits allowed</td>
<td>Underfitting possible</td>
</tr>
</tbody>
</table>
<p><strong>Use case</strong>: - Tune <code>gamma</code> to <strong>prune noisy or unnecessary splits</strong>. - Helpful when the model is <strong>overfitting</strong>, especially on small datasets.</p>
<p><strong>Example</strong>:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>XGBRegressor(gamma<span class="op">=</span><span class="fl">1.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="c05ea353" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== 3. Regularization Experiments: varying gamma =====</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">===== XGBoost with Regularization: Varying Gamma ====="</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the parameter grid for gamma</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__gamma'</span>: [<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new pipeline for the regularization experiment</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>regularization_gamma_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor),</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'regressor'</span>, XGBRegressor(random_state<span class="op">=</span><span class="dv">42</span>, n_estimators<span class="op">=</span>early_stop_model.best_iteration))</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform grid search with cross-validation</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>grid_search_gamma <span class="op">=</span> GridSearchCV(</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    regularization_gamma_pipeline,</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>,</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>grid_search_gamma.fit(X_train, y_train)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Parameters from Regularization Tuning (γ - gamma)::"</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(grid_search_gamma.best_params_)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Cross-Validation RMSE: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(np.sqrt(<span class="op">-</span>grid_search_gamma.best_score_)))</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the best model from grid search</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>best_gamma_model <span class="op">=</span> grid_search_gamma.best_estimator_</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Test Set Evaluation for Best Model from Gamma Regularization Tuning:"</span>)</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>regularization_metrics <span class="op">=</span> evaluate_model(best_gamma_model, X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
===== XGBoost with Regularization: Varying Gamma =====

Best Parameters from Regularization Tuning (γ - gamma)::
{'regressor__gamma': 100}
Best Cross-Validation RMSE: 3428.44

Test Set Evaluation for Best Model from Gamma Regularization Tuning:
Root Mean Squared Error: 3332.02
R² Score: 0.9622</code></pre>
</div>
</div>
<div id="304e0501" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract gamma values and corresponding mean CV RMSE</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>gamma_values <span class="op">=</span> grid_search_gamma.cv_results_[<span class="st">'param_regressor__gamma'</span>].data</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert mean test scores to RMSE, rounding to 2 decimal places</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>mean_rmse_scores <span class="op">=</span> np.sqrt(<span class="op">-</span>grid_search_gamma.cv_results_[<span class="st">'mean_test_score'</span>])</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Round the RMSE scores to 2 decimal places</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>mean_rmse_scores <span class="op">=</span> np.<span class="bu">round</span>(mean_rmse_scores, <span class="dv">4</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot gamma vs RMSE with plain y-axis tick labels</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>plt.plot(gamma_values, mean_rmse_scores, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Gamma (min_split_loss)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'CV RMSE'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Effect of gamma on XGBoost Performance'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="XGBoost_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Effect of <code>gamma</code> on XGBoost Performance</strong></p>
<p>As <code>gamma</code> increases, XGBoost becomes more selective about making splits.</p>
<ul>
<li><strong>Low gamma (0–5)</strong>: Trees grow freely → higher RMSE due to possible overfitting.</li>
<li><strong>Moderate to high gamma (10–100)</strong>: Blocks weak splits → simpler trees with better validation performance.</li>
</ul>
<p>In this dataset, higher <code>gamma</code> values improved generalization by preventing unnecessary splits.</p>
</section>
<section id="reg_lambda-and-reg_alpha-in-xgboost" class="level3" data-number="10.5.8">
<h3 data-number="10.5.8" class="anchored" data-anchor-id="reg_lambda-and-reg_alpha-in-xgboost"><span class="header-section-number">10.5.8</span> <code>reg_lambda</code> and <code>reg_alpha</code> in XGBoost</h3>
<p>XGBoost includes <strong>regularization</strong> to help prevent overfitting by penalizing complex trees.</p>
<ul>
<li><code>reg_lambda</code> (L2 regularization):
<ul>
<li>Penalizes large leaf weights using a squared penalty.</li>
<li>Encourages smaller, smoother weight values (like Ridge regression).</li>
<li>Helps when many features contribute weakly.</li>
</ul></li>
<li><code>reg_alpha</code> (L1 regularization):
<ul>
<li>Penalizes absolute values of leaf weights.</li>
<li>Can shrink some weights to zero, effectively performing feature selection (like Lasso).</li>
<li>Useful when you expect only a few strong features.</li>
</ul></li>
</ul>
<p><strong>Objective function with regularization</strong>: <span class="math display">\[
\mathcal{L} = \text{Loss} + \gamma T + \frac{1}{2} \lambda \sum_j w_j^2 + \alpha \sum_j |w_j|
\]</span></p>
<p>Where: - <span class="math inline">\(\text{Loss}\)</span>: training loss (e.g., squared error or log loss) - <span class="math inline">\(T\)</span>: number of leaves in the tree - <span class="math inline">\(w_j\)</span>: weight of the <span class="math inline">\(j\)</span>-th leaf - <span class="math inline">\(\lambda\)</span>: L2 regularization (Ridge penalty) - <span class="math inline">\(\alpha\)</span>: L1 regularization (Lasso penalty) - <span class="math inline">\(\gamma\)</span>: cost for adding a new leaf (controls tree growth)</p>
<p><strong>Understanding them via Ridge, Lasso, and ElasticNet you learned in STAT303-2</strong></p>
<p>Just like Ridge/Lasso regularization helps linear models generalize better, <code>reg_lambda</code> and <code>reg_alpha</code> help XGBoost prevent overfitting by controlling how complex the trees become through leaf weight penalties.</p>
<ul>
<li><code>reg_alpha</code> = 0 → <strong>No L1 penalty</strong>, behaves like Ridge (only L2 used)</li>
<li><code>reg_lambda</code> = 0 → <strong>No L2 penalty</strong>, behaves like Lasso (only L1 used)</li>
<li><code>reg_alpha &gt; 0</code> and <code>reg_lambda &gt; 0</code> → behaves like <strong>ElasticNet</strong></li>
</ul>
<p>This analogy helps understand how XGBoost controls model complexity:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 38%">
<col style="width: 61%">
</colgroup>
<thead>
<tr class="header">
<th>Setting</th>
<th>Behavior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>reg_alpha=0</code>, <code>reg_lambda&gt;0</code></td>
<td>Like <strong>Ridge</strong> → smooth leaf weights, all included</td>
</tr>
<tr class="even">
<td><code>reg_alpha&gt;0</code>, <code>reg_lambda=0</code></td>
<td>Like <strong>Lasso</strong> → some leaf weights may shrink to zero</td>
</tr>
<tr class="odd">
<td>Both &gt; 0</td>
<td>Like <strong>ElasticNet</strong> → balance shrinkage and sparsity</td>
</tr>
<tr class="even">
<td>Both = 0 (default)</td>
<td>No regularization → may overfit on small/noisy data</td>
</tr>
</tbody>
</table>
<div id="7ad7f33e" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== 3. Regularization Experiments: tuning reg_lambda and reg_alpha =====</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">===== Exploring Regularization Parameters: reg_lambda and reg_alpha ====="</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the parameter grid for reg_lambda and reg_alpha</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>param_grid_reg <span class="op">=</span> {</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__reg_lambda'</span>: [<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__reg_alpha'</span>: [<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new pipeline for the regularization experiment</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>regularization_lambda_alpha_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor),</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'regressor'</span>, XGBRegressor(random_state<span class="op">=</span><span class="dv">42</span>, n_estimators<span class="op">=</span>early_stop_model.best_iteration))</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform grid search with cross-validation</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>grid_search_lambda_alpha_reg <span class="op">=</span> GridSearchCV(</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    regularization_lambda_alpha_pipeline,</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    param_grid_reg,</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>,</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>grid_search_lambda_alpha_reg.fit(X_train, y_train)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Parameters from Lambda and Alpha Regularization Tuning:"</span>)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(grid_search_lambda_alpha_reg.best_params_)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Cross-Validation RMSE: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(np.sqrt(<span class="op">-</span>grid_search_lambda_alpha_reg.best_score_)))</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the best model from grid search</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>best_lambda_alpha_model <span class="op">=</span> grid_search_lambda_alpha_reg.best_estimator_</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Test Set Evaluation for Best Regularization Model (λ and α):"</span>)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>regularization_metrics_reg <span class="op">=</span> evaluate_model(best_lambda_alpha_model, X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
===== Exploring Regularization Parameters: reg_lambda and reg_alpha =====

Best Parameters from Lambda and Alpha Regularization Tuning:
{'regressor__reg_alpha': 1, 'regressor__reg_lambda': 0}
Best Cross-Validation RMSE: 3361.75

Test Set Evaluation for Best Regularization Model (λ and α):
Root Mean Squared Error: 3551.09
R² Score: 0.9570</code></pre>
</div>
</div>
<div id="059b4242" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract reg_lambda and reg_alpha values and corresponding mean CV RMSE</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>reg_lambda_values <span class="op">=</span> grid_search_lambda_alpha_reg.cv_results_[<span class="st">'param_regressor__reg_lambda'</span>].data</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>reg_alpha_values <span class="op">=</span> grid_search_lambda_alpha_reg.cv_results_[<span class="st">'param_regressor__reg_alpha'</span>].data</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert mean test scores to RMSE, rounding to 2 decimal places</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>mean_rmse_scores_reg <span class="op">=</span> np.sqrt(<span class="op">-</span>grid_search_lambda_alpha_reg.cv_results_[<span class="st">'mean_test_score'</span>])</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Round the RMSE scores to 2 decimal places</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>mean_rmse_scores_reg <span class="op">=</span> np.<span class="bu">round</span>(mean_rmse_scores_reg, <span class="dv">4</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame for easier plotting</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>reg_lambda_alpha_results_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reg_lambda'</span>: reg_lambda_values,</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reg_alpha'</span>: reg_alpha_values,</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'mean_rmse'</span>: mean_rmse_scores_reg</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Pivot the DataFrame for heatmap</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>regreg_lambda_alpha_results_df_pivot_df <span class="op">=</span> reg_lambda_alpha_results_df.pivot(index<span class="op">=</span><span class="st">'reg_lambda'</span>, columns<span class="op">=</span><span class="st">'reg_alpha'</span>, values<span class="op">=</span><span class="st">'mean_rmse'</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the heatmap</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>sns.heatmap(regreg_lambda_alpha_results_df_pivot_df, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">".2f"</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>, cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'CV RMSE'</span>})</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Effect of reg_lambda and reg_alpha on XGBoost Performance'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'reg_alpha'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'reg_lambda'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="XGBoost_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="exploring-regularization-hyperparameters-simultaneously" class="level3" data-number="10.5.9">
<h3 data-number="10.5.9" class="anchored" data-anchor-id="exploring-regularization-hyperparameters-simultaneously"><span class="header-section-number">10.5.9</span> Exploring Regularization Hyperparameters Simultaneously</h3>
<p>In addition to <code>gamma</code>, <code>reg_lambda</code>, and <code>reg_alpha</code>, the parameters <code>max_depth</code> and <code>min_child_weight</code> also control the complexity of XGBoost models. These parameters behave similarly to how they work in other tree-based models.</p>
<p>Rather than tuning them in isolation, it’s important to recognize that these parameters <strong>interact</strong> with one another. In the next step, we will tune them <strong>simultaneously</strong> to better capture their combined effect on model performance.</p>
<div id="886b8c9d" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== 3. Regularization Experiments: Simultaneous Exploration  =====</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">===== Exploring Regularization Parameters Simultaneously ====="</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define regularization parameters to test</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>reg_params <span class="op">=</span> [</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'regressor__max_depth'</span>: <span class="dv">3</span>, <span class="st">'regressor__min_child_weight'</span>: <span class="dv">1</span>, <span class="st">'regressor__gamma'</span>: <span class="dv">0</span>, </span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>     <span class="st">'regressor__reg_alpha'</span>: <span class="dv">0</span>, <span class="st">'regressor__reg_lambda'</span>: <span class="dv">1</span>},</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'regressor__max_depth'</span>: <span class="dv">3</span>, <span class="st">'regressor__min_child_weight'</span>: <span class="dv">1</span>, <span class="st">'regressor__gamma'</span>: <span class="dv">0</span>, </span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>     <span class="st">'regressor__reg_alpha'</span>: <span class="dv">1</span>, <span class="st">'regressor__reg_lambda'</span>: <span class="dv">1</span>},</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'regressor__max_depth'</span>: <span class="dv">5</span>, <span class="st">'regressor__min_child_weight'</span>: <span class="dv">3</span>, <span class="st">'regressor__gamma'</span>: <span class="fl">0.1</span>, </span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>     <span class="st">'regressor__reg_alpha'</span>: <span class="dv">0</span>, <span class="st">'regressor__reg_lambda'</span>: <span class="dv">1</span>},</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'regressor__max_depth'</span>: <span class="dv">5</span>, <span class="st">'regressor__min_child_weight'</span>: <span class="dv">3</span>, <span class="st">'regressor__gamma'</span>: <span class="fl">0.1</span>, </span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>     <span class="st">'regressor__reg_alpha'</span>: <span class="dv">1</span>, <span class="st">'regressor__reg_lambda'</span>: <span class="dv">5</span>},</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'regressor__max_depth'</span>: <span class="dv">7</span>, <span class="st">'regressor__min_child_weight'</span>: <span class="dv">1</span>, <span class="st">'regressor__gamma'</span>: <span class="fl">0.2</span>, </span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>     <span class="st">'regressor__reg_alpha'</span>: <span class="dv">5</span>, <span class="st">'regressor__reg_lambda'</span>: <span class="dv">10</span>}</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Store results for comparison</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>reg_results <span class="op">=</span> []</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, params <span class="kw">in</span> <span class="bu">enumerate</span>(reg_params):</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Regularization Test </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(params)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create pipeline with these parameters</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    reg_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'preprocessor'</span>, preprocessor),</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'regressor'</span>, XGBRegressor(</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>            random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>            n_estimators<span class="op">=</span>early_stop_model.best_iteration,</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>            <span class="op">**</span>{k.replace(<span class="st">'regressor__'</span>, <span class="st">''</span>): v <span class="cf">for</span> k, v <span class="kw">in</span> params.items()}</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        ))</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train and evaluate</span></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>    reg_pipeline.fit(X_train, y_train)</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Model Evaluation:"</span>)</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>    metrics <span class="op">=</span> evaluate_model(reg_pipeline, X_test, y_test)</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>    rmse, r2 <span class="op">=</span> metrics</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Store results</span></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>    reg_results.append({</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>        <span class="st">'test'</span>: i<span class="op">+</span><span class="dv">1</span>,</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">'params'</span>: params,</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">'rmse'</span>: rmse,</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">'r2'</span>: r2</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Find best regularization parameters</span></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>reg_df <span class="op">=</span> pd.DataFrame(reg_results)</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>best_reg_idx <span class="op">=</span> reg_df[<span class="st">'rmse'</span>].idxmin()</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>best_reg_params <span class="op">=</span> reg_df.loc[best_reg_idx, <span class="st">'params'</span>]</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Regularization Parameters:"</span>)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_reg_params)</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best RMSE: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(reg_df[<span class="st">'rmse'</span>].<span class="bu">min</span>()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
===== Exploring Regularization Parameters Simultaneously =====

Regularization Test 1:
{'regressor__max_depth': 3, 'regressor__min_child_weight': 1, 'regressor__gamma': 0, 'regressor__reg_alpha': 0, 'regressor__reg_lambda': 1}

Model Evaluation:
Root Mean Squared Error: 3774.48
R² Score: 0.9514

Regularization Test 2:
{'regressor__max_depth': 3, 'regressor__min_child_weight': 1, 'regressor__gamma': 0, 'regressor__reg_alpha': 1, 'regressor__reg_lambda': 1}

Model Evaluation:
Root Mean Squared Error: 3774.48
R² Score: 0.9514

Regularization Test 3:
{'regressor__max_depth': 5, 'regressor__min_child_weight': 3, 'regressor__gamma': 0.1, 'regressor__reg_alpha': 0, 'regressor__reg_lambda': 1}

Model Evaluation:
Root Mean Squared Error: 3334.18
R² Score: 0.9621

Regularization Test 4:
{'regressor__max_depth': 5, 'regressor__min_child_weight': 3, 'regressor__gamma': 0.1, 'regressor__reg_alpha': 1, 'regressor__reg_lambda': 5}

Model Evaluation:
Root Mean Squared Error: 3298.88
R² Score: 0.9629

Regularization Test 5:
{'regressor__max_depth': 7, 'regressor__min_child_weight': 1, 'regressor__gamma': 0.2, 'regressor__reg_alpha': 5, 'regressor__reg_lambda': 10}

Model Evaluation:
Root Mean Squared Error: 3222.51
R² Score: 0.9646

Best Regularization Parameters:
{'regressor__max_depth': 7, 'regressor__min_child_weight': 1, 'regressor__gamma': 0.2, 'regressor__reg_alpha': 5, 'regressor__reg_lambda': 10}
Best RMSE: 3222.51</code></pre>
</div>
</div>
</section>
<section id="comprehensive-hyperparameter-tuning" class="level3" data-number="10.5.10">
<h3 data-number="10.5.10" class="anchored" data-anchor-id="comprehensive-hyperparameter-tuning"><span class="header-section-number">10.5.10</span> Comprehensive Hyperparameter Tuning</h3>
<p>In this step, we expand our search to include a broader set of influential hyperparameters that govern both <strong>model complexity</strong> and <strong>regularization strength</strong> in XGBoost. These include:</p>
<ul>
<li><strong><code>learning_rate</code></strong>: Controls the contribution of each tree in the ensemble.</li>
<li><strong><code>max_depth</code></strong> and <strong><code>min_child_weight</code></strong>: Control tree complexity and can help prevent overfitting.</li>
<li><strong><code>gamma</code></strong>: Adds regularization by requiring a minimum loss reduction for a split.</li>
<li><strong><code>subsample</code></strong> and <strong><code>colsample_bytree</code></strong>: Introduce stochasticity to reduce overfitting by sampling rows and features, respectively.</li>
<li><strong><code>reg_alpha</code></strong> (L1 regularization) and <strong><code>reg_lambda</code></strong> (L2 regularization): Add penalties to leaf weights to shrink overly complex trees.</li>
</ul>
<p>Rather than optimizing these parameters independently, we will <strong>tune them together</strong> using a grid search to capture the complex interactions between them. This comprehensive search aims to identify a well-balanced model that generalizes well to unseen data.</p>
<p>This comprehensive tuning process helps us identify the most effective combination of hyperparameters for maximizing predictive performance while minimizing overfitting.</p>
<section id="why-gridsearchcv-is-not-a-practical-option" class="level4" data-number="10.5.10.1">
<h4 data-number="10.5.10.1" class="anchored" data-anchor-id="why-gridsearchcv-is-not-a-practical-option"><span class="header-section-number">10.5.10.1</span> Why <code>GridSearchCV</code> Is Not a Practical Option</h4>
<p>While <code>GridSearchCV</code> is a straightforward and exhaustive approach, it can be <strong>extremely time-consuming</strong>, especially when tuning many hyperparameters over multiple values. In our case, the parameter grid includes:</p>
<ul>
<li>3 values for <code>learning_rate</code></li>
<li>3 values for <code>max_depth</code></li>
<li>3 values for <code>min_child_weight</code></li>
<li>3 values for <code>gamma</code></li>
<li>3 values each for <code>subsample</code> and <code>colsample_bytree</code></li>
<li>3 values for <code>reg_alpha</code></li>
<li>3 values for <code>reg_lambda</code></li>
</ul>
<p>This results in a <strong>total of 3⁸ = 6,561 combinations</strong>. With 3-fold cross-validation, this would involve training and evaluating <strong>over 19,000 models</strong>, making it <strong>computationally expensive and inefficient</strong>.</p>
<p>The code is included below if you’re curious to try it out — just <strong>uncomment the <code>.fit()</code> line</strong> to experience how long it takes.</p>
<div id="e1c4ac31" class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== 4. Comprehensive Hyperparameter Tuning =====</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">===== Comprehensive Hyperparameter Tuning Using GridSearchCV====="</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define hyperparameter grid</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>],</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__max_depth'</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>],</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__min_child_weight'</span>: [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>],</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__gamma'</span>: [<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>],</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__subsample'</span>: [<span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">1.0</span>],</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__colsample_bytree'</span>: [<span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">1.0</span>],</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__reg_alpha'</span>: [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>],</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__reg_lambda'</span>: [<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>]</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a pipeline for grid search</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>tune_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor),</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'regressor'</span>, XGBRegressor(</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span>early_stop_model.best_iteration</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up grid search with cross-validation</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    tune_pipeline,</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>,</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a><span class="co"># uncomment the line below to run the grid search (it may take a long time)</span></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a><span class="co">#grid_search.fit(X_train, y_train)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
===== Comprehensive Hyperparameter Tuning =====</code></pre>
</div>
</div>
</section>
<section id="smarter-tuning-with-optuna-or-bayessearchcv" class="level4" data-number="10.5.10.2">
<h4 data-number="10.5.10.2" class="anchored" data-anchor-id="smarter-tuning-with-optuna-or-bayessearchcv"><span class="header-section-number">10.5.10.2</span> Smarter Tuning with Optuna or BayesSearchCV</h4>
<p>Instead of exhaustively evaluating every combination like <code>GridSearchCV</code>, we can use smarter search strategies like:</p>
<ul>
<li><p><strong>Optuna</strong>: A powerful hyperparameter optimization framework that uses <strong>Tree-structured Parzen Estimators (TPE)</strong> to efficiently explore the search space. It dynamically chooses the next set of hyperparameters to try based on past performance.</p></li>
<li><p><strong>BayesSearchCV</strong> (from <code>scikit-optimize</code>): Implements <strong>Bayesian optimization</strong>, which builds a probabilistic model of the objective function and selects the most promising hyperparameters to try next.</p></li>
</ul>
<p>These methods are:</p>
<ul>
<li><strong>More efficient</strong>: They converge to good solutions with far fewer iterations.</li>
<li><strong>Flexible</strong>: They support conditional hyperparameter tuning.</li>
<li><strong>Scalable</strong>: Much better suited for high-dimensional or expensive-to-evaluate models.</li>
</ul>
<p>In summary, we commented out the grid search due to its high cost and instead favor more <strong>intelligent, efficient</strong> hyperparameter search methods like <code>Optuna</code> or <code>BayesSearchCV</code> for practical use.</p>
<section id="bayessearchcv-from-skopt" class="level5" data-number="10.5.10.2.1">
<h5 data-number="10.5.10.2.1" class="anchored" data-anchor-id="bayessearchcv-from-skopt"><span class="header-section-number">10.5.10.2.1</span> <code>BayesSearchCV</code> (from <code>skopt</code>)</h5>
<p>You define the search space using a dictionary where:</p>
<ul>
<li>For pipelines and scikit-learn integration, <code>BayesSearchCV</code> is simpler</li>
<li>Keys are hyperparameter names (matching pipeline step names like <code>'regressor__max_depth'</code>)</li>
<li>Values are distributions or discrete ranges from <code>skopt.space</code></li>
</ul>
<blockquote class="blockquote">
<p>🔹 <strong>Key Tip</strong>: Use <code>Real(..., prior='log-uniform')</code> for parameters like <code>learning_rate</code>, which benefit from exploring small values on a <strong>logarithmic scale</strong>.<br>
This helps the search algorithm better identify optimal values in ranges where performance is sensitive to small changes (e.g., between 0.01 and 0.1).</p>
</blockquote>
<div id="050d7a0d" class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define the search space for Bayesian optimization</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>search_space <span class="op">=</span> {</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__learning_rate'</span>: Real(<span class="fl">0.01</span>, <span class="fl">0.5</span>, prior<span class="op">=</span><span class="st">'uniform'</span>),</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__max_depth'</span>: Integer(<span class="dv">3</span>, <span class="dv">7</span>),</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__min_child_weight'</span>: Integer(<span class="dv">1</span>, <span class="dv">5</span>),</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__gamma'</span>: Real(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__subsample'</span>: Real(<span class="fl">0.5</span>, <span class="fl">1.0</span>),</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__colsample_bytree'</span>: Real(<span class="fl">0.5</span>, <span class="fl">1.0</span>),</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__reg_alpha'</span>: Real(<span class="dv">0</span>, <span class="dv">5</span>),</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'regressor__reg_lambda'</span>: Real(<span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a pipeline for Bayesian optimization</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>bayes_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor),</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'regressor'</span>, XGBRegressor(</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span>early_stop_model.best_iteration</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up Bayesian optimization with cross-validation</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>bayes_search <span class="op">=</span> BayesSearchCV(</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    bayes_pipeline,</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    search_space,</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>    n_iter<span class="op">=</span><span class="dv">50</span>,  <span class="co"># Number of iterations for Bayesian optimization</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>,</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform Bayesian optimization</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>bayes_search.fit(X_train, y_train)</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the best parameters and score</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Parameters from Bayesian Optimization:"</span>)</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bayes_search.best_params_)</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Cross-Validation RMSE: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(<span class="op">-</span>bayes_search.best_score_))</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the best model from Bayesian optimization</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>best_bayes_model <span class="op">=</span> bayes_search.best_estimator_</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Bayesian Optimization Model Evaluation:"</span>)</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>bayes_metrics <span class="op">=</span> evaluate_model(best_bayes_model, X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits

Best Parameters from Bayesian Optimization:
OrderedDict({'regressor__colsample_bytree': 0.6350099974437949, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.15012576802968475, 'regressor__max_depth': 7, 'regressor__min_child_weight': 1, 'regressor__reg_alpha': 5.0, 'regressor__reg_lambda': 9.330007518126198, 'regressor__subsample': 0.77576084288087})
Best Cross-Validation RMSE: 3212.04

Bayesian Optimization Model Evaluation:
Root Mean Squared Error: 3083.10
R² Score: 0.9676</code></pre>
</div>
</div>
<p>Let’s visualize the search results</p>
<div id="3ac66ba5" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot convergence</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>plot_convergence(bayes_search.optimizer_results_)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="XGBoost_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="205aaa63" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the objective function</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>plot_objective(bayes_search.optimizer_results_[<span class="dv">0</span>])</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Bayesian Optimization: Objective Function'</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Parameter Value'</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Objective Value (RMSE)'</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="XGBoost_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="f4e91ec1" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the final model with the best hyperparameters</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">===== Final Model with Best Hyperparameters ====="</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>final_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor),</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'regressor'</span>, XGBRegressor(</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span>early_stop_model.best_iteration,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>{k.replace(<span class="st">'regressor__'</span>, <span class="st">''</span>): v <span class="cf">for</span> k, v <span class="kw">in</span> bayes_search.best_params_.items()}</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the final model</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>final_pipeline.fit(X_train, y_train)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate final model</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Final Model Evaluation:"</span>)</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>final_metrics <span class="op">=</span> evaluate_model(final_pipeline, X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
===== Final Model with Best Hyperparameters =====

Final Model Evaluation:
Root Mean Squared Error: 3083.10
R² Score: 0.9676</code></pre>
</div>
</div>
<div id="45892e6e" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display actual vs predicted values for the final model</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> final_pipeline.predict(X_test)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(y_test, y_pred, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>plt.plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], <span class="st">'r--'</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual'</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted'</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Actual vs Predicted Values (Final Model)'</span>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="XGBoost_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="4a4b5c1e" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># output the feature importance for the final model</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>final_importance <span class="op">=</span> plot_feature_importance(final_pipeline.named_steps[<span class="st">'regressor'</span>], </span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>                                             final_pipeline.named_steps[<span class="st">'preprocessor'</span>], </span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>                                             X)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>final_importance</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Feature</th>
<th data-quarto-table-cell-role="th">Importance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>model_ I800</td>
<td>0.109385</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>engineSize</td>
<td>0.085000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>transmission_Manual</td>
<td>0.080872</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>brand_hyundi</td>
<td>0.045237</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>brand_vw</td>
<td>0.041919</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>brand_ford</td>
<td>0.038523</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>model_ Mustang</td>
<td>0.031646</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>model_ i8</td>
<td>0.030787</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>brand_bmw</td>
<td>0.029788</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>year</td>
<td>0.025983</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>brand_merc</td>
<td>0.024978</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>model_ R8</td>
<td>0.024132</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>model_ S Class</td>
<td>0.024024</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>brand_audi</td>
<td>0.019605</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>model_ X7</td>
<td>0.019070</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>model_ V Class</td>
<td>0.014943</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>model_ X-CLASS</td>
<td>0.013910</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>brand_toyota</td>
<td>0.013511</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">18</td>
<td>mpg</td>
<td>0.012854</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">19</td>
<td>model_ X4</td>
<td>0.011403</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="tuning-with-optuna" class="level5" data-number="10.5.10.2.2">
<h5 data-number="10.5.10.2.2" class="anchored" data-anchor-id="tuning-with-optuna"><span class="header-section-number">10.5.10.2.2</span> Tuning with Optuna</h5>
<p>With Optuna, you define the search space inside an objective function using trial suggestions:</p>
<div id="0887d5d0" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> optuna</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the objective function for Optuna</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective(trial):</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Suggest hyperparameters</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> {</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'learning_rate'</span>: trial.suggest_float(<span class="st">'learning_rate'</span>, <span class="fl">0.01</span>, <span class="fl">0.5</span>),</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'max_depth'</span>: trial.suggest_int(<span class="st">'max_depth'</span>, <span class="dv">3</span>, <span class="dv">7</span>),</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">'min_child_weight'</span>: trial.suggest_int(<span class="st">'min_child_weight'</span>, <span class="dv">1</span>, <span class="dv">5</span>),</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'gamma'</span>: trial.suggest_float(<span class="st">'gamma'</span>, <span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'subsample'</span>: trial.suggest_float(<span class="st">'subsample'</span>, <span class="fl">0.5</span>, <span class="fl">1.0</span>),</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'colsample_bytree'</span>: trial.suggest_float(<span class="st">'colsample_bytree'</span>, <span class="fl">0.5</span>, <span class="fl">1.0</span>),</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'reg_alpha'</span>: trial.suggest_float(<span class="st">'reg_alpha'</span>, <span class="dv">0</span>, <span class="dv">5</span>),</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'reg_lambda'</span>: trial.suggest_float(<span class="st">'reg_lambda'</span>, <span class="dv">1</span>, <span class="dv">10</span>),</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'random_state'</span>: <span class="dv">42</span>,</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'n_estimators'</span>: <span class="dv">1000</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the model</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> XGBRegressor(<span class="op">**</span>params)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Optionally: wrap in pipeline if preprocessing is needed</span></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>    pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'preprocessor'</span>, preprocessor),  <span class="co"># assumed to be defined earlier</span></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'regressor'</span>, model)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate with cross-validation</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> cross_val_score(pipeline, X_train, y_train, cv<span class="op">=</span><span class="dv">3</span>, scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>).mean()</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> score  <span class="co"># Maximize negative RMSE (i.e., minimize RMSE)</span></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the Optuna study</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">'maximize'</span>)  <span class="co"># maximizing negative RMSE</span></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>study.optimize(objective, n_trials<span class="op">=</span><span class="dv">50</span>, timeout<span class="op">=</span><span class="dv">600</span>)</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the best result</span></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best trial:"</span>)</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  RMSE (CV): </span><span class="sc">{</span><span class="op">-</span>study<span class="sc">.</span>best_value<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Best hyperparameters:"</span>)</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> key, value <span class="kw">in</span> study.best_params.items():</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    </span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>value<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-05-14 04:47:06,217] A new study created in memory with name: no-name-59242cf6-161a-4605-a35c-8961a98f403e
[I 2025-05-14 04:47:07,258] Trial 0 finished with value: -3162.7913411458335 and parameters: {'learning_rate': 0.1641733170152142, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 0.15950428057497823, 'subsample': 0.8687525001570833, 'colsample_bytree': 0.5001903459871172, 'reg_alpha': 2.767789824640966, 'reg_lambda': 8.129162242032194}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:09,975] Trial 1 finished with value: -3368.8380533854165 and parameters: {'learning_rate': 0.15178125229556488, 'max_depth': 7, 'min_child_weight': 1, 'gamma': 0.050258482002987326, 'subsample': 0.5898378683092566, 'colsample_bytree': 0.9917924243351735, 'reg_alpha': 0.23111115691692774, 'reg_lambda': 2.0125181234384675}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:10,925] Trial 2 finished with value: -3432.02392578125 and parameters: {'learning_rate': 0.42391219724854534, 'max_depth': 3, 'min_child_weight': 5, 'gamma': 0.13708107402474898, 'subsample': 0.6148247399767317, 'colsample_bytree': 0.7362060869492091, 'reg_alpha': 2.489679115528034, 'reg_lambda': 2.1233179056863065}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:12,191] Trial 3 finished with value: -3344.6248372395835 and parameters: {'learning_rate': 0.265690187570691, 'max_depth': 4, 'min_child_weight': 2, 'gamma': 0.16133880047200677, 'subsample': 0.6611070905675426, 'colsample_bytree': 0.6704715035156631, 'reg_alpha': 4.144973354445489, 'reg_lambda': 3.9063999949186705}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:13,975] Trial 4 finished with value: -3270.3804524739585 and parameters: {'learning_rate': 0.028752592609356385, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.03302184395133658, 'subsample': 0.721688869095855, 'colsample_bytree': 0.632919922307615, 'reg_alpha': 3.0139736364453245, 'reg_lambda': 8.336475479937352}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:16,075] Trial 5 finished with value: -3520.0126953125 and parameters: {'learning_rate': 0.3795040467605126, 'max_depth': 5, 'min_child_weight': 4, 'gamma': 0.0923172410962489, 'subsample': 0.6576538128571611, 'colsample_bytree': 0.5874178737107301, 'reg_alpha': 4.327790643794075, 'reg_lambda': 5.539914427905474}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:18,141] Trial 6 finished with value: -3230.2576497395835 and parameters: {'learning_rate': 0.01887765935706954, 'max_depth': 7, 'min_child_weight': 4, 'gamma': 0.08395864006045435, 'subsample': 0.9650583569644329, 'colsample_bytree': 0.5068836778426125, 'reg_alpha': 4.319194027803546, 'reg_lambda': 2.4577201842849408}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:20,158] Trial 7 finished with value: -3265.4407552083335 and parameters: {'learning_rate': 0.10762455895584233, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.18945099975997307, 'subsample': 0.6082738049159904, 'colsample_bytree': 0.8839951047303432, 'reg_alpha': 1.7804602782057595, 'reg_lambda': 4.01856427883501}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:22,225] Trial 8 finished with value: -3521.05517578125 and parameters: {'learning_rate': 0.41352773552997424, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.12690667210056658, 'subsample': 0.5821082070503734, 'colsample_bytree': 0.5074336963373632, 'reg_alpha': 3.7306140414159943, 'reg_lambda': 3.3055935850297096}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:23,242] Trial 9 finished with value: -3271.8055013020835 and parameters: {'learning_rate': 0.08043112986012362, 'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.18113380178376634, 'subsample': 0.972342410237745, 'colsample_bytree': 0.9814376966070582, 'reg_alpha': 4.5010583121903815, 'reg_lambda': 8.046775880725079}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:25,226] Trial 10 finished with value: -3261.6067708333335 and parameters: {'learning_rate': 0.22708806215964497, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 0.0009135391068176013, 'subsample': 0.8494117211823278, 'colsample_bytree': 0.8257696123522402, 'reg_alpha': 1.0416025541499645, 'reg_lambda': 6.671020134916106}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:27,859] Trial 11 finished with value: -3377.5233561197915 and parameters: {'learning_rate': 0.20808419263829792, 'max_depth': 7, 'min_child_weight': 4, 'gamma': 0.09467108637827251, 'subsample': 0.9298835740565166, 'colsample_bytree': 0.5010865276579407, 'reg_alpha': 4.982274512288781, 'reg_lambda': 6.398529741869817}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:30,092] Trial 12 finished with value: -3359.8211263020835 and parameters: {'learning_rate': 0.01826323043937967, 'max_depth': 6, 'min_child_weight': 3, 'gamma': 0.07224880626353157, 'subsample': 0.8525172381777258, 'colsample_bytree': 0.566498265995001, 'reg_alpha': 3.0087037386707145, 'reg_lambda': 9.999053425477364}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:32,225] Trial 13 finished with value: -3389.99609375 and parameters: {'learning_rate': 0.13857618173924105, 'max_depth': 6, 'min_child_weight': 5, 'gamma': 0.1293470109573417, 'subsample': 0.8631896630954577, 'colsample_bytree': 0.7029461161450377, 'reg_alpha': 3.4076274113715366, 'reg_lambda': 1.1597707357570677}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:33,783] Trial 14 finished with value: -3303.03955078125 and parameters: {'learning_rate': 0.3047205728875082, 'max_depth': 4, 'min_child_weight': 4, 'gamma': 0.14361295278041297, 'subsample': 0.7937194720693732, 'colsample_bytree': 0.5727779194914605, 'reg_alpha': 2.129378952206828, 'reg_lambda': 9.80217028801741}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:36,609] Trial 15 finished with value: -3350.712158203125 and parameters: {'learning_rate': 0.17656556325674955, 'max_depth': 6, 'min_child_weight': 3, 'gamma': 0.10914046017834621, 'subsample': 0.9996361890269867, 'colsample_bytree': 0.821830315105234, 'reg_alpha': 1.4844593608366676, 'reg_lambda': 8.251897448342861}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:39,729] Trial 16 finished with value: -3751.3375651041665 and parameters: {'learning_rate': 0.49732527342995736, 'max_depth': 7, 'min_child_weight': 5, 'gamma': 0.06646629587180926, 'subsample': 0.9191757507198699, 'colsample_bytree': 0.6417276413491501, 'reg_alpha': 3.7131164539205996, 'reg_lambda': 4.691801429872557}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:41,442] Trial 17 finished with value: -3220.991943359375 and parameters: {'learning_rate': 0.06349399117329421, 'max_depth': 4, 'min_child_weight': 4, 'gamma': 0.16152083780312498, 'subsample': 0.5193007623949828, 'colsample_bytree': 0.5378275423151795, 'reg_alpha': 4.957968250711724, 'reg_lambda': 6.887432633162225}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:42,826] Trial 18 finished with value: -3196.406494140625 and parameters: {'learning_rate': 0.09062768738247484, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 0.16932220309933962, 'subsample': 0.5102446555382051, 'colsample_bytree': 0.567680668921065, 'reg_alpha': 0.05899287011786036, 'reg_lambda': 7.095135377059309}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:43,876] Trial 19 finished with value: -3185.7190755208335 and parameters: {'learning_rate': 0.26626727039895703, 'max_depth': 3, 'min_child_weight': 2, 'gamma': 0.19772641560218734, 'subsample': 0.770138637973236, 'colsample_bytree': 0.6097234828156883, 'reg_alpha': 0.4836011903906194, 'reg_lambda': 9.025056369210269}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:45,326] Trial 20 finished with value: -3203.70068359375 and parameters: {'learning_rate': 0.26090742668861305, 'max_depth': 3, 'min_child_weight': 2, 'gamma': 0.19121127716686365, 'subsample': 0.7677836477495147, 'colsample_bytree': 0.6255725064175632, 'reg_alpha': 0.9445649986769805, 'reg_lambda': 9.184359429957107}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:46,993] Trial 21 finished with value: -3228.9916178385415 and parameters: {'learning_rate': 0.31856834300340886, 'max_depth': 3, 'min_child_weight': 3, 'gamma': 0.167803945880308, 'subsample': 0.7143519606311484, 'colsample_bytree': 0.5838931745172615, 'reg_alpha': 0.12405952462738234, 'reg_lambda': 7.282731249021393}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:48,459] Trial 22 finished with value: -3219.378662109375 and parameters: {'learning_rate': 0.19033406785822546, 'max_depth': 4, 'min_child_weight': 2, 'gamma': 0.1736546025660118, 'subsample': 0.7757362268856869, 'colsample_bytree': 0.5444873799616068, 'reg_alpha': 0.522783087786272, 'reg_lambda': 8.840854511279815}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:49,809] Trial 23 finished with value: -3211.786865234375 and parameters: {'learning_rate': 0.12106773616337452, 'max_depth': 3, 'min_child_weight': 3, 'gamma': 0.15243869650940434, 'subsample': 0.5134972988786516, 'colsample_bytree': 0.622819927934837, 'reg_alpha': 0.9827289505727954, 'reg_lambda': 7.603828126201174}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:51,676] Trial 24 finished with value: -3334.4794921875 and parameters: {'learning_rate': 0.3147366533286231, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 0.1991269835131424, 'subsample': 0.8079082775226714, 'colsample_bytree': 0.6818057638014908, 'reg_alpha': 1.552038632861544, 'reg_lambda': 6.041540266193317}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:53,576] Trial 25 finished with value: -3267.5618489583335 and parameters: {'learning_rate': 0.23472812275507773, 'max_depth': 4, 'min_child_weight': 1, 'gamma': 0.11335743801729878, 'subsample': 0.8916931874251384, 'colsample_bytree': 0.7531828256664181, 'reg_alpha': 0.5869522985399849, 'reg_lambda': 9.145754803235887}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:54,926] Trial 26 finished with value: -3202.6060384114585 and parameters: {'learning_rate': 0.08193443679035439, 'max_depth': 3, 'min_child_weight': 2, 'gamma': 0.1774109969796935, 'subsample': 0.8212131624598183, 'colsample_bytree': 0.54479642033082, 'reg_alpha': 2.4562856136420543, 'reg_lambda': 7.804051665963241}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:56,627] Trial 27 finished with value: -3199.9505208333335 and parameters: {'learning_rate': 0.1648392550100305, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 0.1995055644785968, 'subsample': 0.7369161561012435, 'colsample_bytree': 0.603109126467272, 'reg_alpha': 1.9696422807593317, 'reg_lambda': 8.794238617217513}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:58,059] Trial 28 finished with value: -3233.1486002604165 and parameters: {'learning_rate': 0.2816142969893795, 'max_depth': 3, 'min_child_weight': 2, 'gamma': 0.14825724873193188, 'subsample': 0.6758392394896388, 'colsample_bytree': 0.5464275473497652, 'reg_alpha': 0.5537122249305592, 'reg_lambda': 7.1212918481316265}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:47:59,893] Trial 29 finished with value: -3205.3538411458335 and parameters: {'learning_rate': 0.1469906386117053, 'max_depth': 4, 'min_child_weight': 1, 'gamma': 0.11925438218317995, 'subsample': 0.8909004703392734, 'colsample_bytree': 0.7322050029057333, 'reg_alpha': 0.037746661579750096, 'reg_lambda': 5.289887258623613}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:48:01,494] Trial 30 finished with value: -3383.5137532552085 and parameters: {'learning_rate': 0.37120330910823546, 'max_depth': 3, 'min_child_weight': 3, 'gamma': 0.1833492386708398, 'subsample': 0.5602887881874641, 'colsample_bytree': 0.6518986122343293, 'reg_alpha': 3.0231284972065575, 'reg_lambda': 9.61973061024477}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:48:03,243] Trial 31 finished with value: -3167.3258463541665 and parameters: {'learning_rate': 0.1863689590113835, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 0.19908264163989292, 'subsample': 0.7278685694121224, 'colsample_bytree': 0.5861480239301309, 'reg_alpha': 2.026116015039801, 'reg_lambda': 8.699297071780851}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:48:05,445] Trial 32 finished with value: -3281.510986328125 and parameters: {'learning_rate': 0.20151346925924155, 'max_depth': 5, 'min_child_weight': 3, 'gamma': 0.16458591948116905, 'subsample': 0.6958914280325602, 'colsample_bytree': 0.6042564555277344, 'reg_alpha': 1.3700762573158425, 'reg_lambda': 8.518791773797872}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:48:07,111] Trial 33 finished with value: -3204.1426595052085 and parameters: {'learning_rate': 0.12026108279051516, 'max_depth': 4, 'min_child_weight': 2, 'gamma': 0.15438462102064923, 'subsample': 0.6242819620230452, 'colsample_bytree': 0.5342892669503979, 'reg_alpha': 0.4963669112142102, 'reg_lambda': 7.666852561159716}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:48:08,476] Trial 34 finished with value: -3220.5049641927085 and parameters: {'learning_rate': 0.2337807893313772, 'max_depth': 3, 'min_child_weight': 3, 'gamma': 0.188224524248803, 'subsample': 0.7519391438650187, 'colsample_bytree': 0.6734690653266131, 'reg_alpha': 2.366857352866043, 'reg_lambda': 9.337266831653581}. Best is trial 0 with value: -3162.7913411458335.
[I 2025-05-14 04:48:10,219] Trial 35 finished with value: -3141.7112630208335 and parameters: {'learning_rate': 0.05427916910483564, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.17217342372478064, 'subsample': 0.6486895737288911, 'colsample_bytree': 0.5748420678684818, 'reg_alpha': 2.823104446765354, 'reg_lambda': 6.123835171658451}. Best is trial 35 with value: -3141.7112630208335.
[I 2025-05-14 04:48:12,727] Trial 36 finished with value: -3424.205810546875 and parameters: {'learning_rate': 0.3434536736887878, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.19798037524773468, 'subsample': 0.6462109533575047, 'colsample_bytree': 0.6013661462288122, 'reg_alpha': 2.8058983646067652, 'reg_lambda': 5.836376792997449}. Best is trial 35 with value: -3141.7112630208335.
[I 2025-05-14 04:48:14,696] Trial 37 finished with value: -3118.7006022135415 and parameters: {'learning_rate': 0.050933621089207015, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.17859904779145075, 'subsample': 0.687046200984366, 'colsample_bytree': 0.5234986611495844, 'reg_alpha': 2.814493606788762, 'reg_lambda': 4.8395816535714555}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:16,481] Trial 38 finished with value: -3122.8831380208335 and parameters: {'learning_rate': 0.06168478840447832, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.13797722131867746, 'subsample': 0.6960007534848832, 'colsample_bytree': 0.5182244063678463, 'reg_alpha': 2.731920033783212, 'reg_lambda': 4.550908916595087}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:18,515] Trial 39 finished with value: -3139.6028645833335 and parameters: {'learning_rate': 0.05316829440470475, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.13489818880210416, 'subsample': 0.6912991523076674, 'colsample_bytree': 0.517984422252086, 'reg_alpha': 3.408188018857992, 'reg_lambda': 4.62131346940151}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:21,326] Trial 40 finished with value: -3165.2281901041665 and parameters: {'learning_rate': 0.040909566934035954, 'max_depth': 6, 'min_child_weight': 1, 'gamma': 0.13647271109557557, 'subsample': 0.6868429049917079, 'colsample_bytree': 0.5098868980895536, 'reg_alpha': 3.3309798162772895, 'reg_lambda': 4.842339064732724}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:22,927] Trial 41 finished with value: -3153.988525390625 and parameters: {'learning_rate': 0.04764134215278892, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.13734423615317123, 'subsample': 0.6396914085172828, 'colsample_bytree': 0.5222333533007302, 'reg_alpha': 2.7683392736744907, 'reg_lambda': 3.4848817151425147}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:25,194] Trial 42 finished with value: -3138.40869140625 and parameters: {'learning_rate': 0.04665794491311853, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.14050710663623797, 'subsample': 0.6466622773319057, 'colsample_bytree': 0.5243207754378303, 'reg_alpha': 2.742598397314503, 'reg_lambda': 3.4532539995737297}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:27,181] Trial 43 finished with value: -3634.5953776041665 and parameters: {'learning_rate': 0.010559089516967338, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.10464776864762987, 'subsample': 0.590380693415102, 'colsample_bytree': 0.5527271103337551, 'reg_alpha': 3.3406191855405254, 'reg_lambda': 4.270515611372069}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:28,967] Trial 44 finished with value: -3160.775146484375 and parameters: {'learning_rate': 0.060736025914241036, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.12354110870609715, 'subsample': 0.7089501071182204, 'colsample_bytree': 0.5237902329649554, 'reg_alpha': 3.7441364304748164, 'reg_lambda': 2.9387955530200216}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:31,730] Trial 45 finished with value: -3168.1395670572915 and parameters: {'learning_rate': 0.037531801199779405, 'max_depth': 6, 'min_child_weight': 2, 'gamma': 0.14149686953692464, 'subsample': 0.6665114574999642, 'colsample_bytree': 0.5033999882927995, 'reg_alpha': 3.0970914358769033, 'reg_lambda': 4.899606528403381}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:34,529] Trial 46 finished with value: -3193.5437825520835 and parameters: {'learning_rate': 0.09959112301640272, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.15729275651842772, 'subsample': 0.622910390210815, 'colsample_bytree': 0.5659218113820054, 'reg_alpha': 2.5987048583369248, 'reg_lambda': 4.437051597406045}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:37,245] Trial 47 finished with value: -3228.6897786458335 and parameters: {'learning_rate': 0.07037240171555721, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.1344051098663805, 'subsample': 0.565145406031194, 'colsample_bytree': 0.9281697283786465, 'reg_alpha': 2.2287279424305964, 'reg_lambda': 3.764118180558043}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:40,511] Trial 48 finished with value: -3211.089111328125 and parameters: {'learning_rate': 0.10995519780575633, 'max_depth': 6, 'min_child_weight': 2, 'gamma': 0.09688240640580331, 'subsample': 0.6949408506367961, 'colsample_bytree': 0.5247184310894689, 'reg_alpha': 3.9418544972703486, 'reg_lambda': 5.287998554183364}. Best is trial 37 with value: -3118.7006022135415.
[I 2025-05-14 04:48:42,711] Trial 49 finished with value: -3200.5746256510415 and parameters: {'learning_rate': 0.028839725004554832, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.024679179556514927, 'subsample': 0.6593982063331032, 'colsample_bytree': 0.5591427707331742, 'reg_alpha': 2.638934979392886, 'reg_lambda': 2.9603331872221825}. Best is trial 37 with value: -3118.7006022135415.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best trial:
  RMSE (CV): 3118.7006
  Best hyperparameters:
    learning_rate: 0.050933621089207015
    max_depth: 5
    min_child_weight: 2
    gamma: 0.17859904779145075
    subsample: 0.687046200984366
    colsample_bytree: 0.5234986611495844
    reg_alpha: 2.814493606788762
    reg_lambda: 4.8395816535714555</code></pre>
</div>
</div>
<p>Let’s visualize the result</p>
<div id="fd419394" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> optuna.visualization <span class="im">as</span> vis</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>fig1 <span class="op">=</span> vis.plot_optimization_history(study)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>fig1.show()</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>fig2 <span class="op">=</span> vis.plot_param_importances(study)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>fig2.show()</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>fig3 <span class="op">=</span> vis.plot_slice(study)</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>fig3.show()</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
</div>
</section>
</section>
<section id="after-training-analyze-and-refine" class="level4" data-number="10.5.10.3">
<h4 data-number="10.5.10.3" class="anchored" data-anchor-id="after-training-analyze-and-refine"><span class="header-section-number">10.5.10.3</span> After Training: Analyze and Refine</h4>
<p>Once the tuning is complete, <strong>don’t forget to visualize the search results</strong> to understand how different hyperparameters affected performance. This helps you:</p>
<ul>
<li>Identify which parameters had the most impact.</li>
<li>Spot trends (e.g., performance plateaus or sharp drop-offs).</li>
<li>Detect boundary effects (e.g., best values lie at the edge of the current search space).</li>
</ul>
<blockquote class="blockquote">
<p>🔹 <strong>Key Tip</strong>: If the best values are near the boundary of your current search space, consider <strong>fine-tuning the search space</strong> and re-running the optimization.</p>
</blockquote>
<p>You can visualize results using:</p>
<ul>
<li><code>Optuna</code>’s built-in plots like <code>plot_optimization_history()</code> and <code>plot_param_importances()</code>.</li>
<li><code>BayesSearchCV</code>’s <code>cv_results_</code> attribute to create custom plots using <code>pandas</code> or <code>seaborn</code>.</li>
</ul>
<p>Effective tuning is often <strong>iterative</strong> — let the data guide you!</p>
</section>
</section>
</section>
<section id="xgboost-for-imbalanced-classification" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="xgboost-for-imbalanced-classification"><span class="header-section-number">10.6</span> XGBoost for Imbalanced Classification</h2>
<section id="common-strategies-across-libraries" class="level3" data-number="10.6.1">
<h3 data-number="10.6.1" class="anchored" data-anchor-id="common-strategies-across-libraries"><span class="header-section-number">10.6.1</span> Common Strategies Across Libraries</h3>
<p>Imbalanced classification arises when one class is significantly underrepresented—common in applications like <strong>fraud detection</strong>, <strong>rare disease diagnosis</strong>, and <strong>anomaly detection</strong>.</p>
<ul>
<li><p><strong>Use Better Evaluation Metrics</strong><br>
Avoid relying on accuracy. Instead, use metrics that reflect class imbalance, such as:</p>
<ul>
<li><strong>F1-score</strong></li>
<li><strong>AUC-PR</strong> (Area Under the Precision-Recall Curve)</li>
<li><strong>Matthews Correlation Coefficient (MCC)</strong></li>
</ul></li>
<li><p><strong>Threshold Tuning</strong><br>
Adjust the <strong>decision threshold</strong> to balance between precision and recall based on your use case.</p></li>
<li><p><strong>Stratified Sampling</strong><br>
When splitting the dataset (for training/validation or cross-validation), use <strong>stratified sampling</strong> to maintain the class distribution in each fold.</p></li>
</ul>
</section>
<section id="handling-class-imbalance-with-scale_pos_weight-in-xgboost" class="level3" data-number="10.6.2">
<h3 data-number="10.6.2" class="anchored" data-anchor-id="handling-class-imbalance-with-scale_pos_weight-in-xgboost"><span class="header-section-number">10.6.2</span> Handling Class Imbalance with <code>scale_pos_weight</code> in XGBoost</h3>
<p>While XGBoost (and other gradient boosting libraries) can perform well on imbalanced datasets, models can become biased toward the <strong>majority class</strong> if no corrective strategies are used. One of the most effective built-in solutions in XGBoost is the <code>scale_pos_weight</code> parameter.</p>
<section id="what-does-scale_pos_weight-do" class="level4" data-number="10.6.2.1">
<h4 data-number="10.6.2.1" class="anchored" data-anchor-id="what-does-scale_pos_weight-do"><span class="header-section-number">10.6.2.1</span> What Does <code>scale_pos_weight</code> Do?</h4>
<p>The <code>scale_pos_weight</code> parameter adjusts the <strong>relative importance</strong> of positive class examples (<code>label = 1</code>) by scaling their gradients and Hessians during training.</p>
<ul>
<li>A higher value places <strong>more penalty on misclassifying positive samples</strong></li>
<li>This encourages the model to <strong>focus more on the minority class</strong>, helping improve recall and F1-score</li>
</ul>
</section>
<section id="when-to-use-it" class="level4" data-number="10.6.2.2">
<h4 data-number="10.6.2.2" class="anchored" data-anchor-id="when-to-use-it"><span class="header-section-number">10.6.2.2</span> When to Use It</h4>
<p>Use <code>scale_pos_weight &gt; 1</code> when:</p>
<ul>
<li>The dataset is <strong>heavily imbalanced</strong></li>
<li>You care more about the <strong>positive class performance</strong> (e.g., improving <strong>recall</strong>, <strong>precision</strong>, or <strong>F1-score</strong>)</li>
</ul>
</section>
</section>
<section id="how-to-set-it" class="level3" data-number="10.6.3">
<h3 data-number="10.6.3" class="anchored" data-anchor-id="how-to-set-it"><span class="header-section-number">10.6.3</span> How to Set It</h3>
<p>A commonly used heuristic:</p>
<p><span class="math display">\[
\text{scale\_pos\_weight} = \frac{\text{Number of negative samples}}{\text{Number of positive samples}}
\]</span></p>
<p>This provides a <strong>balanced gradient contribution</strong> during training and serves as a good <strong>starting point</strong>. You can further fine-tune this value via cross-validation for optimal performance.</p>
<p><strong>Note</strong>: While <code>scale_pos_weight</code> adjusts learning behavior internally, you should still monitor metrics like <strong>AUC-PR</strong>, <strong>F1-score</strong>, or <strong>recall</strong> to ensure it’s improving your model’s performance on the minority class.</p>
<div id="82a64bd9" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>diabetes_train <span class="op">=</span> pd.read_csv(<span class="st">'./Datasets/diabetes_train.csv'</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>diabetes_test <span class="op">=</span> pd.read_csv(<span class="st">'./Datasets/diabetes_test.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="5209b9e8" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(diabetes_train.shape, diabetes_test.shape)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>diabetes_train.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(614, 9) (154, 9)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="62">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Pregnancies</th>
<th data-quarto-table-cell-role="th">Glucose</th>
<th data-quarto-table-cell-role="th">BloodPressure</th>
<th data-quarto-table-cell-role="th">SkinThickness</th>
<th data-quarto-table-cell-role="th">Insulin</th>
<th data-quarto-table-cell-role="th">BMI</th>
<th data-quarto-table-cell-role="th">DiabetesPedigreeFunction</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2</td>
<td>88</td>
<td>74</td>
<td>19</td>
<td>53</td>
<td>29.0</td>
<td>0.229</td>
<td>22</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>129</td>
<td>84</td>
<td>0</td>
<td>0</td>
<td>28.0</td>
<td>0.284</td>
<td>27</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0</td>
<td>102</td>
<td>78</td>
<td>40</td>
<td>90</td>
<td>34.5</td>
<td>0.238</td>
<td>24</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0</td>
<td>123</td>
<td>72</td>
<td>0</td>
<td>0</td>
<td>36.3</td>
<td>0.258</td>
<td>52</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>144</td>
<td>82</td>
<td>46</td>
<td>180</td>
<td>46.1</td>
<td>0.335</td>
<td>46</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="261f1bc8" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check the outcome of the distribution in the training set and test set</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(diabetes_train[<span class="st">'Outcome'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(diabetes_test[<span class="st">'Outcome'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Outcome
0    0.662866
1    0.337134
Name: proportion, dtype: float64
Outcome
0    0.603896
1    0.396104
Name: proportion, dtype: float64</code></pre>
</div>
</div>
<div id="c3b00dc0" class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Preprocessing</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>X_diabetes <span class="op">=</span> diabetes_train.drop(columns<span class="op">=</span>[<span class="st">'Outcome'</span>])</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>y_diabetes <span class="op">=</span> diabetes_train[<span class="st">'Outcome'</span>]</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>X_diabetes_test <span class="op">=</span> diabetes_test.drop(columns<span class="op">=</span>[<span class="st">'Outcome'</span>])</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>y_diabetes_test <span class="op">=</span> diabetes_test[<span class="st">'Outcome'</span>]</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="co"># define categorical and numerical columns</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>categorical_cols_diabetes <span class="op">=</span> X_diabetes.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>]).columns.tolist()</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>numerical_cols_diabetes <span class="op">=</span> X_diabetes.select_dtypes(exclude<span class="op">=</span>[<span class="st">'object'</span>]).columns.tolist()</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co"># define the preprocessor, passing the numerical and categorical columns</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>preprocessor_diabetes <span class="op">=</span> ColumnTransformer(</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>    transformers<span class="op">=</span>[</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'num'</span>, <span class="st">'passthrough'</span>, numerical_cols_diabetes),  <span class="co"># no scaling</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'cat'</span>, OneHotEncoder(handle_unknown<span class="op">=</span><span class="st">'ignore'</span>), categorical_cols_diabetes)</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a pipeline for the diabetes dataset</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>diabetes_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor_diabetes),</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'regressor'</span>, XGBClassifier(random_state<span class="op">=</span><span class="dv">42</span>))</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the pipeline on the diabetes dataset</span></span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>diabetes_pipeline.fit(X_diabetes, y_diabetes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-3 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('preprocessor',
                 ColumnTransformer(transformers=[('num', 'passthrough',
                                                  ['Pregnancies', 'Glucose',
                                                   'BloodPressure',
                                                   'SkinThickness', 'Insulin',
                                                   'BMI',
                                                   'DiabetesPedigreeFunction',
                                                   'Age']),
                                                 ('cat',
                                                  OneHotEncoder(handle_unknown='ignore'),
                                                  [])])),
                ('regressor',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=None,
                               num_parallel_tree=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox"><label for="sk-estimator-id-9" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>Pipeline</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[('preprocessor',
                 ColumnTransformer(transformers=[('num', 'passthrough',
                                                  ['Pregnancies', 'Glucose',
                                                   'BloodPressure',
                                                   'SkinThickness', 'Insulin',
                                                   'BMI',
                                                   'DiabetesPedigreeFunction',
                                                   'Age']),
                                                 ('cat',
                                                  OneHotEncoder(handle_unknown='ignore'),
                                                  [])])),
                ('regressor',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=None,
                               num_parallel_tree=None, ...))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox"><label for="sk-estimator-id-10" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>preprocessor: ColumnTransformer</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class="sk-toggleable__content fitted"><pre>ColumnTransformer(transformers=[('num', 'passthrough',
                                 ['Pregnancies', 'Glucose', 'BloodPressure',
                                  'SkinThickness', 'Insulin', 'BMI',
                                  'DiabetesPedigreeFunction', 'Age']),
                                ('cat', OneHotEncoder(handle_unknown='ignore'),
                                 [])])</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-11" type="checkbox"><label for="sk-estimator-id-11" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>num</div></div></label><div class="sk-toggleable__content fitted"><pre>['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-12" type="checkbox"><label for="sk-estimator-id-12" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>passthrough</div></div></label><div class="sk-toggleable__content fitted"><pre>passthrough</pre></div> </div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-13" type="checkbox"><label for="sk-estimator-id-13" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>cat</div></div></label><div class="sk-toggleable__content fitted"><pre>[]</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-14" type="checkbox"><label for="sk-estimator-id-14" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>OneHotEncoder</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html">?<span>Documentation for OneHotEncoder</span></a></div></label><div class="sk-toggleable__content fitted"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div> </div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-15" type="checkbox"><label for="sk-estimator-id-15" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>XGBClassifier</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier">?<span>Documentation for XGBClassifier</span></a></div></label><div class="sk-toggleable__content fitted"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div>
</div>
</div>
<div id="3677a990" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make predictions on the test set</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">===== Test Performance with Default Setting ====="</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>y_diabetes_pred <span class="op">=</span> diabetes_pipeline.predict(X_diabetes_test)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate the model in terms of accuracy, precision, recall, and f1-score</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> np.mean(y_diabetes_pred <span class="op">==</span> y_diabetes_test)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy on Diabetes Test Set: </span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> precision_score(y_diabetes_test, y_diabetes_pred)</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision on Diabetes Test Set: </span><span class="sc">{</span>precision<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> recall_score(y_diabetes_test, y_diabetes_pred)</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall on Diabetes Test Set: </span><span class="sc">{</span>recall<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1_score(y_diabetes_test, y_diabetes_pred)</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1 Score on Diabetes Test Set: </span><span class="sc">{</span>f1<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
===== Test Performance with Default Setting =====
Accuracy on Diabetes Test Set: 0.73
Precision on Diabetes Test Set: 0.68
Recall on Diabetes Test Set: 0.59
F1 Score on Diabetes Test Set: 0.63</code></pre>
</div>
</div>
</section>
<section id="using-scale_pos_weight" class="level3" data-number="10.6.4">
<h3 data-number="10.6.4" class="anchored" data-anchor-id="using-scale_pos_weight"><span class="header-section-number">10.6.4</span> Using <code>scale_pos_weight</code></h3>
<div id="9292c568" class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>neg <span class="op">=</span> (diabetes_train[<span class="st">'Outcome'</span>] <span class="op">==</span> <span class="dv">0</span>).<span class="bu">sum</span>()</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> (diabetes_train[<span class="st">'Outcome'</span>] <span class="op">==</span> <span class="dv">1</span>).<span class="bu">sum</span>()</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>baseline_ratio <span class="op">=</span> neg <span class="op">/</span> pos</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co"># set a small grid for scale_pos_weight</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>scale_pos_weight <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>]</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new pipeline for the diabetes dataset</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>diabetes_pipeline_scale <span class="op">=</span> Pipeline([</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor_diabetes),</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'regressor'</span>, XGBClassifier(random_state<span class="op">=</span><span class="dv">42</span>))</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Store results for comparison</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>diabetes_results <span class="op">=</span> []</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, weight <span class="kw">in</span> <span class="bu">enumerate</span>(scale_pos_weight):</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Scale Pos Weight Test </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"scale_pos_weight = </span><span class="sc">{</span>weight<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update the pipeline with the scale_pos_weight parameter</span></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>    diabetes_pipeline_scale.set_params(regressor__scale_pos_weight<span class="op">=</span>weight)</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train and evaluate</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>    diabetes_pipeline_scale.fit(X_diabetes, y_diabetes)</span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>    y_diabetes_pred <span class="op">=</span> diabetes_pipeline_scale.predict(X_diabetes_test)</span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate the model</span></span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> np.mean(y_diabetes_pred <span class="op">==</span> y_diabetes_test)</span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a>    precision <span class="op">=</span> precision_score(y_diabetes_test, y_diabetes_pred)</span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a>    recall <span class="op">=</span> recall_score(y_diabetes_test, y_diabetes_pred)</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(y_diabetes_test, y_diabetes_pred)</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Store results</span></span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a>    diabetes_results.append({</span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">'test'</span>: i<span class="op">+</span><span class="dv">1</span>,</span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">'scale_pos_weight'</span>: weight,</span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a>        <span class="st">'accuracy'</span>: accuracy,</span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">'precision'</span>: precision,</span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">'recall'</span>: recall,</span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a>        <span class="st">'f1'</span>: f1</span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame for the results</span></span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a>diabetes_results_df <span class="op">=</span> pd.DataFrame(diabetes_results)   </span>
<span id="cb46-44"><a href="#cb46-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-45"><a href="#cb46-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the best scale_pos_weight based on F1 score</span></span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a>best_f1_idx <span class="op">=</span> diabetes_results_df[<span class="st">'f1'</span>].idxmax()</span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a>best_scale_pos_weight <span class="op">=</span> diabetes_results_df.loc[best_f1_idx, <span class="st">'scale_pos_weight'</span>]</span>
<span id="cb46-48"><a href="#cb46-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">===== Test Performance with Best Scale Pos Weight: ====="</span>)</span>
<span id="cb46-49"><a href="#cb46-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_scale_pos_weight)</span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best F1 Score: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(diabetes_results_df[<span class="st">'f1'</span>].<span class="bu">max</span>()))</span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a><span class="co"># find the accuracy, precision, and recall for the best scale_pos_weight</span></span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a>best_accuracy <span class="op">=</span> diabetes_results_df.loc[best_f1_idx, <span class="st">'accuracy'</span>]</span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a>best_precision <span class="op">=</span> diabetes_results_df.loc[best_f1_idx, <span class="st">'precision'</span>]</span>
<span id="cb46-54"><a href="#cb46-54" aria-hidden="true" tabindex="-1"></a>best_recall <span class="op">=</span> diabetes_results_df.loc[best_f1_idx, <span class="st">'recall'</span>]</span>
<span id="cb46-55"><a href="#cb46-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Accuracy: </span><span class="sc">{</span>best_accuracy<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb46-56"><a href="#cb46-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Precision: </span><span class="sc">{</span>best_precision<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb46-57"><a href="#cb46-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Recall: </span><span class="sc">{</span>best_recall<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Scale Pos Weight Test 1:
scale_pos_weight = 1

Scale Pos Weight Test 2:
scale_pos_weight = 2

Scale Pos Weight Test 3:
scale_pos_weight = 3

Scale Pos Weight Test 4:
scale_pos_weight = 5

Scale Pos Weight Test 5:
scale_pos_weight = 10

Best Scale Pos Weight:
3
Best F1 Score: 0.69
Best Accuracy: 0.76
Best Precision: 0.71
Best Recall: 0.67</code></pre>
</div>
</div>
<div id="828d54fd" class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the results for accuracy, precision, and recall with different colors</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>plt.plot(diabetes_results_df[<span class="st">'scale_pos_weight'</span>], diabetes_results_df[<span class="st">'accuracy'</span>], marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Accuracy'</span>)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>plt.plot(diabetes_results_df[<span class="st">'scale_pos_weight'</span>], diabetes_results_df[<span class="st">'precision'</span>], marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'orange'</span>, label<span class="op">=</span><span class="st">'Precision'</span>)</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>plt.plot(diabetes_results_df[<span class="st">'scale_pos_weight'</span>], diabetes_results_df[<span class="st">'recall'</span>], marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Recall'</span>)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Scale Pos Weight'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Score'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Effect of Scale Pos Weight on Accuracy, Precision, and Recall'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>plt.xticks(scale_pos_weight)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="XGBoost_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Tuning <code>scale_pos_weight</code> changes the <strong>model’s internal learning dynamics</strong>, not just the decision threshold. This allows the model to adjust how it learns from imbalanced data.</p>
<p>In this case, as <code>scale_pos_weight</code> increases from 1 to 3:</p>
<ul>
<li>XGBoost starts giving <strong>more importance to the minority (positive) class</strong>.</li>
<li>The model becomes better at identifying <strong>true positives</strong> → ✅ <strong>Recall increases</strong></li>
<li>Simultaneously, it avoids more <strong>false positives</strong> → ✅ <strong>Precision increases</strong></li>
</ul>
<p>✅ This indicates the model was previously <strong>underperforming on the positive class</strong>, and that moderate rebalancing (e.g., <code>scale_pos_weight = 3</code>) helped improve <strong>both recall and precision</strong> — something that can happen when the model is initially biased toward the majority class.</p>
</section>
<section id="threshold-adjustment" class="level3" data-number="10.6.5">
<h3 data-number="10.6.5" class="anchored" data-anchor-id="threshold-adjustment"><span class="header-section-number">10.6.5</span> Threshold adjustment</h3>
<div id="50d25e90" class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get prediction probabilities</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>y_diabetes_pred_proba <span class="op">=</span> diabetes_pipeline.predict_proba(X_diabetes_test)[:, <span class="dv">1</span>]</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the precision-recall curve</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>precision, recall, thresholds <span class="op">=</span> precision_recall_curve(y_diabetes_test, y_diabetes_pred_proba)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="co"># final threshold</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>f1_scores <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (precision <span class="op">*</span> recall) <span class="op">/</span> (precision <span class="op">+</span> recall <span class="op">+</span> <span class="fl">1e-9</span>) <span class="co"># avoid division by zero</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>best_f1_threshold <span class="op">=</span> thresholds[np.argmax(f1_scores)]</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>best_threshold <span class="op">=</span> np.<span class="bu">round</span>(best_f1_threshold, <span class="dv">2</span>)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Threshold for F1 Score: </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a><span class="co"># adjust the threshold for the predictions</span></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>y_diabetes_pred_adjusted <span class="op">=</span> (y_diabetes_pred_proba <span class="op">&gt;=</span> best_f1_threshold).astype(<span class="bu">int</span>)</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate the model with the adjusted threshold</span></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>accuracy_adjusted <span class="op">=</span> np.mean(y_diabetes_pred_adjusted <span class="op">==</span> y_diabetes_test)</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy with Adjusted Threshold: </span><span class="sc">{</span>accuracy_adjusted<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>precision_adjusted <span class="op">=</span> precision_score(y_diabetes_test, y_diabetes_pred_adjusted)</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision with Adjusted Threshold: </span><span class="sc">{</span>precision_adjusted<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>recall_adjusted <span class="op">=</span> recall_score(y_diabetes_test, y_diabetes_pred_adjusted)</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall with Adjusted Threshold: </span><span class="sc">{</span>recall_adjusted<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the precision-recall curve</span></span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>plt.plot(recall, precision, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Precision'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision-Recall Curve'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>recall[np.argmax(f1_scores)], color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Best Threshold'</span>)</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best Threshold for F1 Score: 0.19
Accuracy with Adjusted Threshold: 0.78
Precision with Adjusted Threshold: 0.68
Recall with Adjusted Threshold: 0.82</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="XGBoost_files/figure-html/cell-30-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="alternative-method-custom-instance-weights-sample_weight" class="level3" data-number="10.6.6">
<h3 data-number="10.6.6" class="anchored" data-anchor-id="alternative-method-custom-instance-weights-sample_weight"><span class="header-section-number">10.6.6</span> Alternative Method: Custom Instance Weights (<code>sample_weight</code>)</h3>
<p>You can assign <strong>custom weights to individual training samples</strong> using the <code>sample_weight</code> parameter in <code>fit()</code> (scikit-learn API) or <code>weight</code> in <code>DMatrix</code> (native API). This gives you <strong>fine-grained control</strong> over how much each sample contributes to the loss and gradient during training.</p>
<p>Example (scikit-learn API):</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign higher weights to positive class</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> np.where(y_train <span class="op">==</span> <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">1</span>)</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> XGBClassifier()</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train, sample_weight<span class="op">=</span>weights)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>When to Use This:</strong></p>
<ul>
<li><p>When you want more flexibility than scale_pos_weight allows</p></li>
<li><p>When the imbalance is complex (e.g., multi-class or cost-sensitive)</p></li>
<li><p>When you want to incorporate domain knowledge into weight assignments</p></li>
</ul>
</section>
<section id="scale_pos_weight-vs.-sample_weight" class="level3" data-number="10.6.7">
<h3 data-number="10.6.7" class="anchored" data-anchor-id="scale_pos_weight-vs.-sample_weight"><span class="header-section-number">10.6.7</span> <code>scale_pos_weight</code> vs.&nbsp;<code>sample_weight</code></h3>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 44%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Feature</strong></th>
<th><strong><code>scale_pos_weight</code></strong></th>
<th><strong><code>sample_weight</code></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Applies to</strong></td>
<td>Entire positive class (<code>label = 1</code>)</td>
<td>Individual samples</td>
</tr>
<tr class="even">
<td><strong>How it works</strong></td>
<td>Multiplies gradients and Hessians of the positive class during training</td>
<td>Directly scales the loss function per instance</td>
</tr>
<tr class="odd">
<td><strong>Use case</strong></td>
<td>Binary classification with class imbalance</td>
<td>Any situation needing custom weighting (e.g., multi-class, domain-driven)</td>
</tr>
<tr class="even">
<td><strong>Flexibility</strong></td>
<td>One global weight value</td>
<td>Full per-sample control</td>
</tr>
<tr class="odd">
<td><strong>Where to set</strong></td>
<td><code>scale_pos_weight</code> parameter in <code>XGBClassifier</code> or <code>DMatrix</code></td>
<td><code>sample_weight</code> in <code>.fit()</code> or <code>weight=</code> in <code>DMatrix</code></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="resources-for-learning-xgboost" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="resources-for-learning-xgboost"><span class="header-section-number">10.7</span> Resources for Learning XGBoost</h2>
<p>The foundational paper is:</p>
<p><strong>XGBoost: A Scalable Tree Boosting System</strong><br>
<em>Authors</em>: Tianqi Chen and Carlos Guestrin<br>
<em>Conference</em>: KDD 2016<br>
<a href="https://arxiv.org/abs/1603.02754">Link to paper (PDF)</a><br>
<a href="https://doi.org/10.1145/2939672.2939785">DOI: 10.1145/2939672.2939785</a></p>
<p>XGBoost is a relatively recent algorithm (2016), and thus not yet included in many standard textbooks. Below are helpful learning resources:</p>
<ul>
<li><a href="https://xgboost.readthedocs.io/en/stable/python/python_api.html">Documentation</a></li>
<li><a href="https://files.speakerdeck.com/presentations/5c6dab45648344208185d2b1ab4fdc95/XGBoost-Newest.pdf">Slides by Tianqi Chen</a></li>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/2939672.2939785">Reference Paper</a></li>
<li><a href="https://www.youtube.com/watch?v=Vly8xGnNiWs">Video by Tianqi Chen (author)</a></li>
<li><a href="https://www.youtube.com/watch?v=OtD8wVaFm6E">StatQuest Video Explanation</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Gradient_Boosting.html" class="pagination-link" aria-label="Gradient Boosting">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gradient Boosting</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./LightGBM_CatBoost.html" class="pagination-link" aria-label="LightGBM and CatBoost">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">LightGBM and CatBoost</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>