{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b6569ab",
   "metadata": {},
   "source": [
    "## Ensemble modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f819f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold\n",
    "from sklearn.ensemble import VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier, GradientBoostingRegressor,GradientBoostingClassifier, BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import itertools as it\n",
    "import time as time\n",
    "import xgboost as xgb\n",
    "from pyearth import Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9036ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carID</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18473</td>\n",
       "      <td>bmw</td>\n",
       "      <td>6 Series</td>\n",
       "      <td>2020</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>11</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>53.3282</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15064</td>\n",
       "      <td>bmw</td>\n",
       "      <td>6 Series</td>\n",
       "      <td>2019</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>10813</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>53.0430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18268</td>\n",
       "      <td>bmw</td>\n",
       "      <td>6 Series</td>\n",
       "      <td>2020</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>6</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>53.4379</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18480</td>\n",
       "      <td>bmw</td>\n",
       "      <td>6 Series</td>\n",
       "      <td>2017</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>18895</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>51.5140</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18492</td>\n",
       "      <td>bmw</td>\n",
       "      <td>6 Series</td>\n",
       "      <td>2015</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>62953</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>160</td>\n",
       "      <td>51.4903</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carID brand      model  year transmission  mileage fuelType  tax      mpg  \\\n",
       "0  18473   bmw   6 Series  2020    Semi-Auto       11   Diesel  145  53.3282   \n",
       "1  15064   bmw   6 Series  2019    Semi-Auto    10813   Diesel  145  53.0430   \n",
       "2  18268   bmw   6 Series  2020    Semi-Auto        6   Diesel  145  53.4379   \n",
       "3  18480   bmw   6 Series  2017    Semi-Auto    18895   Diesel  145  51.5140   \n",
       "4  18492   bmw   6 Series  2015    Automatic    62953   Diesel  160  51.4903   \n",
       "\n",
       "   engineSize  price  \n",
       "0         3.0  37980  \n",
       "1         3.0  33980  \n",
       "2         3.0  36850  \n",
       "3         3.0  25998  \n",
       "4         3.0  18990  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the same datsasets as used for linear regression in STAT303-2, \n",
    "#so that we can compare the non-linear models with linear regression\n",
    "trainf = pd.read_csv('./Datasets/Car_features_train.csv')\n",
    "trainp = pd.read_csv('./Datasets/Car_prices_train.csv')\n",
    "testf = pd.read_csv('./Datasets/Car_features_test.csv')\n",
    "testp = pd.read_csv('./Datasets/Car_prices_test.csv')\n",
    "train = pd.merge(trainf,trainp)\n",
    "test = pd.merge(testf,testp)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6b5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['mileage','mpg','year','engineSize']]\n",
    "Xtest = test[['mileage','mpg','year','engineSize']]\n",
    "y = train['price']\n",
    "ytest = test['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bb4c98",
   "metadata": {},
   "source": [
    "### Voting Regressor\n",
    "Here, we will combine the predictions of different models. The function `VotingRegressor()` averages the predictions of all the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528559d6",
   "metadata": {},
   "source": [
    "Below are the individual models tuned in the previous chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f241c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for XGBoost =  5533.09714940882\n",
      "RMSE for AdaBoost =  5693.165811600585\n",
      "RMSE for Random forest =  5642.45839697972\n",
      "RMSE for Gradient Boosting =  5405.787029062213\n"
     ]
    }
   ],
   "source": [
    "# Tuned XGBoost model \n",
    "m1 = xgb.XGBRegressor(random_state=1,max_depth=6,n_estimators=1000,gamma=1,\n",
    "                                         learning_rate = 0.01,reg_lambda=0.001).fit(X, y)\n",
    "print(\"RMSE for XGBoost = \", np.sqrt(mean_squared_error(m1.predict(Xtest), ytest)))\n",
    "\n",
    "\n",
    "m2 = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=10),n_estimators=50,learning_rate=1.0,\n",
    "                         random_state=1).fit(X, y)\n",
    "print(\"RMSE for AdaBoost = \", np.sqrt(mean_squared_error(m2.predict(Xtest), ytest)))\n",
    "\n",
    "\n",
    "m3 = RandomForestRegressor(n_estimators=300, random_state=1,\n",
    "                        n_jobs=-1, max_features=2).fit(X, y)\n",
    "print(\"RMSE for Random forest = \", np.sqrt(mean_squared_error(m3.predict(Xtest), ytest)))\n",
    "\n",
    "\n",
    "m4 = GradientBoostingRegressor(max_depth=8,n_estimators=100,learning_rate=0.1,\n",
    "                         random_state=1,loss='huber').fit(X, y)\n",
    "print(\"RMSE for Gradient Boosting = \", np.sqrt(mean_squared_error(m4.predict(Xtest), ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "360b4748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model RMSE =  5356.19553079535\n"
     ]
    }
   ],
   "source": [
    "# Combining models that have been tuned individually\n",
    "m1 = xgb.XGBRegressor(random_state=1,max_depth=6,n_estimators=1000,gamma=1,\n",
    "                                         learning_rate = 0.01,reg_lambda=0.001)\n",
    "m2 = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=10),n_estimators=50,learning_rate=1.0,\n",
    "                         random_state=1)\n",
    "m3 = RandomForestRegressor(n_estimators=300, random_state=1,\n",
    "                        n_jobs=-1, max_features=2)\n",
    "m4 = GradientBoostingRegressor(max_depth=8,n_estimators=100,learning_rate=0.1,\n",
    "                         random_state=1,loss='huber')\n",
    "en=VotingRegressor(estimators = [('xgb',m1),('ada',m2),('rf',m3),('gb',m4)])\n",
    "en.fit(X,y)\n",
    "print(\"Ensemble model RMSE = \", np.sqrt(mean_squared_error(en.predict(Xtest),ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aeaea6",
   "metadata": {},
   "source": [
    "### Stacking Regressor\n",
    "Stacking is a more sophisticated method of ensembling models. The method is as follows:\n",
    "\n",
    "1. The training data is split into *K* folds. Each of the *K* folds serves as a test data in one of the *K* iterations, and the rest of the folds serve as train data. \n",
    "\n",
    "2. Each model is used to make predictions on each of the *K* folds, after being trainined on the remaining *K-1* folds. In this manner, each model predicts the response on each train data point - when that train data point was not used to train the model.\n",
    "\n",
    "3. Predictions at each training data points are generated by each model in step 2 (the above step). These predictions are now used as predictors to train a meta-model (referred by the argument *final_estimator*), with the original response as the response. The meta-model (or *final_estimator*) learns to combine predictions of differnt models to make a better prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1551cf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model RMSE =  5311.051612697244\n"
     ]
    }
   ],
   "source": [
    "#Stacking using LinearRegression as the meta-model\n",
    "en=StackingRegressor(estimators = [('xgb',m1),('ada',m2),('rf',m3),('gb',m4)],\n",
    "                     final_estimator=LinearRegression(),                                          \n",
    "                    cv = KFold(n_splits = 5, shuffle = True, random_state=1))\n",
    "en.fit(X,y)\n",
    "print(\"Ensemble model RMSE = \", np.sqrt(mean_squared_error(en.predict(Xtest),ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fdff36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1754083 , 0.28344251, 0.11715329, 0.44980934])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en.final_estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc823e84",
   "metadata": {},
   "source": [
    "Note the above coefficients of the meta-model. The model gives the highest weight to the gradient boosing model, and the lowest weight to the random forest model. Also, note that the coefficients need not sum to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "85ed301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model RMSE =  5310.481811320582\n"
     ]
    }
   ],
   "source": [
    "#Stacking using Lasso as the meta-model\n",
    "en=StackingRegressor(estimators = [('xgb',m1),('ada',m2),('rf',m3),('gb',m4)],\n",
    "                     final_estimator=LassoCV(),                                          \n",
    "                    cv = KFold(n_splits = 5, shuffle = True, random_state=1))\n",
    "en.fit(X,y)\n",
    "print(\"Ensemble model RMSE = \", np.sqrt(mean_squared_error(en.predict(Xtest),ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "404a2480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17639973, 0.28186944, 0.1152561 , 0.45119952])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en.final_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "228eac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model RMSE =  5303.308982301974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akl0407\\Anaconda3\\lib\\site-packages\\pyearth\\earth.py:813: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  pruning_passer.run()\n",
      "C:\\Users\\akl0407\\Anaconda3\\lib\\site-packages\\pyearth\\earth.py:1066: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  coef, resid = np.linalg.lstsq(B, weighted_y[:, i])[0:2]\n"
     ]
    }
   ],
   "source": [
    "#Stacking using MARS as the meta-model\n",
    "en=StackingRegressor(estimators = [('xgb',m1),('ada',m2),('rf',m3),('gb',m4)],\n",
    "                     final_estimator=Earth(max_degree=1),                                          \n",
    "                    cv = KFold(n_splits = 5, shuffle = True, random_state=1))\n",
    "en.fit(X,y)\n",
    "print(\"Ensemble model RMSE = \", np.sqrt(mean_squared_error(en.predict(Xtest),ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c8d3c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earth Model\n",
      "-------------------------------------\n",
      "Basis Function  Pruned  Coefficient  \n",
      "-------------------------------------\n",
      "(Intercept)     No      59644        \n",
      "h(x3-75435)     No      0.402779     \n",
      "h(75435-x3)     No      -0.406517    \n",
      "h(x1-74988)     No      0.822699     \n",
      "h(74988-x1)     No      -0.119104    \n",
      "h(x2-72702.8)   No      -0.449716    \n",
      "h(72702.8-x2)   No      -0.280938    \n",
      "x0              No      0.211986     \n",
      "-------------------------------------\n",
      "MSE: 25038308.7322, GCV: 25226136.6357, RSQ: 0.9070, GRSQ: 0.9063\n"
     ]
    }
   ],
   "source": [
    "print(en.final_estimator_.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a0392a",
   "metadata": {},
   "source": [
    "# XGBoost for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82a64bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  \\\n",
       "0   63    1       typical     145   233    1        2    150      0      2.3   \n",
       "1   67    1  asymptomatic     160   286    0        2    108      1      1.5   \n",
       "2   67    1  asymptomatic     120   229    0        2    129      1      2.6   \n",
       "3   37    1    nonanginal     130   250    0        0    187      0      3.5   \n",
       "4   41    0    nontypical     130   204    0        2    172      0      1.4   \n",
       "\n",
       "   Slope   Ca        Thal  AHD  \n",
       "0      3  0.0       fixed   No  \n",
       "1      2  3.0      normal  Yes  \n",
       "2      2  2.0  reversable  Yes  \n",
       "3      3  0.0      normal   No  \n",
       "4      1  0.0      normal   No  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Heart.csv')\n",
    "data.dropna(inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad7fa6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>asymptomatic</th>\n",
       "      <th>nonanginal</th>\n",
       "      <th>nontypical</th>\n",
       "      <th>typical</th>\n",
       "      <th>fixed</th>\n",
       "      <th>normal</th>\n",
       "      <th>reversable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  Slope   Ca  \\\n",
       "0   63    1     145   233    1        2    150      0      2.3      3  0.0   \n",
       "1   67    1     160   286    0        2    108      1      1.5      2  3.0   \n",
       "2   67    1     120   229    0        2    129      1      2.6      2  2.0   \n",
       "3   37    1     130   250    0        0    187      0      3.5      3  0.0   \n",
       "4   41    0     130   204    0        2    172      0      1.4      1  0.0   \n",
       "\n",
       "   asymptomatic  nonanginal  nontypical  typical  fixed  normal  reversable  \n",
       "0             0           0           0        1      1       0           0  \n",
       "1             1           0           0        0      0       1           0  \n",
       "2             1           0           0        0      0       0           1  \n",
       "3             0           1           0        0      0       1           0  \n",
       "4             0           0           1        0      0       1           0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Response variable\n",
    "y = pd.get_dummies(data['AHD'])['Yes']\n",
    "\n",
    "#Creating a dataframe for predictors with dummy varibles replacing the categorical variables\n",
    "X = data.drop(columns = ['AHD','ChestPain','Thal'])\n",
    "X = pd.concat([X,pd.get_dummies(data['ChestPain']),pd.get_dummies(data['Thal'])],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec2149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train and test datasets\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,train_size = 0.5,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e17635af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.871494 using {'base_estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 0.01, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(random_state=1)\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100,200,500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01,0.1, 1.0]\n",
    "grid['base_estimator'] = [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), \n",
    "                          DecisionTreeClassifier(max_depth=3),DecisionTreeClassifier(max_depth=4)]\n",
    "# define the evaluation procedure\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',refit='accuracy')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(Xtrain, ytrain)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "#    print(\"%f (%f) with: %r\" % (mean, stdev, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "195131ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.871954 using {'learning_rate': 1.0, 'max_depth': 4, 'n_estimators': 100, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=1)\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100,200,500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01,0.1, 1.0]\n",
    "grid['max_depth'] = [1,2,3,4,5]\n",
    "grid['subsample'] = [0.5,1.0]\n",
    "# define the evaluation procedure\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',refit='accuracy')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(Xtrain, ytrain)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "#    print(\"%f (%f) with: %r\" % (mean, stdev, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a88754",
   "metadata": {},
   "source": [
    "XGBoost has an additional parameter for classification: **scale_pos_weight**\n",
    "\n",
    "Gradients are used as the basis for fitting subsequent trees added to boost or correct errors made by the existing state of the ensemble of decision trees.\n",
    "\n",
    "The scale_pos_weight value is used to scale the gradient for the positive class.\n",
    "\n",
    "This has the effect of scaling errors made by the model during training on the positive class and encourages the model to over-correct them. In turn, this can help the model achieve better performance when making predictions on the positive class. Pushed too far, it may result in the model overfitting the positive class at the cost of worse performance on the negative class or both classes.\n",
    "\n",
    "As such, the scale_pos_weight can be used to train a class-weighted or cost-sensitive version of XGBoost for imbalanced classification.\n",
    "\n",
    "A sensible default value to set for the scale_pos_weight hyperparameter is the inverse of the class distribution. For example, for a dataset with a 1 to 100 ratio for examples in the minority to majority classes, the scale_pos_weight can be set to 100. This will give classification errors made by the model on the minority class (positive class) 100 times more impact, and in turn, 100 times more correction than errors made on the majority class.\n",
    "\n",
    "Ref:https://machinelearningmastery.com/xgboost-for-imbalanced-classification/#:~:text=The%20scale_pos_weight%20value%20is%20used,model%20to%20over%2Dcorrect%20them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "94b14915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "[22:00:02] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'gamma': 0.25, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 25, 'reg_lambda': 0.01, 'scale_pos_weight': 1.5} 0.872183908045977\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "param_grid = {'n_estimators':[25,100,500],\n",
    "                'max_depth': [6,7,8],\n",
    "              'learning_rate': [0.01,0.1,0.2],\n",
    "               'gamma': [0.1,0.25,0.5],\n",
    "               'reg_lambda':[0,0.01,0.001],\n",
    "                'scale_pos_weight':[1.25,1.5,1.75]#Control the balance of positive and negative weights, useful for unbalanced classes. A typical value to consider: sum(negative instances) / sum(positive instances).\n",
    "             }\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "optimal_params = GridSearchCV(estimator=xgb.XGBClassifier(objective = 'binary:logistic',random_state=1,\n",
    "                                                         use_label_encoder=False),\n",
    "                             param_grid = param_grid,\n",
    "                             scoring = 'accuracy',\n",
    "                             verbose = 1,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv)\n",
    "optimal_params.fit(Xtrain,ytrain)\n",
    "print(optimal_params.best_params_,optimal_params.best_score_)\n",
    "print(\"Time taken = \", (time.time()-start_time)/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8fef62d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_scale_pos_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.111135</td>\n",
       "      <td>0.017064</td>\n",
       "      <td>0.005629</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.5</td>\n",
       "      <td>{'gamma': 0.25, 'learning_rate': 0.2, 'max_dep...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.872184</td>\n",
       "      <td>0.05656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.215781</td>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>{'gamma': 0.1, 'learning_rate': 0.2, 'max_dept...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.865517</td>\n",
       "      <td>0.05874</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1.391273</td>\n",
       "      <td>0.107808</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>{'gamma': 0.25, 'learning_rate': 0.01, 'max_de...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.865517</td>\n",
       "      <td>0.05874</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1.247463</td>\n",
       "      <td>0.053597</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.75</td>\n",
       "      <td>{'gamma': 0.25, 'learning_rate': 0.01, 'max_de...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.865517</td>\n",
       "      <td>0.05874</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1.394361</td>\n",
       "      <td>0.087307</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.75</td>\n",
       "      <td>{'gamma': 0.25, 'learning_rate': 0.01, 'max_de...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.865517</td>\n",
       "      <td>0.05874</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_gamma  \\\n",
       "409       0.111135      0.017064         0.005629        0.000737        0.25   \n",
       "226       0.215781      0.007873         0.005534        0.001615         0.1   \n",
       "290       1.391273      0.107808         0.007723        0.006286        0.25   \n",
       "266       1.247463      0.053597         0.006830        0.002728        0.25   \n",
       "269       1.394361      0.087307         0.005530        0.001718        0.25   \n",
       "\n",
       "    param_learning_rate param_max_depth param_n_estimators param_reg_lambda  \\\n",
       "409                 0.2               6                 25             0.01   \n",
       "226                 0.2               8                100                0   \n",
       "290                0.01               7                500                0   \n",
       "266                0.01               6                500             0.01   \n",
       "269                0.01               6                500            0.001   \n",
       "\n",
       "    param_scale_pos_weight                                             params  \\\n",
       "409                    1.5  {'gamma': 0.25, 'learning_rate': 0.2, 'max_dep...   \n",
       "226                    1.5  {'gamma': 0.1, 'learning_rate': 0.2, 'max_dept...   \n",
       "290                   1.75  {'gamma': 0.25, 'learning_rate': 0.01, 'max_de...   \n",
       "266                   1.75  {'gamma': 0.25, 'learning_rate': 0.01, 'max_de...   \n",
       "269                   1.75  {'gamma': 0.25, 'learning_rate': 0.01, 'max_de...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  \\\n",
       "409           0.866667           0.766667                0.9   \n",
       "226           0.833333           0.766667                0.9   \n",
       "290           0.833333           0.766667                0.9   \n",
       "266           0.833333           0.766667                0.9   \n",
       "269           0.833333           0.766667                0.9   \n",
       "\n",
       "     split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "409           0.931034           0.896552         0.872184         0.05656   \n",
       "226           0.931034           0.896552         0.865517         0.05874   \n",
       "290           0.931034           0.896552         0.865517         0.05874   \n",
       "266           0.931034           0.896552         0.865517         0.05874   \n",
       "269           0.931034           0.896552         0.865517         0.05874   \n",
       "\n",
       "     rank_test_score  \n",
       "409                1  \n",
       "226                2  \n",
       "290                2  \n",
       "266                2  \n",
       "269                2  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results=pd.DataFrame(optimal_params.cv_results_)\n",
    "cv_results.sort_values(by = 'mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10f29424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute confusion matrix and prediction accuracy on test/train data\n",
    "def confusion_matrix_data(data,actual_values,model,cutoff=0.5):\n",
    "#Predict the values using the Logit model\n",
    "    pred_values = model.predict_proba(data)[:,1]\n",
    "# Specify the bins\n",
    "    bins=np.array([0,cutoff,1])\n",
    "#Confusion matrix\n",
    "    cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n",
    "    cm_df = pd.DataFrame(cm)\n",
    "    cm_df.columns = ['Predicted 0','Predicted 1']\n",
    "    cm_df = cm_df.rename(index={0: 'Actual 0',1:'Actual 1'})\n",
    "# Calculate the accuracy\n",
    "    accuracy = 100*(cm[0,0]+cm[1,1])/cm.sum()\n",
    "    fnr = 100*(cm[1,0])/(cm[1,0]+cm[1,1])\n",
    "    precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n",
    "    fpr = 100*(cm[0,1])/(cm[0,0]+cm[0,1])\n",
    "    tpr = 100*(cm[1,1])/(cm[1,0]+cm[1,1])\n",
    "    print(\"Accuracy = \", accuracy)\n",
    "    print(\"Precision = \", precision)\n",
    "    print(\"FNR = \", fnr)\n",
    "    print(\"FPR = \", fpr)\n",
    "    print(\"TPR or Recall = \", tpr)\n",
    "    print(\"Confusion matrix = \\n\", cm_df)\n",
    "    return (\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "233bfb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7718120805369127"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = xgb.XGBClassifier(objective = 'binary:logistic',random_state=1,gamma=0.25,learning_rate = 0.01,max_depth=6,\n",
    "                              n_estimators = 500,reg_lambda = 0.01,scale_pos_weight=1.75,use_label_encoder=False)\n",
    "model4.fit(Xtrain,ytrain,eval_metric='error')\n",
    "model4.score(Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065421a",
   "metadata": {},
   "source": [
    "If we increase the value of *scale_pos_weight*, the model will focus on classifying positives more correctly. This will increase the recall (true positive rate) since the focus is on identifying all positives. However, this will lead to identifying positives aggresively, and observations 'similar' to observations of the positive class will also be predicted as positive resulting in an increase in false positives and a decrease in precision. See the trend below as we increase the value of *scale_pos_weight*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb89598a",
   "metadata": {},
   "source": [
    "## Precision & recall vs scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f4bc610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0 0.00 (0.00)\n",
      ">1 0.77 (0.13)\n",
      ">10 0.81 (0.09)\n",
      ">100 0.85 (0.11)\n",
      ">1000 0.85 (0.10)\n",
      ">10000 0.90 (0.06)\n",
      ">100000 0.90 (0.08)\n",
      ">1000000 0.90 (0.06)\n",
      ">10000000 0.91 (0.10)\n",
      ">100000000 0.96 (0.03)\n",
      ">1000000000 1.00 (0.00)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25a2695bc10>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    # explore learning rates from 0.1 to 2 in 0.1 increments\n",
    "    for i in [0,1,10,1e2,1e3,1e4,1e5,1e6,1e7,1e8,1e9]:\n",
    "        key = '%.0f' % i\n",
    "        models[key] = xgb.XGBClassifier(objective = 'binary:logistic',scale_pos_weight=i,random_state=1)\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores_recall = cross_val_score(model, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "    scores_precision = cross_val_score(model, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "    return list([scores_recall,scores_precision])\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results_recall, results_precision, names = list(), list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    scores_recall = scores[0]\n",
    "    scores_precision = scores[1]\n",
    "    # store the results\n",
    "    results_recall.append(scores_recall)\n",
    "    results_precision.append(scores_precision)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.2f (%.2f)' % (name, np.mean(scores_recall), np.std(scores_recall)))\n",
    "# plot model performance for comparison\n",
    "plt.figure(figsize=(7, 7))\n",
    "sns.set(font_scale = 1.5)\n",
    "pdata = pd.DataFrame(results_precision)\n",
    "pdata.columns = list(['p1','p2','p3','p4','p5'])\n",
    "pdata['metric'] = 'precision'\n",
    "rdata = pd.DataFrame(results_recall)\n",
    "rdata.columns = list(['p1','p2','p3','p4','p5'])\n",
    "rdata['metric'] = 'recall'\n",
    "pr_data = pd.concat([pdata,rdata])\n",
    "pr_data.reset_index(drop=False,inplace= True)\n",
    "#sns.boxplot(x=\"day\", y=\"total_bill\", hue=\"time\",pr_data=tips, linewidth=2.5)\n",
    "pr_data_melt=pr_data.melt(id_vars = ['index','metric'])\n",
    "pr_data_melt['index']=pr_data_melt['index']-1\n",
    "pr_data_melt['index'] = pr_data_melt['index'].astype('str')\n",
    "pr_data_melt.replace(to_replace='-1',value =  '-inf',inplace=True)\n",
    "sns.boxplot(x='index', y=\"value\", hue=\"metric\", data=pr_data_melt, linewidth=2.5)\n",
    "plt.xlabel('$log_{10}$(scale_pos_weight)',fontsize=15)\n",
    "plt.ylabel('Precision / Recall ',fontsize=15)\n",
    "plt.legend(loc=\"lower right\", frameon=True, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "54ccc812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:52:56] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Adaboost accuracy =  0.7986577181208053\n",
      "Random forest accuracy =  0.8120805369127517\n",
      "Gradient boost accuracy =  0.7986577181208053\n",
      "XGBoost model accuracy =  0.7718120805369127\n"
     ]
    }
   ],
   "source": [
    "#Adaboost \n",
    "model_ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=200, \n",
    "                               random_state=1,learning_rate=0.01).fit(Xtrain, ytrain)    \n",
    "test_accuracy=model_ada.score(Xtest,ytest) #Returns the classification accuracy of the model on test data\n",
    "    \n",
    "#Random forest\n",
    "model_rf = RandomForestClassifier(n_estimators=500, random_state=1,max_features=3,\n",
    "                        n_jobs=-1,oob_score=False).fit(Xtrain, ytrain)\n",
    "test_accuracy2=model_rf.score(Xtest,ytest) #Returns the classification accuracy of the model on test data\n",
    "    \n",
    "#Gradient boost\n",
    "model_gb = GradientBoostingClassifier(n_estimators=100, random_state=1,max_depth=4,learning_rate=1.0).fit(Xtrain, ytrain)\n",
    "test_accuracy3=model_gb.score(Xtest,ytest) #Returns the classification accuracy of the model on test data\n",
    "\n",
    "#XGBoost\n",
    "model_xgb = xgb.XGBClassifier(objective = 'binary:logistic',random_state=1,gamma=0.25,learning_rate = 0.01,max_depth=6,\n",
    "                              n_estimators = 500,reg_lambda = 0.01,scale_pos_weight=1.75,\n",
    "                           use_label_encoder=False).fit(Xtrain,ytrain)\n",
    "test_accuracy4=model_xgb.score(Xtest,ytest) #Returns the classification accuracy of the model on test data\n",
    "\n",
    "print(\"Adaboost accuracy = \",test_accuracy)\n",
    "print(\"Random forest accuracy = \",test_accuracy2)\n",
    "print(\"Gradient boost accuracy = \",test_accuracy3)\n",
    "print(\"XGBoost model accuracy = \",test_accuracy4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd653a7",
   "metadata": {},
   "source": [
    "## Ensemble modeling\n",
    "### Voting classifier - hard voting\n",
    "In this type of ensembling, the predicted class is the one predicted by the majority of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d30cc7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8322147651006712"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adaboost \n",
    "model_ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=200, \n",
    "                               random_state=1,learning_rate=0.01)   \n",
    "    \n",
    "#Random forest\n",
    "model_rf = RandomForestClassifier(n_estimators=500, random_state=1,max_features=3,\n",
    "                        n_jobs=-1,oob_score=False)\n",
    "    \n",
    "#Gradient boost\n",
    "model_gb = GradientBoostingClassifier(n_estimators=100, random_state=1,max_depth=4,learning_rate=1.0)\n",
    "\n",
    "#XGBoost\n",
    "model_xgb = xgb.XGBClassifier(objective = 'binary:logistic',random_state=1,gamma=0.25,learning_rate = 0.01,max_depth=6,\n",
    "                              n_estimators = 500,reg_lambda = 0.01,scale_pos_weight=1.75,\n",
    "                           use_label_encoder=False,eval_metric='error')\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[('ada',model_ada),('rf',model_rf),('gb',model_gb),('xgb',model_xgb)])\n",
    "ensemble_model.fit(Xtrain,ytrain)\n",
    "np.mean(ensemble_model.predict(Xtest)==ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5915b57",
   "metadata": {},
   "source": [
    "Note that the prediction accuracy of the ensemble is higher than the prediction accuracy of each of the individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a5d02",
   "metadata": {},
   "source": [
    "### Voting classifier - soft voting\n",
    "In this type of ensembling, the predicted class is the one based on the average predicted probabilities of all the classifiers. The threshold probabiltiy is 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e7c0f301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7919463087248322"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model = VotingClassifier(estimators=[('ada',model_ada),('rf',model_rf),('gb',model_gb),('xgb',model_xgb)],\n",
    "                                 voting='soft')\n",
    "ensemble_model.fit(Xtrain,ytrain)\n",
    "np.mean(ensemble_model.predict(Xtest)==ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c70bed",
   "metadata": {},
   "source": [
    "Note that soft voting will be good only for well calibrate classifiers, i.e., all the classifiers must have probabilities at the same scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4c3f4",
   "metadata": {},
   "source": [
    "### Stacking classifier\n",
    "Conceptually, the idea is similar to that of Stacking regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "20cd5cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986577181208053"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Logistic regression as the meta model (final_estimator)\n",
    "ensemble_model = StackingClassifier(estimators=[('ada',model_ada),('rf',model_rf),('gb',model_gb),('xgb',model_xgb)],\n",
    "                                   final_estimator=LogisticRegression(random_state=1,max_iter=10000),n_jobs=-1,\n",
    "                                   cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1))\n",
    "ensemble_model.fit(Xtrain,ytrain)\n",
    "np.mean(ensemble_model.predict(Xtest)==ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b48ecdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8416763 , 1.35885574, 1.68328219, 1.38872517]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model.final_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "57693cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825503355704698"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using random forests as the meta model (final_estimator). Note that random forest will require tuning\n",
    "ensemble_model = StackingClassifier(estimators=[('ada',model_ada),('rf',model_rf),('gb',model_gb),('xgb',model_xgb)],\n",
    "                                   final_estimator=RandomForestClassifier(n_estimators=500, max_features=1,\n",
    "                                                                          random_state=1,oob_score=True),n_jobs=-1,\n",
    "                                   cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1))\n",
    "ensemble_model.fit(Xtrain,ytrain)\n",
    "np.mean(ensemble_model.predict(Xtest)==ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd67695",
   "metadata": {},
   "source": [
    "Note that a complex *final_estimator* such as random forest will require tuning. In the above case, the *max_features* argument of random forests has been tuned to obtain the maximum OOB score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7bf18e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8581081081081081"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The final predictor - random forest obtains the maximum oob_score for max_features = 1\n",
    "ensemble_model.final_estimator_.oob_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
