{
 "cells": [
  {
   "cell_type": "raw",
   "id": "577166cb",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Introduction to Scikit-learn\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "    toc-depth: 4\n",
    "    jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb5a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ebb681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn has 100s of models - grouped in sublibraries, such as linear_model\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "# sklearn also has many tools for cleaning/processing data, also grouped in sublibraries\n",
    "from sklearn.model_selection import train_test_split # splitting one dataset into train and test\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1312e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Datasets/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54976ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the predictors and response - THIS IS HOW ALL SKLEARN OBJECTS ACCEPT DATA (different from statsmodels)\n",
    "y = data.Outcome\n",
    "X = data.drop(\"Outcome\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f52dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and test data\n",
    "    # 80-20 split, which is usual - 70-30 split is also fine, 90-10 is fine if the dataset is large\n",
    "    # random_state to set a random seed for the splitting - reproducible results\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 45)\n",
    "# stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608e8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With linear/logistic regression in scikit-learn, especially when the predictors have different orders \n",
    "# of magn., scaling is necessary. This is to enable the training algo. which we did not cover. (Gradient Descent)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # Do NOT refit the scaler with the test data, just transform it.\n",
    "\n",
    "X_train = X_train_scaled \n",
    "X_test = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33a0c14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.37662337662337\n"
     ]
    }
   ],
   "source": [
    "# Create a model - not trained yet\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Test the model - prediction - two ways to go\n",
    "y_pred = logreg.predict(X_test) # Get the predicted classes first\n",
    "print(accuracy_score(y_pred, y_test)*100) # Use the predicted and true classes for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac6e6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.37662337662337\n"
     ]
    }
   ],
   "source": [
    "print(logreg.score(X_test, y_test)*100) # Use .score with test predictors and response to get the accuracy\n",
    "                                            # Implements the same thing under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f9b8266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32572891  1.20110566 -0.32046591  0.06849882 -0.21727131  0.72619528\n",
      "   0.40088897  0.29698818]]\n"
     ]
    }
   ],
   "source": [
    "print(logreg.coef_) # Use coef_ to return the coefficients - only log reg inference you can do with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee3c53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87 17]\n",
      " [24 26]]\n",
      "0.6046511627906976\n",
      "0.52\n"
     ]
    }
   ],
   "source": [
    "# all metrics exist in sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "\n",
    "# What we covered today:\n",
    "    # A recap of Log. Reg. with sklearn\n",
    "        # Separate the predictors and response (if necessary)\n",
    "        # Split the data into train and test (if necessary)\n",
    "        \n",
    "        # Create a model\n",
    "        # Train with .fit\n",
    "        # Predict with .predict or get the accuracy with .score\n",
    "        # Use sklearn metrics with y_pred and y_test\n",
    "\n",
    "\n",
    "        # Same idea with LinearRegression()\n",
    "        # .score returns r-squared by default\n",
    "        # use the appropriate metrics!\n",
    "\n",
    "\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b92389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78 26]\n",
      " [15 35]]\n",
      "0.5737704918032787\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "# More details on the LogisticRegression model:\n",
    "    # Inputs - for regularization and \n",
    "    # prediction prob.s instead of classes - so we can change the thresholds\n",
    "    \n",
    "# .predict_proba returns the prob.s for both classes\n",
    "    # Two cols for two classes\n",
    "    # Apply your threshold to y_pred_probs[1] (second col)\n",
    "y_pred_probs = logreg.predict_proba(X_test)    \n",
    "\n",
    "cutoff = 0.3\n",
    "\n",
    "y_pred2 = y_pred_probs[:,1] > cutoff\n",
    "y_pred2 = y_pred2.astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print(precision_score(y_test, y_pred2))\n",
    "print(recall_score(y_test, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab2d2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.37662337662337\n"
     ]
    }
   ],
   "source": [
    "# Throughout the course, we will create many different models in sklearn, all of them will have\n",
    "    # .fit\n",
    "    # .predict\n",
    "    # .score\n",
    "    # .predict_proba\n",
    "# methods, among others that are specific to them. Make sure how to use there 4 basic ones.\n",
    "\n",
    "# Let's take a look at the documentation - always do this for the other models we will see\n",
    "# Log Reg model has default regularization\n",
    "    # Default (regularization) penalty is \"l2\" - this means Ridge \n",
    "    # C is 1/lambda - remember that lambda is the hyperparameter that is multiplied with the ridge penalty\n",
    "        # C is 1 by default\n",
    "        \n",
    "# Let's take away the regularization\n",
    "logreg2 = LogisticRegression(C=1e10)\n",
    "logreg2.fit(X_train, y_train)\n",
    "y_pred = logreg2.predict(X_test) # Get the predicted classes first\n",
    "print(accuracy_score(y_pred, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "057a53b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.53246753246754\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy stayed the same - reg was not very necessary\n",
    "\n",
    "# Too much reg\n",
    "logreg2 = LogisticRegression(C=1e-10)\n",
    "logreg2.fit(X_train, y_train)\n",
    "y_pred = logreg2.predict(X_test) # Get the predicted classes first\n",
    "print(accuracy_score(y_pred, y_test)*100)\n",
    "\n",
    "# Test accuracy is even lower - too much reg caused underfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fea0c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The key to take full advantage of sklearn models is their inputs\n",
    "    # Always read the doc\n",
    "    # In Log Reg, you can switch to Lasso with penalty = 'l1' - for variable selection\n",
    "    # For no regression, besides what we did above, you can use penalty = None\n",
    "    \n",
    "# Recall that C, or lambda, is a hyperparameter, which is optimized with cross-validation\n",
    "    # There is LogisticRegressionCV, just like LassoCV and RidgeCV\n",
    "    # Works the exact same way - check LassoCV and RidgeCV notes\n",
    "    \n",
    "# For all the sklearn models we will create in this course, there will be hyperparameters.\n",
    "    # Mostly more than one for each model\n",
    "    # These hyperparameters will determine how much regularization the model will have\n",
    "    # These models will not have a CV version\n",
    "    # So, we need to use two sklearn tools that implement cross-validation\n",
    "        # cross_val_score - now\n",
    "        # GridSearchCV - later when we get to trees and tree-based models\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "val_scores = []\n",
    "\n",
    "hyperparam_vals = 10**np.linspace(-5, 10)\n",
    "\n",
    "for c_val in hyperparam_vals: # For each possible C value in your grid\n",
    "    logreg_model = LogisticRegression(C=c_val) # Create a model with the C value\n",
    "    \n",
    "    val_scores.append(cross_val_score(logreg_model, X_train, y_train, scoring='accuracy', cv=5)) # Find the cv results\n",
    "    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hyperparam_vals, np.mean(np.array(val_scores), axis=1))\n",
    "plt.xlabel('possible C value')\n",
    "plt.ylabel('avg 5-fold CV value')\n",
    "plt.xscale('log')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Train the best model with the hyperparam val that returns the highest average accuracy\n",
    "logreg_model_best = LogisticRegression(C=hyperparam_vals[np.argmax(np.mean(np.array(val_scores), axis=1))])\n",
    "\n",
    "# .fit\n",
    "# .predict & .predict_proba\n",
    "# .score\n",
    "# ...\n",
    "\n",
    "# Log. reg. has one hyperparameter - C.\n",
    "# More complex models will have more\n",
    "# If we have two hyperparams - we can use a nested loop and cross_val_score\n",
    "    # or we can use GridSearchCV - more on that when we get to trees and tree-based models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
