{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bd972c94",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Assignment 3 (Section 21)\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "    number-sections: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a5837",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity. \n",
    "\n",
    "2. Write your code in the *Code* cells and your answer in the *Markdown* cells of the Jupyter notebook. Ensure that the solution is written neatly enough to understand and grade.\n",
    "\n",
    "3. Use [Quarto](https://quarto.org/docs/output-formats/html-basics.html) to print the *.ipynb* file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: `quarto render filename.ipynb --to html`. Submit the HTML file.\n",
    "\n",
    "4. The assignment is worth 100 points, and is due on **Wednesday, 8th May 2024 at 11:59 pm**. \n",
    "\n",
    "5. **Five points are properly formatting the assignment**. The breakdown is as follows:\n",
    "- Must be an HTML file rendered using Quarto (2 pts). *If you have a Quarto issue, you must mention the issue & quote the error you get when rendering using Quarto in the comments section of Canvas, and submit the ipynb file. If your issue doesn't seem genuine, you will lose points.* \n",
    "- There aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.) (1 pt)\n",
    "- Final answers of each question are written in Markdown cells (1 pt).\n",
    "- There is no piece of unnecessary / redundant code, and no unnecessary / redundant text (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b697b3",
   "metadata": {},
   "source": [
    "## 1) Regression Problem - Miami housing\n",
    "### 1a) Data preparation\n",
    "Read the data *miami-housing.csv*. Check the description of the variables [here](https://www.kaggle.com/datasets/deepcontractor/miami-housing-dataset). Split the data into 60% train and 40% test. Use `random_state = 45`. The response is `SALE_PRC`, and the rest of the columns are predictors, except `PARCELNO`. Print the shape of the predictors dataframe of the train data.\n",
    "\n",
    "*(2 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a34ecb",
   "metadata": {},
   "source": [
    "### 1b) Decision tree\n",
    "Develop a decision tree model to predict `SALE_PRC` based on all the predictors. Use `random_state = 45`. Use the default hyperparameter values. What is the MAE (mean absolute error) on test data? \n",
    "\n",
    "*(3 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c453b",
   "metadata": {},
   "source": [
    "### 1c) Tuning decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f63a7d",
   "metadata": {},
   "source": [
    "Tune the hyperparameters of the decision tree model developed in the previous question, and compute the MAE on test data. You must tune the hyperparameters in the following manner:\n",
    " \n",
    "The cross-validated MAE obtained must be less than $68,000. You must show the optimal values of the hyperparameters obtained, and the find the test MAE with the tuned model.\n",
    "\n",
    "**Hint:** \n",
    "\n",
    "1. BayesSearchCV() may take less than a minute with `max_depth` and `max_features`\n",
    "2. You are free to decide which hyperparameters to tune.\n",
    "\n",
    "*(9 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f19055",
   "metadata": {},
   "source": [
    "### 1d) Bagging decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a41cd8",
   "metadata": {},
   "source": [
    "Bag decision trees, and compute the out-of-bag MAE. Use enough number of trees, such that the MAE stabilizes. Other than `n_estimators`, use default values of hyperparameters.\n",
    "\n",
    "The out-of-bag cross-validated MAE must be less than $48,000.\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392f662",
   "metadata": {},
   "source": [
    "### 1e) Bagging without bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4be1b",
   "metadata": {},
   "source": [
    "Bag decision trees without bootstrapping, i.e., put `bootstrap = False` while bagging the trees, and compute the cross-valdiated MAE. Why is the MAE obtained much higher than that in the previous question, but lower than that obtained in [C.1.2](https://nustat.github.io/STAT303-3-class-notes/Assignment%20C.html#decision-tree)?\n",
    "\n",
    "*(1 point for code, 3 + 3 points for reasoning)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02bf9ed",
   "metadata": {},
   "source": [
    "### 1f) Bagging without bootstrapping samples, but bootstrapping features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31eb6d",
   "metadata": {},
   "source": [
    "Bag decision trees without bootstrapping samplse, but bootstrapping features, i.e., put `bootstrap = False`, and `bootstrap_features = True` while bagging the trees, and compute the cross-validated MAE. Why is the MAE obtained much lower than that in the previous question?\n",
    "\n",
    "*(1 point for code, 3 points for reasoning)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06644b7",
   "metadata": {},
   "source": [
    "### 1g) Tuning bagged tree model\n",
    "#### 1g)i) Approaches\n",
    "\n",
    "There are two approaches for tuning a bagged tree model:\n",
    "\n",
    "1. Out of bag prediction\n",
    "\n",
    "2. $K$-fold cross validation using `GridSearchCV`.\n",
    "\n",
    "What is the advantage of each approach over the other, i.e., what is the advantage of the out-of-bag approach over $K$-fold cross validation, and what is the advantage of $K$-fold cross validation over the out-of-bag approach?\n",
    "\n",
    "*(3 + 3 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75312e3c",
   "metadata": {},
   "source": [
    "#### 1g)ii) Tuning the hyperparameters\n",
    "\n",
    "Tune the hyperparameters of the bagged tree model developed in [C.1.4](https://nustat.github.io/STAT303-3-class-notes/Assignment%20C.html#bagging-decision-trees). You may use either of the approaches mentioned in the previous question. Show the optimal values of the hyperparameters obtained. Compute the MAE on test data with the tuned model. Your cross-validated MAE must be less than the cross-validate MAE ontained in the previous question.\n",
    "\n",
    "It is up to you to pick the hyperparameters and their values in the grid.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "`GridSearchCV()` may work better than `BayesSearchCV()` in this case. Why?\n",
    "\n",
    "*(9 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad011c83",
   "metadata": {},
   "source": [
    "### 1h) Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3982732e",
   "metadata": {},
   "source": [
    "#### 1h)(i) Tuning random forest\n",
    "Tune a random forest model to predict `SALE_PRC`, and compute the MAE on test data. The cross-validated MAE must be less than $46,000.\n",
    "\n",
    "It is up to you to pick the hyperparameters and their values in the grid.\n",
    "\n",
    "**Hint:** OOB approach will take less than a minute.\n",
    "\n",
    "*(9 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18e636",
   "metadata": {},
   "source": [
    "#### 1h)(ii) Feature importance\n",
    "Arrange and print the predictors in decreasing order of importance.\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5748ff9e",
   "metadata": {},
   "source": [
    "#### 1h)(iii) Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556f599",
   "metadata": {},
   "source": [
    "Drop the least important predictor, and find the cross-validated MAE of the tuned model again. You may need to adjust the `max_features` hyperparameter to account for the dropped predictor. Did the cross-validate MAE reduce?\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0e973d",
   "metadata": {},
   "source": [
    "#### 1h)(iv) Random forest vs bagging: `max_features` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4211a1",
   "metadata": {},
   "source": [
    "Note that the `max_features` hyperparameter is there both in the `RandomForestRegressor()` function and the `BaggingRegressor()` function. Does it have the same meaning in both the functions? If not, then what is the difference?\n",
    "\n",
    "**Hint:** Check scikit-learn documentation\n",
    "\n",
    "*(1 + 3 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ae154",
   "metadata": {},
   "source": [
    "## 2) Classification - Term deposit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b9e803",
   "metadata": {},
   "source": [
    "The data for this question is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls, where bank clients were called to subscribe for a term deposit. \n",
    "\n",
    "There is a train data - *train.csv*, which you will use to develop a model. There is a test data - *test.csv*, which you will use to test your model. Each dataset has the following attributes about the clients called in the marketing campaign:\n",
    "\n",
    "1. `age`: Age of the client\n",
    "\n",
    "2. `education`: Education level of the client \n",
    "\n",
    "3. `day`: Day of the month the call is made\n",
    "\n",
    "4. `month`: Month of the call \n",
    "\n",
    "5. `y`: did the client subscribe to a term deposit? \n",
    "\n",
    "6. `duration`: Call duration, in seconds. This attribute highly affects the output target (e.g., if `duration`=0 then `y`='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call `y` is obviously known. Thus, this input should only be included for inference purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "(Raw data source: [Source](https://archive.ics.uci.edu/ml/datasets/bank+marketing). Do not use the raw data source for this assignment. It is just for reference.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2b007",
   "metadata": {},
   "source": [
    "### 2a) Data preparation\n",
    "Convert all the categorical predictors in the data to dummy variables. Note that `month` and `education` are categorical variables.\n",
    "\n",
    "*(2 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a078d",
   "metadata": {},
   "source": [
    "### 2b) Random forest\n",
    "Develop and tune a **random forest model** to predict the probability of a client subscribing to a term deposit based on `age`, `education`, `day` and `month`. The model must have: \n",
    "\n",
    "(a)  **Minimum overall classification accuracy of 75%** among the classification accuracies on *train.csv*, and *test.csv*. \n",
    "\n",
    "(b) **Minimum recall of 60%** among the recall on *train.csv*, and *test.csv*. \n",
    "\n",
    "Print the accuracy and recall for both the datasets - *train.csv*, and *test.csv*.\n",
    "\n",
    "Note that: \n",
    "\n",
    "i. You cannot use `duration` as a predictor. The predictor is not useful for prediction because its value is determined after the marketing call ends. However, after the call ends, we already know whether the client responded positively or negatively. \n",
    "\n",
    "ii. You are free to choose any value of threshold probability for classifying observations. However, you must use the same threshold on both the datasets.\n",
    "\n",
    "iii. Use cross-validation on train data to optimize the model hyperparameters.\n",
    "\n",
    "iv. Using the optimal model hyperparameters obtained in (iii), develop the decision tree model. Plot the cross-validated accuracy and recall against decision threshold probability. Tune the decision threshold probability based on the plot, or the data underlying the plot to achieve the required trade-off between recall and accuracy.\n",
    "\n",
    "v. Evaluate the accuracy and recall of the developed model with the tuned decision threshold probability on both the datasets. Note that the test dataset must only be used to evaluate performance metrics, and not optimize any hyperparameters or decision threshold probability.\n",
    "\n",
    "*(22 points - 8 points for tuning the hyperparameters, 5 points for making the plot, 5 points for tuning the decision threshold probability based on the plot, and 4 points for printing the accuracy & recall on both the datasets)*\n",
    "\n",
    "**Hint:** \n",
    "\n",
    "1. Restrict the search for `max_depth` to a maximum of 25, and `max_leaf_nodes` to a maximum of 45. Without this restriction, you may get a better recall for threshold probability = 0.5, but are likely to get a worse trade-off between recall and accuracy. Tune `max_features`, `max_depth`, and `max_leaf_nodes` with OOB cross-validation.\n",
    "\n",
    "2. Use `oob_decision_function_` for OOB cross-validated probabilities.\n",
    "\n",
    "It is up to you to pick the hyperparameters and their values in the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c867ae27",
   "metadata": {},
   "source": [
    "## 3) Predictor transformations in trees\n",
    "Can a non-linear monotonic transformation of predictors (such as *log(), sqrt()* etc.) be useful in improving the accuracy of decision tree models?\n",
    "\n",
    "*(4 points for answer)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
