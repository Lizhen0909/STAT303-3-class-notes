<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>9&nbsp; Gradient Boosting – Data Science III with python (Class notes)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Lec9_XGBoost.html" rel="next">
<link href="./adaboost.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-8da5b4427184b79ecddefad3d342027e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./regression_tree_sp25.html">Tree based models</a></li><li class="breadcrumb-item"><a href="./Gradient_Boosting.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gradient Boosting</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="https://statistics.northwestern.edu/" class="sidebar-logo-link">
      <img src="./NU_Stat_logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science III with python (Class notes)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Bias &amp; Variance; KNN</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Bias_variance_code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Bias-variance tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./KNN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">KNN</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Hyperparameter tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Hyperparameter tuning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Tree based models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression_tree_sp25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Classification _Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Classification trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bagging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Bagging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./random_forest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Random Forests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./adaboost.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Adaptive Boosting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Gradient_Boosting.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gradient Boosting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec9_XGBoost.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">XGBoost</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec11_More boosting models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">LightGBM and CatBoost</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec10_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Ensemble modeling</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment1_sp25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Assignment 1</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment2_sp25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Assignment 2</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment3_sp25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Assignment 3</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Datasets, assignment and project files</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#core-hyperparameters-in-gradient-boosting" id="toc-core-hyperparameters-in-gradient-boosting" class="nav-link active" data-scroll-target="#core-hyperparameters-in-gradient-boosting"><span class="header-section-number">9.1</span> Core Hyperparameters in Gradient Boosting</a>
  <ul>
  <li><a href="#effect-of-number-of-trees-on-cross-validation-error" id="toc-effect-of-number-of-trees-on-cross-validation-error" class="nav-link" data-scroll-target="#effect-of-number-of-trees-on-cross-validation-error"><span class="header-section-number">9.1.1</span> Effect of Number of Trees on Cross-Validation Error</a></li>
  <li><a href="#early-stopping-in-gradient-boosting" id="toc-early-stopping-in-gradient-boosting" class="nav-link" data-scroll-target="#early-stopping-in-gradient-boosting"><span class="header-section-number">9.1.2</span> Early stopping in Gradient Boosting</a></li>
  <li><a href="#effect-of-learning-rate-on-cross-validation-error" id="toc-effect-of-learning-rate-on-cross-validation-error" class="nav-link" data-scroll-target="#effect-of-learning-rate-on-cross-validation-error"><span class="header-section-number">9.1.3</span> Effect of Learning Rate on Cross-Validation Error</a></li>
  <li><a href="#learning-rate-and-number-of-trees-are-closely-linked" id="toc-learning-rate-and-number-of-trees-are-closely-linked" class="nav-link" data-scroll-target="#learning-rate-and-number-of-trees-are-closely-linked"><span class="header-section-number">9.1.4</span> Learning Rate and Number of Trees Are Closely Linked</a></li>
  <li><a href="#effect-of-stochastic-gradient-boosting-on-cross-validation-error" id="toc-effect-of-stochastic-gradient-boosting-on-cross-validation-error" class="nav-link" data-scroll-target="#effect-of-stochastic-gradient-boosting-on-cross-validation-error"><span class="header-section-number">9.1.5</span> Effect of Stochastic Gradient Boosting on Cross-Validation Error</a></li>
  <li><a href="#effect-of-tree-complexity-on-cross-validation-error-not-tuned-here" id="toc-effect-of-tree-complexity-on-cross-validation-error-not-tuned-here" class="nav-link" data-scroll-target="#effect-of-tree-complexity-on-cross-validation-error-not-tuned-here"><span class="header-section-number">9.1.6</span> Effect of Tree Complexity on Cross-Validation Error (Not Tuned Here)</a></li>
  <li><a href="#loss-function-loss" id="toc-loss-function-loss" class="nav-link" data-scroll-target="#loss-function-loss"><span class="header-section-number">9.1.7</span> Loss Function (<code>loss</code>)</a></li>
  </ul></li>
  <li><a href="#joint-hyperparameter-tuning-in-gradient-boosting-for-regression" id="toc-joint-hyperparameter-tuning-in-gradient-boosting-for-regression" class="nav-link" data-scroll-target="#joint-hyperparameter-tuning-in-gradient-boosting-for-regression"><span class="header-section-number">9.2</span> Joint Hyperparameter Tuning in Gradient Boosting for Regression</a>
  <ul>
  <li><a href="#using-bayessearchcv" id="toc-using-bayessearchcv" class="nav-link" data-scroll-target="#using-bayessearchcv"><span class="header-section-number">9.2.1</span> Using <code>BayesSearchCV</code></a></li>
  <li><a href="#tuning-with-optuna" id="toc-tuning-with-optuna" class="nav-link" data-scroll-target="#tuning-with-optuna"><span class="header-section-number">9.2.2</span> Tuning with Optuna</a></li>
  </ul></li>
  <li><a href="#scaling-gradient-boosting-for-large-datasets-and-smarter-tuning" id="toc-scaling-gradient-boosting-for-large-datasets-and-smarter-tuning" class="nav-link" data-scroll-target="#scaling-gradient-boosting-for-large-datasets-and-smarter-tuning"><span class="header-section-number">9.3</span> Scaling Gradient Boosting for Large Datasets and Smarter Tuning</a></li>
  <li><a href="#independent-study" id="toc-independent-study" class="nav-link" data-scroll-target="#independent-study"><span class="header-section-number">9.4</span> Independent Study</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./regression_tree_sp25.html">Tree based models</a></li><li class="breadcrumb-item"><a href="./Gradient_Boosting.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gradient Boosting</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gradient Boosting</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><em>Check the gradient boosting algorithm in section 10.10.2 of the book, <a href="https://hastie.su.domains/ElemStatLearn/">Elements of Statistical Learning</a> before using these notes.</em></p>
<p><em>Note that in this course, lecture notes are not sufficient, you must read the book for better understanding. Lecture notes are just implementing the concepts of the book on a dataset, but not explaining the concepts elaborately.</em></p>
<section id="core-hyperparameters-in-gradient-boosting" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="core-hyperparameters-in-gradient-boosting"><span class="header-section-number">9.1</span> Core Hyperparameters in Gradient Boosting</h2>
<ol type="1">
<li><p><strong>Number of Trees</strong> (<code>n_estimators</code>)</p>
<ul>
<li>Use <strong>early stopping</strong> (via <code>n_iter_no_change</code> and <code>validation_fraction</code> in scikit-learn) to avoid overfitting.<br>
</li>
<li>Start with a large value (e.g., 500–1000) and let early stopping prune unnecessary trees.</li>
</ul></li>
<li><p><strong>Early Stopping</strong></p>
<ul>
<li>Prevents overfitting by halting training once the validation performance stops improving.<br>
</li>
<li>Controlled using:
<ul>
<li><code>n_iter_no_change</code>: Number of rounds with no improvement before stopping (e.g., 10).</li>
<li><code>validation_fraction</code>: Fraction of training data reserved as internal validation set (e.g., 0.1).</li>
<li><code>tol</code>: Minimum improvement to be considered significant (e.g., <code>1e-4</code>).</li>
</ul></li>
<li>Set a large <code>n_estimators</code>, and let early stopping determine the optimal number of boosting iterations.</li>
</ul></li>
<li><p><strong>Learning Rate</strong> (<code>learning_rate</code>)</p>
<ul>
<li>Shrinks the contribution of each tree to improve generalization.<br>
</li>
<li><em>Typical range</em>: 0.01–0.2 (lower values require more trees).</li>
</ul></li>
<li><p><strong>Tree Complexity</strong></p>
<ul>
<li><code>max_depth</code>: Depth of individual trees. Start shallow (3–6) to limit overfitting.<br>
</li>
<li><code>min_samples_split</code>: Minimum samples required to split a node (e.g., 10–50).<br>
</li>
<li><code>min_samples_leaf</code>: Minimum samples required in a leaf node (e.g., 5–20).</li>
</ul></li>
<li><p><strong>Stochastic Gradient Boosting</strong></p>
<ul>
<li><code>subsample</code>: Fraction of training data sampled per tree (e.g., 0.5–1.0).<br>
</li>
<li><code>max_features</code>: Fraction/absolute number of features used per split (e.g., <code>sqrt(n_features)</code> or <code>0.8</code>).</li>
</ul></li>
<li><p><strong>Loss Function</strong> (<code>loss</code>)</p>
<ul>
<li>Matches the problem type:
<ul>
<li>Regression: <code>squared_error</code>, <code>absolute_error</code></li>
<li>Classification: <code>log_loss</code> (binary/multinomial deviance)</li>
</ul></li>
</ul></li>
</ol>
<div id="f819f995" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score,train_test_split, KFold, cross_val_predict</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> root_mean_squared_error, mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve, accuracy_score, <span class="op">\</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>recall_score, precision_score, confusion_matrix</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor,DecisionTreeClassifier</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV, ParameterGrid, StratifiedKFold</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor,GradientBoostingClassifier, BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder, FunctionTransformer</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools <span class="im">as</span> it</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time <span class="im">as</span> time</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt <span class="im">import</span> BayesSearchCV</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt.space <span class="im">import</span> Real, Categorical, Integer</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt.plots <span class="im">import</span> plot_objective, plot_histogram, plot_convergence</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython <span class="im">import</span> display</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s reuse the car dataset to evaluate how different hyperparameter settings affect the performance of gradient boosting</p>
<div id="a9036ef3" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>car <span class="op">=</span> pd.read_csv(<span class="st">'Datasets/car.csv'</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>car.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">brand</th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">transmission</th>
<th data-quarto-table-cell-role="th">mileage</th>
<th data-quarto-table-cell-role="th">fuelType</th>
<th data-quarto-table-cell-role="th">tax</th>
<th data-quarto-table-cell-role="th">mpg</th>
<th data-quarto-table-cell-role="th">engineSize</th>
<th data-quarto-table-cell-role="th">price</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>vw</td>
<td>Beetle</td>
<td>2014</td>
<td>Manual</td>
<td>55457</td>
<td>Diesel</td>
<td>30</td>
<td>65.3266</td>
<td>1.6</td>
<td>7490</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>vauxhall</td>
<td>GTC</td>
<td>2017</td>
<td>Manual</td>
<td>15630</td>
<td>Petrol</td>
<td>145</td>
<td>47.2049</td>
<td>1.4</td>
<td>10998</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>merc</td>
<td>G Class</td>
<td>2012</td>
<td>Automatic</td>
<td>43000</td>
<td>Diesel</td>
<td>570</td>
<td>25.1172</td>
<td>3.0</td>
<td>44990</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>audi</td>
<td>RS5</td>
<td>2019</td>
<td>Automatic</td>
<td>10</td>
<td>Petrol</td>
<td>145</td>
<td>30.5593</td>
<td>2.9</td>
<td>51990</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>merc</td>
<td>X-CLASS</td>
<td>2018</td>
<td>Automatic</td>
<td>14000</td>
<td>Diesel</td>
<td>240</td>
<td>35.7168</td>
<td>2.3</td>
<td>28990</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="db6b5f99" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> car.drop(columns<span class="op">=</span>[<span class="st">'price'</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> car[<span class="st">'price'</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the categorical columns and put them in a list</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>categorical_feature <span class="op">=</span> X.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>]).columns.tolist()</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the numerical columns and put them in a list</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>numerical_feature <span class="op">=</span> X.select_dtypes(include<span class="op">=</span>[<span class="st">'int64'</span>, <span class="st">'float64'</span>]).columns.tolist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c7d5fb7e" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OneHotEncoder(handle_unknown<span class="op">=</span><span class="st">'ignore'</span>, sparse_output<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>X_train_encoded <span class="op">=</span> encoder.fit_transform(X_train[categorical_feature])</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>X_test_encoded <span class="op">=</span> encoder.transform(X_test[categorical_feature])</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the encoded features back to DataFrame</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>X_train_encoded_df <span class="op">=</span> pd.DataFrame(X_train_encoded, columns<span class="op">=</span>encoder.get_feature_names_out(categorical_feature))</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>X_test_encoded_df <span class="op">=</span> pd.DataFrame(X_test_encoded, columns<span class="op">=</span>encoder.get_feature_names_out(categorical_feature))</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Concatenate the encoded features with the original numerical features</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>X_train_final <span class="op">=</span> pd.concat([X_train_encoded_df, X_train[numerical_feature].reset_index(drop<span class="op">=</span><span class="va">True</span>)], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>X_test_final <span class="op">=</span> pd.concat([X_test_encoded_df, X_test[numerical_feature].reset_index(drop<span class="op">=</span><span class="va">True</span>)], axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="effect-of-number-of-trees-on-cross-validation-error" class="level3" data-number="9.1.1">
<h3 data-number="9.1.1" class="anchored" data-anchor-id="effect-of-number-of-trees-on-cross-validation-error"><span class="header-section-number">9.1.1</span> Effect of Number of Trees on Cross-Validation Error</h3>
<p>Effect of Number of Trees on Cross-Validation Error In Gradient Boosting, the number of trees (<code>n_estimators</code>) controls how many boosting rounds the model performs. Adding more trees can reduce bias and improve training accuracy, but it also increases the risk of overfitting, especially with a high learning rate.</p>
<p>The optimal number of trees is often found by balancing <strong>model complexity</strong> and <strong>generalization performance</strong> using cross-validation.</p>
<div id="452c9c3a" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_models():</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    models <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># define number of trees to consider</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    n_trees <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>, <span class="dv">2000</span>, <span class="dv">5000</span>]</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n <span class="kw">in</span> n_trees:</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        models[<span class="bu">str</span>(n)] <span class="op">=</span> GradientBoostingRegressor(n_estimators<span class="op">=</span>n,random_state<span class="op">=</span><span class="dv">1</span>,loss<span class="op">=</span><span class="st">'huber'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> models</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate a given model using cross-validation</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model, X, y):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># define the evaluation procedure</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># evaluate the model and collect the results</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> np.sqrt(<span class="op">-</span>cross_val_score(model, X, y, scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, cv<span class="op">=</span>cv, n_jobs<span class="op">=-</span><span class="dv">1</span>))</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> scores</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># get the models to evaluate</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> get_models()</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate the models and store results</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>results, names <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, model <span class="kw">in</span> models.items():</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># evaluate the model</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> evaluate_model(model, X_train_final, y_train)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store the results</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    results.append(scores)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    names.append(name)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># summarize the performance along the way</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'&gt;</span><span class="sc">%s</span><span class="st"> </span><span class="sc">%.3f</span><span class="st"> (</span><span class="sc">%.3f</span><span class="st">)'</span> <span class="op">%</span> (name, np.mean(scores), np.std(scores)))</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co"># plot model performance for comparison</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>plt.boxplot(results, labels<span class="op">=</span>names, showmeans<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Cross validation error'</span>,fontsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of trees'</span>,fontsize<span class="op">=</span><span class="dv">15</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt;2 14769.612 (563.444)
&gt;5 12572.047 (567.992)
&gt;10 10383.351 (555.641)
&gt;50 6549.576 (722.462)
&gt;100 5232.949 (656.216)
&gt;500 3419.467 (262.753)
&gt;1000 3106.002 (184.799)
&gt;2000 3194.874 (293.134)
&gt;5000 3272.374 (380.296)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Gradient_Boosting_files/figure-html/cell-6-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="early-stopping-in-gradient-boosting" class="level3" data-number="9.1.2">
<h3 data-number="9.1.2" class="anchored" data-anchor-id="early-stopping-in-gradient-boosting"><span class="header-section-number">9.1.2</span> Early stopping in Gradient Boosting</h3>
<p><strong>Early stopping</strong> is a regularization technique used to prevent overfitting in boosting models. Instead of specifying a fixed number of trees (<code>n_estimators</code>), the algorithm monitors performance on a <strong>validation set</strong> and stops adding new trees once the model’s improvement has plateaued.</p>
<p>In scikit-learn, early stopping can be enabled using: - <code>early_stopping=True</code> - <code>validation_fraction</code>: The fraction of training data used as a validation set - <code>n_iter_no_change</code>: Number of iterations to wait without improvement before stopping</p>
<p>This approach not only improves generalization but also reduces training time by avoiding unnecessary trees.</p>
<div id="2231df15" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> <span class="bu">dict</span>(n_estimators<span class="op">=</span><span class="dv">2000</span>, max_depth<span class="op">=</span><span class="dv">5</span>, learning_rate<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>gbm_full <span class="op">=</span> GradientBoostingRegressor(<span class="op">**</span>params)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>gbm_early_stopping <span class="op">=</span> GradientBoostingRegressor(</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>params,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    validation_fraction<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    n_iter_no_change<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>gbm_full.fit(X_train_final, y_train)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>training_time_full <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>n_estimators_full <span class="op">=</span> gbm_full.n_estimators_</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>gbm_early_stopping.fit(X_train_final, y_train)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>training_time_early_stopping <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>estimators_early_stopping <span class="op">=</span> gbm_early_stopping.n_estimators_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s calculate the RMSE on both the training and test datasets for each model, which will be used for later visualization.</p>
<div id="cabba68f" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import root mean squared error function</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> root_mean_squared_error</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>train_errors_without <span class="op">=</span> []</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>test_errors_without <span class="op">=</span> []</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>train_errors_with <span class="op">=</span> []</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>test_errors_with <span class="op">=</span> []</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (train_pred, test_pred) <span class="kw">in</span> <span class="bu">enumerate</span>(</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">zip</span>(</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        gbm_full.staged_predict(X_train_final),</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        gbm_full.staged_predict(X_test_final),</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    train_errors_without.append(root_mean_squared_error(y_train, train_pred))</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    test_errors_without.append(root_mean_squared_error(y_test, test_pred))</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (train_pred, test_pred) <span class="kw">in</span> <span class="bu">enumerate</span>(</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">zip</span>(</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        gbm_early_stopping.staged_predict(X_train_final),</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        gbm_early_stopping.staged_predict(X_test_final),</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    train_errors_with.append(root_mean_squared_error(y_train, train_pred))</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    test_errors_with.append(root_mean_squared_error(y_test, test_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s visulize Comparison. It includes three subplots:</p>
<ol type="1">
<li>Plotting training errors of both models over boosting iterations.</li>
<li>Plotting test errors of both models over boosting iterations.</li>
<li>Creating a bar chart to compare the training times and the number of estimators used by the models with and without early stopping.</li>
</ol>
<div id="784add04" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(train_errors_without, label<span class="op">=</span><span class="st">"gbm_full"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(train_errors_with, label<span class="op">=</span><span class="st">"gbm_early_stopping"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">"Boosting Iterations"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">"RMSE (Training)"</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_yscale(<span class="st">"log"</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"Training Error"</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(test_errors_without, label<span class="op">=</span><span class="st">"gbm_full"</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(test_errors_with, label<span class="op">=</span><span class="st">"gbm_early_stopping"</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">"Boosting Iterations"</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">"RMSE (Test)"</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_yscale(<span class="st">"log"</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">"Test Error"</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>training_times <span class="op">=</span> [training_time_full, training_time_early_stopping]</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">"gbm_full"</span>, <span class="st">"gbm_early_stopping"</span>]</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> axes[<span class="dv">2</span>].bar(labels, training_times)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">"Training Time (s)"</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar, n_estimators <span class="kw">in</span> <span class="bu">zip</span>(bars, [n_estimators_full, estimators_early_stopping]):</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    height <span class="op">=</span> bar.get_height()</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">2</span>].text(</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>        bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>,</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>        height <span class="op">+</span> <span class="fl">0.001</span>,</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Estimators: </span><span class="sc">{</span>n_estimators<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>        ha<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>        va<span class="op">=</span><span class="st">"bottom"</span>,</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Gradient_Boosting_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The difference in training error between the <code>gbm_full</code> and the <code>gbm_early_stopping</code> stems from the fact that<br>
<code>gbm_early_stopping</code> sets aside <code>validation_fraction</code> of the training data as an internal validation set.</p>
<p>Early stopping is decided based on this internal validation score.</p>
<p><strong>Benefits of Using Early Stopping in Boosting:</strong></p>
<ul>
<li><p><strong>Preventing Overfitting</strong><br>
Early stopping helps avoid overfitting by monitoring the test error.<br>
When the error stabilizes or starts increasing, training stops — resulting in better generalization to unseen data.</p></li>
<li><p><strong>Improving Training Efficiency</strong><br>
Models with early stopping often require <strong>fewer estimators</strong> while achieving similar accuracy.<br>
This reduces training time significantly compared to training without early stopping.</p></li>
</ul>
</section>
<section id="effect-of-learning-rate-on-cross-validation-error" class="level3" data-number="9.1.3">
<h3 data-number="9.1.3" class="anchored" data-anchor-id="effect-of-learning-rate-on-cross-validation-error"><span class="header-section-number">9.1.3</span> Effect of Learning Rate on Cross-Validation Error</h3>
<p>The learning rate (<code>learning_rate</code>) determines how much each new tree contributes to the overall model. A <strong>smaller learning rate</strong> results in slower learning and often requires more trees to achieve good performance. A <strong>larger learning rate</strong> speeds up learning but increases the risk of overfitting.</p>
<p>Finding the optimal learning rate involves balancing: - <strong>High learning rate</strong> → faster convergence, but higher risk of overfitting<br>
- <strong>Low learning rate</strong> → better generalization, but requires more trees and longer training time</p>
<p>Cross-validation helps identify the learning rate that minimizes prediction error while ensuring model stability.</p>
<div id="3553d5cc" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_models():</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    models <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create 9 evenly spaced values between 0.2 and 1.0</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    learning_rates <span class="op">=</span> np.linspace(<span class="fl">0.2</span>, <span class="fl">1.0</span>, <span class="dv">9</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> learning_rate <span class="kw">in</span> learning_rates:</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Round to 2 decimal places for clean keys</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        lr_rounded <span class="op">=</span> <span class="bu">round</span>(learning_rate, <span class="dv">2</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        key <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>lr_rounded<span class="sc">:.2f}</span><span class="ss">"</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        models[key] <span class="op">=</span> GradientBoostingRegressor(learning_rate<span class="op">=</span>lr_rounded, random_state<span class="op">=</span><span class="dv">1</span>, loss<span class="op">=</span><span class="st">'huber'</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> models</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate a given model using cross-validation</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model, X, y):</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># define the evaluation procedure</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># evaluate the model and collect the results</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> np.sqrt(<span class="op">-</span>cross_val_score(model, X, y, scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, cv<span class="op">=</span>cv, n_jobs<span class="op">=-</span><span class="dv">1</span>))</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> scores</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="co"># get the models to evaluate</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> get_models()</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate the models and store results</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>results, names <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>mean_scores <span class="op">=</span> []  <span class="co"># Track mean scores separately</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, model <span class="kw">in</span> models.items():</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># evaluate the model</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> evaluate_model(model, X_train_final, y_train)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store the results</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>    results.append(scores)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>    names.append(name)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate and store mean score</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>    mean_score <span class="op">=</span> np.mean(scores)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    mean_scores.append(mean_score)</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># summarize the performance along the way</span></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'&gt;</span><span class="sc">%s</span><span class="st"> </span><span class="sc">%.1f</span><span class="st"> (</span><span class="sc">%.1f</span><span class="st">)'</span> <span class="op">%</span> (name, mean_score, np.std(scores)))</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a><span class="co"># plot model performance for comparison</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>plt.boxplot(results, labels<span class="op">=</span>names, showmeans<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Cross validation error'</span>, fontsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Learning rate'</span>, fontsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Model Performance by Learning Rate'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the best model using the saved mean scores</span></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>best_index <span class="op">=</span> np.argmin(mean_scores)</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>best_lr <span class="op">=</span> names[best_index]</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>best_score <span class="op">=</span> mean_scores[best_index]</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight the best model on the plot</span></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_index<span class="op">+</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>plt.text(best_index<span class="op">+</span><span class="fl">1.2</span>, <span class="bu">min</span>(mean_scores)<span class="op">*</span><span class="fl">0.95</span>, </span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>         <span class="ss">f'Best: </span><span class="sc">{</span>best_lr<span class="sc">}</span><span class="ss"> (RMSE: </span><span class="sc">{</span>best_score<span class="sc">:.1f}</span><span class="ss">)'</span>, </span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>         color<span class="op">=</span><span class="st">'red'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the best model information</span></span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Best model: </span><span class="sc">{</span>best_lr<span class="sc">}</span><span class="ss"> with RMSE: </span><span class="sc">{</span>best_score<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt;0.20 4193.7 (301.2)
&gt;0.30 3740.3 (306.3)
&gt;0.40 3630.0 (212.2)
&gt;0.50 3529.6 (181.5)
&gt;0.60 3650.2 (169.0)
&gt;0.70 3644.7 (142.5)
&gt;0.80 3908.9 (260.6)
&gt;0.90 3968.7 (201.1)
&gt;1.00 4208.3 (368.5)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Gradient_Boosting_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Best model: 0.50 with RMSE: 3529.563</code></pre>
</div>
</div>
</section>
<section id="learning-rate-and-number-of-trees-are-closely-linked" class="level3" data-number="9.1.4">
<h3 data-number="9.1.4" class="anchored" data-anchor-id="learning-rate-and-number-of-trees-are-closely-linked"><span class="header-section-number">9.1.4</span> Learning Rate and Number of Trees Are Closely Linked</h3>
<p>The <strong>learning rate</strong> and <strong>number of trees</strong> (<code>n_estimators</code>) are tightly coupled hyperparameters in gradient boosting. Their balance plays a key role in model performance and overfitting control.</p>
<ul>
<li>A <strong>lower learning rate</strong> slows the learning process, requiring <strong>more trees</strong> to achieve strong performance.</li>
<li>A <strong>higher learning rate</strong> speeds up training but may cause the model to <strong>overfit</strong> if not regularized properly.</li>
</ul>
<p>⚠️ A high learning rate with too few trees can lead to poor generalization, while a very low learning rate with too many trees may improve accuracy but increase training time significantly.</p>
<p><strong>Best practice:</strong> Use a low to moderate learning rate (e.g., <code>0.01</code>–<code>0.1</code>) combined with <strong>early stopping</strong> to find the optimal number of trees.</p>
</section>
<section id="effect-of-stochastic-gradient-boosting-on-cross-validation-error" class="level3" data-number="9.1.5">
<h3 data-number="9.1.5" class="anchored" data-anchor-id="effect-of-stochastic-gradient-boosting-on-cross-validation-error"><span class="header-section-number">9.1.5</span> Effect of Stochastic Gradient Boosting on Cross-Validation Error</h3>
<p><strong>Stochastic Gradient Boosting</strong> enhances generalization by introducing randomness into the model-building process. Two key hyperparameters that control this are <code>subsample</code> and <code>max_features</code>, and they operate on <strong>different dimensions</strong> of the data:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 20%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Applies To</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>subsample</code></td>
<td>Rows (data points)</td>
<td>Randomly samples a fraction of the training data for each tree</td>
</tr>
<tr class="even">
<td><code>max_features</code></td>
<td>Columns (features)</td>
<td>Randomly samples a fraction of the features for each tree or split</td>
</tr>
</tbody>
</table>
<p>By tuning these parameters, we can reduce overfitting and increase model robustness. However, setting them too low may lead to underfitting due to insufficient information per tree.</p>
<div id="e06e6340" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> make_scorer, mean_squared_error</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define model</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GradientBoostingRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">4</span>, learning_rate<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define param grid</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'subsample'</span>: np.linspace(<span class="fl">0.2</span>, <span class="fl">1.0</span>, <span class="dv">9</span>),</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_features'</span>: np.linspace(<span class="fl">0.2</span>, <span class="fl">1.0</span>, <span class="dv">9</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE scoring</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>scorer <span class="op">=</span> make_scorer(mean_squared_error, greater_is_better<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid search</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model, param_grid<span class="op">=</span>param_grid,</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>                    scoring<span class="op">=</span>scorer, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>grid.fit(X_train_final, y_train)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame from results</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(grid.cv_results_)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>results_df[<span class="st">'mean_rmse'</span>] <span class="op">=</span> np.sqrt(<span class="op">-</span>results_df[<span class="st">'mean_test_score'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 81 candidates, totalling 405 fits</code></pre>
</div>
</div>
<div id="9cd37cec" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Round subsample and max_features to 2 decimal places for display</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>results_df[<span class="st">'subsample'</span>] <span class="op">=</span> results_df[<span class="st">'param_subsample'</span>].astype(<span class="bu">float</span>).<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>results_df[<span class="st">'max_features'</span>] <span class="op">=</span> results_df[<span class="st">'param_max_features'</span>].astype(<span class="bu">float</span>).<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Then pivot using the rounded values</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>heatmap_data <span class="op">=</span> results_df.pivot(index<span class="op">=</span><span class="st">'subsample'</span>, columns<span class="op">=</span><span class="st">'max_features'</span>, values<span class="op">=</span><span class="st">'mean_rmse'</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot heatmap</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">9</span>))</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>sns.heatmap(heatmap_data, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">".3f"</span>, cmap<span class="op">=</span><span class="st">"YlGnBu"</span>, cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'CV RMSE'</span>})</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Grid Search: CV RMSE by Subsample and Max Features'</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Subsample'</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Max Features'</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Gradient_Boosting_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="effect-of-tree-complexity-on-cross-validation-error-not-tuned-here" class="level3" data-number="9.1.6">
<h3 data-number="9.1.6" class="anchored" data-anchor-id="effect-of-tree-complexity-on-cross-validation-error-not-tuned-here"><span class="header-section-number">9.1.6</span> Effect of Tree Complexity on Cross-Validation Error (Not Tuned Here)</h3>
<p><strong>Tree complexity</strong> controls how expressive and flexible each individual tree in the gradient boosting ensemble can be. While deeper and more complex trees can capture intricate patterns in the data, they are also more prone to overfitting, especially when combined with many trees.</p>
<p>Key parameters include:</p>
<ul>
<li><code>max_depth</code>: Limits the depth of each tree. Shallower trees (e.g., depth 3–6) are preferred for reducing overfitting.</li>
<li><code>min_samples_split</code>: Specifies the minimum number of samples required to split an internal node. Higher values make the tree more conservative.</li>
<li><code>min_samples_leaf</code>: Sets the minimum number of samples required to be at a leaf node. This also helps smooth the model and avoid capturing noise.</li>
</ul>
<p>These parameters influence the bias-variance trade-off by adjusting how expressive each tree can be.</p>
<p>Since we have already discussed and tuned these parameters in earlier lessons (decision trees and random forests), we will <strong>not tune them again here</strong>.</p>
</section>
<section id="loss-function-loss" class="level3" data-number="9.1.7">
<h3 data-number="9.1.7" class="anchored" data-anchor-id="loss-function-loss"><span class="header-section-number">9.1.7</span> Loss Function (<code>loss</code>)</h3>
<p>In gradient boosting, the loss function determines how the model measures prediction errors and guides the optimization process during training. Here’s a breakdown of common loss functions for regression and classification tasks:</p>
<ul>
<li><strong>Regression</strong>:
<ul>
<li><code>squared_error</code>: Penalizes larger errors more heavily; sensitive to outliers. <em>(Default for regression)</em></li>
<li><code>absolute_error</code>: Penalizes all errors equally; more robust to outliers.</li>
<li><code>huber</code>: Combines squared and absolute error; less sensitive to outliers than <code>squared_error</code> and smoother than <code>absolute_error</code>.</li>
</ul></li>
<li><strong>Classification</strong>:
<ul>
<li><code>log_loss</code>: Also known as logistic loss or deviance; commonly used for binary and multiclass classification.</li>
<li><code>exponential</code>: Used by AdaBoost; heavily penalizes misclassified points, making it more sensitive to outliers.</li>
</ul></li>
</ul>
<p>Choosing an appropriate loss function ensures the model is optimized for the specific structure and goals of the problem.</p>
</section>
</section>
<section id="joint-hyperparameter-tuning-in-gradient-boosting-for-regression" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="joint-hyperparameter-tuning-in-gradient-boosting-for-regression"><span class="header-section-number">9.2</span> Joint Hyperparameter Tuning in Gradient Boosting for Regression</h2>
<p>Since the optimal values of hyperparameters are often interdependent, they should be tuned <strong>together</strong> rather than in isolation to achieve the best performance.</p>
<section id="using-bayessearchcv" class="level3" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="using-bayessearchcv"><span class="header-section-number">9.2.1</span> Using <code>BayesSearchCV</code></h3>
<p>We can use <code>BayesSearchCV</code> with early stopping to <strong>simultaneously tune multiple hyperparameters</strong> in a more efficient and automated way.</p>
<div id="65054b73" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># time the search</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the search space</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>search_space <span class="op">=</span> {</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: Real(<span class="fl">0.01</span>, <span class="fl">0.8</span>, prior<span class="op">=</span><span class="st">'log-uniform'</span>),  <span class="co"># Prefer lower rates</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: Integer(<span class="dv">4</span>, <span class="dv">32</span>),          <span class="co"># Shallow trees to prevent overfitting</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: Integer(<span class="dv">2</span>, <span class="dv">100</span>), <span class="co"># Regularize splits</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_leaf'</span>: Integer(<span class="dv">1</span>, <span class="dv">30</span>),  <span class="co"># Regularize leaves</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'subsample'</span>: Real(<span class="fl">0.1</span>, <span class="fl">1.0</span>),         <span class="co"># Stochastic sampling</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_features'</span>: Categorical([</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sqrt'</span>, <span class="st">'log2'</span>, <span class="va">None</span>,  <span class="co"># String options</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        <span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>  <span class="co"># Fractional options (discrete)</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    ])  <span class="co"># Feature sampling</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the model</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>model_with_early_stopping <span class="op">=</span> GradientBoostingRegressor(</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">10000</span>,  <span class="co"># Start with a large number of trees</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    validation_fraction<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># Reserve 10% of training data for validation</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    n_iter_no_change<span class="op">=</span><span class="dv">10</span>,      <span class="co"># Stop after 20 rounds of no improvement</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    tol<span class="op">=</span><span class="fl">0.001</span>,           <span class="co"># Tolerance for early stopping</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the search</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>bayes_cv  <span class="op">=</span> BayesSearchCV(</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    model_with_early_stopping,</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    search_space,</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    n_iter<span class="op">=</span><span class="dv">50</span>,  <span class="co"># Number of iterations</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>,</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">5</span>,  <span class="co"># Cross-validation folds</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,  <span class="co"># Use all available cores</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span>,  <span class="co"># Verbosity level</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>  <span class="co"># For reproducibility</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>bayes_cv.fit(X_train_final, y_train)</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Stop the timer</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time.time()</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate elapsed time</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>elapsed_time <span class="op">=</span> (end <span class="op">-</span> start)<span class="op">/</span><span class="dv">60</span>  <span class="co"># Convert to minutes</span></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Print elapsed time</span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Elapsed time for Bayesian optimization with early stopping: </span><span class="sc">{</span>elapsed_time<span class="sc">:.2f}</span><span class="ss"> minutes"</span>)</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the best parameters and score</span></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>best_params <span class="op">=</span> bayes_cv.best_params_</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>best_score <span class="op">=</span> np.sqrt(<span class="op">-</span>bayes_cv.best_score_)</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Parameters: </span><span class="sc">{</span>best_params<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best CV RMSE: </span><span class="sc">{</span>best_score<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Elapsed time for Bayesian optimization with early stopping: 10.24 minutes
Best Parameters: OrderedDict({'learning_rate': 0.01, 'max_depth': 32, 'max_features': 0.6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'subsample': 0.302790110221997})
Best CV RMSE: 3142.483</code></pre>
</div>
</div>
<div id="a7695e37" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the optimization results</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>plot_convergence(bayes_cv.optimizer_results_)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Gradient_Boosting_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="6c1d110e" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the objective function</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>plot_objective(bayes_cv.optimizer_results_[<span class="dv">0</span>])</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Bayesian Optimization: Objective Function'</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Parameter Value'</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Objective Value (RMSE)'</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Gradient_Boosting_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="tuning-with-optuna" class="level3" data-number="9.2.2">
<h3 data-number="9.2.2" class="anchored" data-anchor-id="tuning-with-optuna"><span class="header-section-number">9.2.2</span> Tuning with Optuna</h3>
<div id="681af397" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective(trial):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define hyperparameters to optimize</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> {</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'learning_rate'</span>: trial.suggest_float(<span class="st">'learning_rate'</span>, <span class="fl">0.01</span>, <span class="fl">0.8</span>, log<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'max_depth'</span>: trial.suggest_int(<span class="st">'max_depth'</span>, <span class="dv">4</span>, <span class="dv">32</span>),</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'min_samples_split'</span>: trial.suggest_int(<span class="st">'min_samples_split'</span>, <span class="dv">2</span>, <span class="dv">100</span>),</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'min_samples_leaf'</span>: trial.suggest_int(<span class="st">'min_samples_leaf'</span>, <span class="dv">1</span>, <span class="dv">30</span>),</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'subsample'</span>: trial.suggest_float(<span class="st">'subsample'</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span>),</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">'max_features'</span>: trial.suggest_categorical(</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_features'</span>, </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>            [<span class="st">'sqrt'</span>, <span class="st">'log2'</span>, <span class="va">None</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>]</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'n_iter_no_change'</span>: <span class="dv">10</span>,  <span class="co"># Stop if no improvement in 50 rounds</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'validation_fraction'</span>: <span class="fl">0.1</span>,  <span class="co"># 10% of training data for validation</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'tol'</span>: <span class="fl">0.001</span>,  <span class="co"># Tolerance for early stopping</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'n_estimators'</span>: <span class="dv">10000</span>,  <span class="co"># Start with a large number of trees</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">'random_state'</span>: <span class="dv">42</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize the model with the parameters, adding early stopping</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> GradientBoostingRegressor(</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>params</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> GradientBoostingRegressor(<span class="op">**</span>params)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the evaluation procedure</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform cross-validation</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> cross_val_score(model, X_train_final, y_train, cv<span class="op">=</span>cv, scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(np.sqrt(<span class="op">-</span>scores)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0fb4bec0" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> optuna</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a study object</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">"minimize"</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>study.optimize(objective, n_trials<span class="op">=</span><span class="dv">50</span>, timeout<span class="op">=</span><span class="dv">600</span>)  <span class="co"># 50 trials or 10 min</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Stop the timer</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time.time()</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate elapsed time</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>elapsed_time <span class="op">=</span> (end <span class="op">-</span> start)<span class="op">/</span><span class="dv">60</span>  <span class="co"># Convert to minutes</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Elapsed time for Optuna optimization: </span><span class="sc">{</span>elapsed_time<span class="sc">:.2f}</span><span class="ss"> minutes"</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the best parameters and score</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>best_params_optuna <span class="op">=</span> study.best_params</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>best_score_optuna <span class="op">=</span> study.best_value</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Parameters: </span><span class="sc">{</span>best_params_optuna<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best CV RMSE: </span><span class="sc">{</span>best_score_optuna<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-05-06 17:02:10,428] A new study created in memory with name: no-name-a137b8c9-3b60-46c9-a520-903b610148de
[I 2025-05-06 17:02:29,091] Trial 0 finished with value: 3713.7523573640283 and parameters: {'learning_rate': 0.02248358344580717, 'max_depth': 14, 'min_samples_split': 84, 'min_samples_leaf': 10, 'subsample': 0.9198945421607535, 'max_features': 0.8}. Best is trial 0 with value: 3713.7523573640283.
[I 2025-05-06 17:02:30,785] Trial 1 finished with value: 4709.295547981693 and parameters: {'learning_rate': 0.021255444625248174, 'max_depth': 12, 'min_samples_split': 44, 'min_samples_leaf': 7, 'subsample': 0.1707682907352387, 'max_features': 0.4}. Best is trial 0 with value: 3713.7523573640283.
[I 2025-05-06 17:02:31,180] Trial 2 finished with value: 6213.951571057093 and parameters: {'learning_rate': 0.257260645216299, 'max_depth': 16, 'min_samples_split': 51, 'min_samples_leaf': 28, 'subsample': 0.254712411062096, 'max_features': 'log2'}. Best is trial 0 with value: 3713.7523573640283.
[I 2025-05-06 17:02:31,883] Trial 3 finished with value: 6581.2879973994595 and parameters: {'learning_rate': 0.039685822132341286, 'max_depth': 8, 'min_samples_split': 100, 'min_samples_leaf': 23, 'subsample': 0.10645669656397064, 'max_features': 0.7}. Best is trial 0 with value: 3713.7523573640283.
[I 2025-05-06 17:02:32,144] Trial 4 finished with value: 5363.950030465088 and parameters: {'learning_rate': 0.3455781519918328, 'max_depth': 17, 'min_samples_split': 77, 'min_samples_leaf': 6, 'subsample': 0.12865977500830594, 'max_features': 0.3}. Best is trial 0 with value: 3713.7523573640283.
[I 2025-05-06 17:02:32,430] Trial 5 finished with value: 4845.887213572036 and parameters: {'learning_rate': 0.4565662155241608, 'max_depth': 26, 'min_samples_split': 83, 'min_samples_leaf': 2, 'subsample': 0.15850689303953563, 'max_features': 0.4}. Best is trial 0 with value: 3713.7523573640283.
[I 2025-05-06 17:02:33,509] Trial 6 finished with value: 4571.976448159823 and parameters: {'learning_rate': 0.10735415192791704, 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 14, 'subsample': 0.27035383258765106, 'max_features': 0.6}. Best is trial 0 with value: 3713.7523573640283.
[I 2025-05-06 17:02:37,056] Trial 7 finished with value: 3877.957199433686 and parameters: {'learning_rate': 0.02247133609163658, 'max_depth': 16, 'min_samples_split': 56, 'min_samples_leaf': 14, 'subsample': 0.6650860961577256, 'max_features': 'log2'}. Best is trial 0 with value: 3713.7523573640283.
[I 2025-05-06 17:02:43,003] Trial 8 finished with value: 4569.273660258111 and parameters: {'learning_rate': 0.06107251708354381, 'max_depth': 31, 'min_samples_split': 25, 'min_samples_leaf': 28, 'subsample': 0.5318799842701212, 'max_features': 0.6}. Best is trial 0 with value: 3713.7523573640283.
[I 2025-05-06 17:02:45,166] Trial 9 finished with value: 3698.820690997482 and parameters: {'learning_rate': 0.2976093956967727, 'max_depth': 19, 'min_samples_split': 66, 'min_samples_leaf': 11, 'subsample': 0.684007192168673, 'max_features': 0.4}. Best is trial 9 with value: 3698.820690997482.
[I 2025-05-06 17:02:51,446] Trial 10 finished with value: 3732.1319915304725 and parameters: {'learning_rate': 0.14857584264946835, 'max_depth': 23, 'min_samples_split': 65, 'min_samples_leaf': 19, 'subsample': 0.9764359841828532, 'max_features': 0.9}. Best is trial 9 with value: 3698.820690997482.
[I 2025-05-06 17:02:58,569] Trial 11 finished with value: 4300.5959486610955 and parameters: {'learning_rate': 0.010202602277738192, 'max_depth': 4, 'min_samples_split': 97, 'min_samples_leaf': 9, 'subsample': 0.8832039167433217, 'max_features': 'sqrt'}. Best is trial 9 with value: 3698.820690997482.
[I 2025-05-06 17:02:59,894] Trial 12 finished with value: 4520.923335421491 and parameters: {'learning_rate': 0.7620683026616721, 'max_depth': 22, 'min_samples_split': 79, 'min_samples_leaf': 11, 'subsample': 0.7319044315900822, 'max_features': 0.8}. Best is trial 9 with value: 3698.820690997482.
[I 2025-05-06 17:03:01,948] Trial 13 finished with value: 3571.01788037487 and parameters: {'learning_rate': 0.15614029401648188, 'max_depth': 12, 'min_samples_split': 67, 'min_samples_leaf': 1, 'subsample': 0.5111987527158, 'max_features': None}. Best is trial 13 with value: 3571.01788037487.
[I 2025-05-06 17:03:04,511] Trial 14 finished with value: 3721.8669565390346 and parameters: {'learning_rate': 0.18254411875454832, 'max_depth': 10, 'min_samples_split': 36, 'min_samples_leaf': 4, 'subsample': 0.4612952455517902, 'max_features': None}. Best is trial 13 with value: 3571.01788037487.
[I 2025-05-06 17:03:08,463] Trial 15 finished with value: 4586.350862990998 and parameters: {'learning_rate': 0.07811568693635618, 'max_depth': 21, 'min_samples_split': 66, 'min_samples_leaf': 19, 'subsample': 0.4388461890810313, 'max_features': None}. Best is trial 13 with value: 3571.01788037487.
[I 2025-05-06 17:03:09,014] Trial 16 finished with value: 4058.9829855282683 and parameters: {'learning_rate': 0.6182727390711481, 'max_depth': 6, 'min_samples_split': 66, 'min_samples_leaf': 3, 'subsample': 0.7300101814075026, 'max_features': 0.2}. Best is trial 13 with value: 3571.01788037487.
[I 2025-05-06 17:03:10,412] Trial 17 finished with value: 3517.5610120729484 and parameters: {'learning_rate': 0.2260987084594416, 'max_depth': 27, 'min_samples_split': 30, 'min_samples_leaf': 1, 'subsample': 0.6220947410623251, 'max_features': 0.5}. Best is trial 17 with value: 3517.5610120729484.
[I 2025-05-06 17:03:12,200] Trial 18 finished with value: 3430.5907640777577 and parameters: {'learning_rate': 0.17398353431679398, 'max_depth': 32, 'min_samples_split': 22, 'min_samples_leaf': 1, 'subsample': 0.567921000087246, 'max_features': 0.5}. Best is trial 18 with value: 3430.5907640777577.
[I 2025-05-06 17:03:13,771] Trial 19 finished with value: 3799.704577632151 and parameters: {'learning_rate': 0.2113771906877164, 'max_depth': 32, 'min_samples_split': 13, 'min_samples_leaf': 6, 'subsample': 0.35701198752701807, 'max_features': 0.5}. Best is trial 18 with value: 3430.5907640777577.
[I 2025-05-06 17:03:16,441] Trial 20 finished with value: 3462.9715057349613 and parameters: {'learning_rate': 0.11859708798761973, 'max_depth': 28, 'min_samples_split': 22, 'min_samples_leaf': 1, 'subsample': 0.6147825598561754, 'max_features': 0.5}. Best is trial 18 with value: 3430.5907640777577.
[I 2025-05-06 17:03:19,025] Trial 21 finished with value: 3476.7550517115924 and parameters: {'learning_rate': 0.10420353418823357, 'max_depth': 28, 'min_samples_split': 23, 'min_samples_leaf': 1, 'subsample': 0.6215767359553783, 'max_features': 0.5}. Best is trial 18 with value: 3430.5907640777577.
[I 2025-05-06 17:03:21,047] Trial 22 finished with value: 3383.380528420081 and parameters: {'learning_rate': 0.10471285971022815, 'max_depth': 29, 'min_samples_split': 19, 'min_samples_leaf': 4, 'subsample': 0.597377769880787, 'max_features': 0.5}. Best is trial 22 with value: 3383.380528420081.
[I 2025-05-06 17:03:23,960] Trial 23 finished with value: 3209.6438264561025 and parameters: {'learning_rate': 0.04575023632986291, 'max_depth': 29, 'min_samples_split': 16, 'min_samples_leaf': 5, 'subsample': 0.8240310872125836, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:03:26,667] Trial 24 finished with value: 3317.3765168790715 and parameters: {'learning_rate': 0.05301655488320774, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.8242756561073044, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:03:28,696] Trial 25 finished with value: 3288.8335695654087 and parameters: {'learning_rate': 0.04830647451540176, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.7942027280810069, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:03:32,953] Trial 26 finished with value: 3425.413176428209 and parameters: {'learning_rate': 0.042308997055776246, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.8278354367709382, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:03:35,890] Trial 27 finished with value: 3469.518619833793 and parameters: {'learning_rate': 0.0466230123921755, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 13, 'subsample': 0.8052277987014741, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:03:41,256] Trial 28 finished with value: 3555.0715331503548 and parameters: {'learning_rate': 0.031455552094573465, 'max_depth': 30, 'min_samples_split': 12, 'min_samples_leaf': 17, 'subsample': 0.8119650691265342, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:03:47,727] Trial 29 finished with value: 3257.3393769477807 and parameters: {'learning_rate': 0.01452498187868172, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.9848024466984958, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:03:59,875] Trial 30 finished with value: 3455.808400573129 and parameters: {'learning_rate': 0.0141106226105524, 'max_depth': 20, 'min_samples_split': 33, 'min_samples_leaf': 10, 'subsample': 0.9897132424049275, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:04:01,814] Trial 31 finished with value: 3348.559154847241 and parameters: {'learning_rate': 0.0669987413846962, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.9162347855034817, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:04:06,672] Trial 32 finished with value: 3323.7458320560645 and parameters: {'learning_rate': 0.027301254899220292, 'max_depth': 29, 'min_samples_split': 15, 'min_samples_leaf': 7, 'subsample': 0.8815062963541562, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:04:13,437] Trial 33 finished with value: 3424.053952590986 and parameters: {'learning_rate': 0.01865944524867004, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.7603406633468363, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:04:16,575] Trial 34 finished with value: 3247.244108372873 and parameters: {'learning_rate': 0.05328518948332194, 'max_depth': 26, 'min_samples_split': 38, 'min_samples_leaf': 5, 'subsample': 0.933814407713822, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:04:33,247] Trial 35 finished with value: 3512.98378266172 and parameters: {'learning_rate': 0.032811685881104016, 'max_depth': 27, 'min_samples_split': 43, 'min_samples_leaf': 3, 'subsample': 0.9349199422561425, 'max_features': 0.7}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:04:42,133] Trial 36 finished with value: 3273.2818821200813 and parameters: {'learning_rate': 0.014531603935487294, 'max_depth': 21, 'min_samples_split': 41, 'min_samples_leaf': 7, 'subsample': 0.9566273610057331, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:04:59,100] Trial 37 finished with value: 3478.727227894916 and parameters: {'learning_rate': 0.016111352463965768, 'max_depth': 15, 'min_samples_split': 43, 'min_samples_leaf': 12, 'subsample': 0.9356897625242079, 'max_features': 0.3}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:05:09,392] Trial 38 finished with value: 3309.6797560000705 and parameters: {'learning_rate': 0.010128458871148667, 'max_depth': 19, 'min_samples_split': 50, 'min_samples_leaf': 7, 'subsample': 0.8779877712669655, 'max_features': 'sqrt'}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:06:01,821] Trial 39 finished with value: 3755.080833012932 and parameters: {'learning_rate': 0.01334752150112578, 'max_depth': 21, 'min_samples_split': 38, 'min_samples_leaf': 9, 'subsample': 0.999021215832478, 'max_features': 0.9}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:06:11,332] Trial 40 finished with value: 3733.741397844383 and parameters: {'learning_rate': 0.025229997026387254, 'max_depth': 18, 'min_samples_split': 29, 'min_samples_leaf': 25, 'subsample': 0.9448604828360397, 'max_features': 0.2}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:06:15,992] Trial 41 finished with value: 3306.4308993805207 and parameters: {'learning_rate': 0.035797039293280396, 'max_depth': 25, 'min_samples_split': 53, 'min_samples_leaf': 5, 'subsample': 0.8554335326676519, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:06:19,531] Trial 42 finished with value: 3215.3040996921914 and parameters: {'learning_rate': 0.021059029078340487, 'max_depth': 23, 'min_samples_split': 16, 'min_samples_leaf': 3, 'subsample': 0.7626063576387598, 'max_features': 0.1}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:06:23,455] Trial 43 finished with value: 3234.8110020390777 and parameters: {'learning_rate': 0.019500530051685346, 'max_depth': 23, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.9062572351704351, 'max_features': 'log2'}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:06:27,847] Trial 44 finished with value: 3249.4922397265354 and parameters: {'learning_rate': 0.019103729427167728, 'max_depth': 23, 'min_samples_split': 18, 'min_samples_leaf': 3, 'subsample': 0.9103498041706436, 'max_features': 'log2'}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:06:31,136] Trial 45 finished with value: 3210.997902617934 and parameters: {'learning_rate': 0.02189353173609953, 'max_depth': 23, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.7603822335305171, 'max_features': 'log2'}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:06:34,258] Trial 46 finished with value: 3244.661570113128 and parameters: {'learning_rate': 0.023188029126972206, 'max_depth': 26, 'min_samples_split': 27, 'min_samples_leaf': 3, 'subsample': 0.7040659125354018, 'max_features': 'log2'}. Best is trial 23 with value: 3209.6438264561025.
[I 2025-05-06 17:06:37,225] Trial 47 finished with value: 3205.3588096764424 and parameters: {'learning_rate': 0.022878117048627775, 'max_depth': 23, 'min_samples_split': 27, 'min_samples_leaf': 3, 'subsample': 0.6772149662412676, 'max_features': 'log2'}. Best is trial 47 with value: 3205.3588096764424.
[I 2025-05-06 17:06:40,411] Trial 48 finished with value: 3245.293742974289 and parameters: {'learning_rate': 0.028053242768614584, 'max_depth': 23, 'min_samples_split': 17, 'min_samples_leaf': 2, 'subsample': 0.6651900286813389, 'max_features': 'log2'}. Best is trial 47 with value: 3205.3588096764424.
[I 2025-05-06 17:06:43,714] Trial 49 finished with value: 3238.761898699402 and parameters: {'learning_rate': 0.02112270512859443, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.7755749957927541, 'max_features': 'log2'}. Best is trial 47 with value: 3205.3588096764424.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Elapsed time for Optuna optimization: 4.55 minutes
Best Parameters: {'learning_rate': 0.022878117048627775, 'max_depth': 23, 'min_samples_split': 27, 'min_samples_leaf': 3, 'subsample': 0.6772149662412676, 'max_features': 'log2'}
Best CV RMSE: 3205.359</code></pre>
</div>
</div>
<div id="e9ad2bb2" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>optuna.visualization.plot_optimization_history(study).show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
</div>
<div id="567e894a" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>optuna.visualization.plot_param_importances(study).show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
</div>
<div id="d452edcb" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>optuna.visualization.plot_parallel_coordinate(study).show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
</div>
</section>
</section>
<section id="scaling-gradient-boosting-for-large-datasets-and-smarter-tuning" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="scaling-gradient-boosting-for-large-datasets-and-smarter-tuning"><span class="header-section-number">9.3</span> Scaling Gradient Boosting for Large Datasets and Smarter Tuning</h2>
<p>Check out <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html"><code>HistGradientBoostingRegressor()</code></a> and <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html"><code>HistGradientBoostingClassifier()</code></a> for a faster gradient boosting algorithm for big datasets <em>(more than 10,000 observations)</em>.</p>
<p>Check out tips for faster hyperparameter tuning, such as tuning <code>max_leaf_nodes</code> instead of <code>max_depth</code> <a href="https://scikit-learn.org/stable/modules/ensemble.html#controlling-the-tree-size">here</a>.</p>
</section>
<section id="independent-study" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="independent-study"><span class="header-section-number">9.4</span> Independent Study</h2>
<p>In this notebook, we used the car dataset for a guided regression task to illustrate the core hyperparameters in gradient boosting and how to tune them to balance bias and variance.</p>
<p>For your practice, please work with the <strong>diabetes dataset</strong> and complete the following:</p>
<ul>
<li>Fit a baseline gradient boosting classifier.</li>
<li>Tune key hyperparameters: <code>learning_rate</code>, <code>n_estimators</code>, <code>max_depth</code>, and <code>subsample</code>.</li>
<li>Use <strong>early stopping</strong> to determine the optimal number of trees.</li>
<li>Compare training and test <code>roc_auc</code> before and after tuning.</li>
<li>Visualize the learning curve (training vs test error across iterations).</li>
<li>Summarize what combination of hyperparameters yielded the best performance and how they impacted bias and variance.</li>
</ul>
<p>Feel free to use <code>GridSearchCV</code>, <code>BayesSearchCV</code>, or other tuning as you prefer.</p>
<div id="7b50e2fd" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.read_csv(<span class="st">'./Datasets/diabetes_train.csv'</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.read_csv(<span class="st">'./Datasets/diabetes_test.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="41f5f44f" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train.shape, test.shape)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>train.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(614, 9) (154, 9)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="39">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Pregnancies</th>
<th data-quarto-table-cell-role="th">Glucose</th>
<th data-quarto-table-cell-role="th">BloodPressure</th>
<th data-quarto-table-cell-role="th">SkinThickness</th>
<th data-quarto-table-cell-role="th">Insulin</th>
<th data-quarto-table-cell-role="th">BMI</th>
<th data-quarto-table-cell-role="th">DiabetesPedigreeFunction</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2</td>
<td>88</td>
<td>74</td>
<td>19</td>
<td>53</td>
<td>29.0</td>
<td>0.229</td>
<td>22</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>129</td>
<td>84</td>
<td>0</td>
<td>0</td>
<td>28.0</td>
<td>0.284</td>
<td>27</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0</td>
<td>102</td>
<td>78</td>
<td>40</td>
<td>90</td>
<td>34.5</td>
<td>0.238</td>
<td>24</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0</td>
<td>123</td>
<td>72</td>
<td>0</td>
<td>0</td>
<td>36.3</td>
<td>0.258</td>
<td>52</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>144</td>
<td>82</td>
<td>46</td>
<td>180</td>
<td>46.1</td>
<td>0.335</td>
<td>46</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="68b1eac9" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check the distribution of the target variable</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">'Outcome'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>Outcome
0    0.662866
1    0.337134
Name: proportion, dtype: float64</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./adaboost.html" class="pagination-link" aria-label="Adaptive Boosting">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Adaptive Boosting</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Lec9_XGBoost.html" class="pagination-link" aria-label="XGBoost">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">XGBoost</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>